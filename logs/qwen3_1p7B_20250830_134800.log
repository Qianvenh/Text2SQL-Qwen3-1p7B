[2025-08-30 13:48:06,042] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
WARNING 08-30 13:48:08 _custom_ops.py:14] Failed to import from vllm._C with ImportError('/home/qianwenhao/.conda/envs/llamafactory/lib/python3.11/site-packages/vllm/_C.abi3.so: undefined symbol: _ZN5torch3jit11parseSchemaERKSs')
[INFO|2025-08-30 13:48:09] llamafactory.cli:143 >> Initializing 4 distributed tasks at: 127.0.0.1:59237
W0830 13:48:11.005000 4003314 site-packages/torch/distributed/run.py:793] 
W0830 13:48:11.005000 4003314 site-packages/torch/distributed/run.py:793] *****************************************
W0830 13:48:11.005000 4003314 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0830 13:48:11.005000 4003314 site-packages/torch/distributed/run.py:793] *****************************************
[2025-08-30 13:48:15,539] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-30 13:48:15,542] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-30 13:48:16,325] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-30 13:48:16,521] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-30 13:48:17,657] [INFO] [comm.py:669:init_distributed] cdb=None
[W830 13:48:17.340427839 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[2025-08-30 13:48:17,749] [INFO] [comm.py:669:init_distributed] cdb=None
[W830 13:48:17.430839861 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[INFO|2025-08-30 13:48:17] llamafactory.hparams.parser:406 >> Process rank: 1, world size: 4, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
[INFO|2025-08-30 13:48:17] llamafactory.hparams.parser:406 >> Process rank: 2, world size: 4, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
[rank1]:[W830 13:48:18.364455625 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[2025-08-30 13:48:18,738] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-08-30 13:48:18,738] [INFO] [comm.py:700:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[W830 13:48:18.420505899 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[rank2]:[W830 13:48:18.426352494 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[INFO|2025-08-30 13:48:18] llamafactory.hparams.parser:143 >> Set `ddp_find_unused_parameters` to False in DDP training since LoRA is enabled.
[INFO|2025-08-30 13:48:18] llamafactory.hparams.parser:406 >> Process rank: 0, world size: 4, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
[INFO|tokenization_utils_base.py:2021] 2025-08-30 13:48:18,823 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-08-30 13:48:18,823 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-08-30 13:48:18,823 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-08-30 13:48:18,823 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-08-30 13:48:18,823 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-08-30 13:48:18,824 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-08-30 13:48:18,824 >> loading file chat_template.jinja
[2025-08-30 13:48:18,917] [INFO] [comm.py:669:init_distributed] cdb=None
[W830 13:48:18.600358720 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[INFO|2025-08-30 13:48:19] llamafactory.hparams.parser:406 >> Process rank: 3, world size: 4, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
[INFO|tokenization_utils_base.py:2299] 2025-08-30 13:48:19,197 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:696] 2025-08-30 13:48:19,197 >> loading configuration file /home/qianwenhao/LLM/Qwen3-1.7B/config.json
[INFO|configuration_utils.py:770] 2025-08-30 13:48:19,200 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "max_position_embeddings": 40960,
  "max_window_layers": 28,
  "model_type": "qwen3",
  "num_attention_heads": 16,
  "num_hidden_layers": 28,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|tokenization_utils_base.py:2021] 2025-08-30 13:48:19,200 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-08-30 13:48:19,200 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-08-30 13:48:19,200 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-08-30 13:48:19,200 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-08-30 13:48:19,200 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-08-30 13:48:19,201 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-08-30 13:48:19,201 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-08-30 13:48:19,573 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|2025-08-30 13:48:19] llamafactory.data.loader:143 >> Loading dataset text2sql.json...
[rank3]:[W830 13:48:19.590678391 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
Converting format of dataset (num_proc=16):   0%|          | 0/126285 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16):   0%|          | 579/126285 [00:00<00:23, 5402.45 examples/s]Converting format of dataset (num_proc=16):  15%|█▌        | 19220/126285 [00:00<00:01, 106929.04 examples/s]Converting format of dataset (num_proc=16):  33%|███▎      | 41590/126285 [00:00<00:00, 158117.78 examples/s]Converting format of dataset (num_proc=16):  50%|█████     | 63505/126285 [00:00<00:00, 180899.56 examples/s]Converting format of dataset (num_proc=16):  68%|██████▊   | 85690/126285 [00:00<00:00, 195360.74 examples/s]Converting format of dataset (num_proc=16):  84%|████████▍ | 106439/126285 [00:00<00:00, 197801.40 examples/s]Converting format of dataset (num_proc=16): 100%|██████████| 126285/126285 [00:01<00:00, 125256.09 examples/s]
[rank0]:[W830 13:48:22.781401081 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
Running tokenizer on dataset (num_proc=16):   0%|          | 0/126285 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   1%|          | 1000/126285 [00:01<02:42, 769.54 examples/s]Running tokenizer on dataset (num_proc=16):   2%|▏         | 2000/126285 [00:01<01:29, 1381.20 examples/s]Running tokenizer on dataset (num_proc=16):   3%|▎         | 4000/126285 [00:01<00:41, 2961.85 examples/s]Running tokenizer on dataset (num_proc=16):   6%|▌         | 7000/126285 [00:02<00:21, 5596.51 examples/s]Running tokenizer on dataset (num_proc=16):   8%|▊         | 10000/126285 [00:02<00:13, 8748.91 examples/s]Running tokenizer on dataset (num_proc=16):  10%|▉         | 12000/126285 [00:02<00:11, 9758.01 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 16000/126285 [00:02<00:07, 13873.61 examples/s]Running tokenizer on dataset (num_proc=16):  14%|█▍        | 18000/126285 [00:02<00:08, 13317.09 examples/s]Running tokenizer on dataset (num_proc=16):  17%|█▋        | 22000/126285 [00:02<00:05, 17512.84 examples/s]Running tokenizer on dataset (num_proc=16):  21%|██        | 26000/126285 [00:02<00:04, 20326.45 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▍       | 31000/126285 [00:02<00:03, 25593.92 examples/s]Running tokenizer on dataset (num_proc=16):  27%|██▋       | 34000/126285 [00:03<00:03, 23395.62 examples/s]Running tokenizer on dataset (num_proc=16):  30%|███       | 38000/126285 [00:03<00:03, 23714.38 examples/s]Running tokenizer on dataset (num_proc=16):  32%|███▏      | 41000/126285 [00:03<00:03, 24252.27 examples/s]Running tokenizer on dataset (num_proc=16):  35%|███▍      | 44000/126285 [00:03<00:04, 20065.74 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 48000/126285 [00:03<00:03, 20256.07 examples/s]Running tokenizer on dataset (num_proc=16):  40%|████      | 51000/126285 [00:03<00:03, 19880.05 examples/s]Running tokenizer on dataset (num_proc=16):  43%|████▎     | 54000/126285 [00:04<00:05, 14063.62 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 56000/126285 [00:04<00:04, 14210.26 examples/s]Running tokenizer on dataset (num_proc=16):  46%|████▌     | 58000/126285 [00:04<00:04, 14691.03 examples/s]Running tokenizer on dataset (num_proc=16):  50%|████▉     | 63000/126285 [00:04<00:02, 21319.56 examples/s]Running tokenizer on dataset (num_proc=16):  54%|█████▍    | 68000/126285 [00:04<00:02, 24476.53 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▌    | 71000/126285 [00:05<00:02, 24629.30 examples/s]Running tokenizer on dataset (num_proc=16):  59%|█████▊    | 74000/126285 [00:05<00:02, 21117.01 examples/s]Running tokenizer on dataset (num_proc=16):  61%|██████    | 77000/126285 [00:05<00:02, 19810.95 examples/s]Running tokenizer on dataset (num_proc=16):  67%|██████▋   | 84000/126285 [00:05<00:01, 29167.62 examples/s]Running tokenizer on dataset (num_proc=16):  70%|██████▉   | 88000/126285 [00:05<00:01, 26139.08 examples/s]Running tokenizer on dataset (num_proc=16):  73%|███████▎  | 91893/126285 [00:05<00:01, 25046.64 examples/s]Running tokenizer on dataset (num_proc=16):  76%|███████▌  | 95786/126285 [00:06<00:01, 23727.63 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 102786/126285 [00:06<00:00, 32119.29 examples/s]Running tokenizer on dataset (num_proc=16):  84%|████████▍ | 106679/126285 [00:06<00:00, 26044.83 examples/s]Running tokenizer on dataset (num_proc=16):  87%|████████▋ | 110249/126285 [00:06<00:00, 23746.27 examples/s]Running tokenizer on dataset (num_proc=16):  90%|████████▉ | 113035/126285 [00:06<00:00, 24129.23 examples/s]Running tokenizer on dataset (num_proc=16):  93%|█████████▎| 117035/126285 [00:06<00:00, 19865.49 examples/s]Running tokenizer on dataset (num_proc=16):  95%|█████████▍| 119714/126285 [00:07<00:00, 15354.06 examples/s]Running tokenizer on dataset (num_proc=16):  97%|█████████▋| 122393/126285 [00:07<00:00, 13581.77 examples/s]Running tokenizer on dataset (num_proc=16):  99%|█████████▊| 124393/126285 [00:13<00:01, 1542.73 examples/s] Running tokenizer on dataset (num_proc=16): 100%|██████████| 126285/126285 [00:20<00:00, 760.40 examples/s] Running tokenizer on dataset (num_proc=16): 100%|██████████| 126285/126285 [00:20<00:00, 6174.35 examples/s]
training example:
input_ids:
[151644, 8948, 198, 22043, 279, 4625, 10802, 323, 279, 1196, 3405, 11, 6923, 279, 12159, 7870, 3239, 13, 576, 2550, 1969, 387, 1172, 264, 2697, 7870, 3239, 11, 2041, 40841, 11, 6042, 11, 476, 4960, 1467, 13, 151645, 198, 151644, 872, 271, 58, 3540, 35839, 921, 22599, 14363, 6625, 8987, 320, 29041, 8987, 842, 9221, 11, 829, 15762, 11, 5537, 15762, 1215, 39518, 12496, 6625, 8987, 320, 29041, 8987, 842, 11, 829, 11, 5537, 8, 14710, 320, 16, 11, 364, 13079, 49628, 516, 364, 25221, 4567, 320, 17, 11, 364, 62502, 9082, 516, 364, 25018, 4667, 30776, 14363, 44788, 47067, 320, 29041, 842, 9221, 11, 6625, 8987, 842, 9221, 11, 8123, 25272, 11, 6278, 4164, 28543, 1215, 39518, 12496, 44788, 47067, 320, 29041, 842, 11, 6625, 8987, 842, 11, 8123, 11, 6278, 4164, 8, 14710, 320, 16, 11, 220, 16, 11, 220, 16, 17, 15, 11, 364, 17, 15, 17, 16, 12, 15, 16, 12, 15, 16, 4567, 320, 17, 11, 220, 16, 11, 220, 16, 20, 15, 11, 364, 17, 15, 17, 16, 12, 15, 17, 12, 15, 16, 4567, 320, 18, 11, 220, 17, 11, 220, 16, 23, 15, 11, 364, 17, 15, 17, 16, 12, 15, 16, 12, 15, 16, 1157, 58, 52428, 921, 3838, 374, 279, 2790, 8123, 315, 44788, 6088, 553, 1817, 6625, 8987, 11, 10615, 553, 6625, 8987, 5267, 151645, 198, 151644, 77091, 198, 151667, 271, 151668, 271, 4858, 6625, 8987, 842, 11, 829, 11, 30735, 74706, 8, 438, 2790, 26941, 4295, 44788, 47067, 13069, 6625, 8987, 6197, 44788, 47067, 73270, 8987, 842, 284, 6625, 8987, 73270, 8987, 842, 26870, 7710, 6625, 8987, 842, 11, 829, 15520, 7710, 2790, 26941, 16089, 26, 151645, 198]
inputs:
<|im_start|>system
Given the database schema and the user question, generate the corresponding SQL query. The output must be only a valid SQL query, without explanations, comments, or extra text.<|im_end|>
<|im_start|>user

[SCHEMA]
CREATE TABLE salesperson (salesperson_id INT, name TEXT, region TEXT); INSERT INTO salesperson (salesperson_id, name, region) VALUES (1, 'John Doe', 'North'), (2, 'Jane Smith', 'South'); CREATE TABLE timber_sales (sales_id INT, salesperson_id INT, volume REAL, sale_date DATE); INSERT INTO timber_sales (sales_id, salesperson_id, volume, sale_date) VALUES (1, 1, 120, '2021-01-01'), (2, 1, 150, '2021-02-01'), (3, 2, 180, '2021-01-01');
[QUESTION]
What is the total volume of timber sold by each salesperson, sorted by salesperson?
<|im_end|>
<|im_start|>assistant
<think>

</think>

SELECT salesperson_id, name, SUM(volume) as total_volume FROM timber_sales JOIN salesperson ON timber_sales.salesperson_id = salesperson.salesperson_id GROUP BY salesperson_id, name ORDER BY total_volume DESC;<|im_end|>

label_ids:
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 151667, 271, 151668, 271, 4858, 6625, 8987, 842, 11, 829, 11, 30735, 74706, 8, 438, 2790, 26941, 4295, 44788, 47067, 13069, 6625, 8987, 6197, 44788, 47067, 73270, 8987, 842, 284, 6625, 8987, 73270, 8987, 842, 26870, 7710, 6625, 8987, 842, 11, 829, 15520, 7710, 2790, 26941, 16089, 26, 151645, 198]
labels:
<think>

</think>

SELECT salesperson_id, name, SUM(volume) as total_volume FROM timber_sales JOIN salesperson ON timber_sales.salesperson_id = salesperson.salesperson_id GROUP BY salesperson_id, name ORDER BY total_volume DESC;<|im_end|>

[INFO|configuration_utils.py:696] 2025-08-30 13:48:43,428 >> loading configuration file /home/qianwenhao/LLM/Qwen3-1.7B/config.json
[INFO|configuration_utils.py:770] 2025-08-30 13:48:43,429 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "max_position_embeddings": 40960,
  "max_window_layers": 28,
  "model_type": "qwen3",
  "num_attention_heads": 16,
  "num_hidden_layers": 28,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|2025-08-30 13:48:43] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
[INFO|modeling_utils.py:1148] 2025-08-30 13:48:43,648 >> loading weights file /home/qianwenhao/LLM/Qwen3-1.7B/model.safetensors.index.json
[INFO|modeling_utils.py:3881] 2025-08-30 13:48:43,649 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[2025-08-30 13:48:43,649] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 4
[2025-08-30 13:48:43,773] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 4
[2025-08-30 13:48:43,780] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 4
[2025-08-30 13:48:43,781] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 4
[INFO|configuration_utils.py:1135] 2025-08-30 13:48:44,006 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "use_cache": false
}

[2025-08-30 13:48:44,334] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 311, num_elems = 2.03B
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.76it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.76it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.74it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.45it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.48it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.47it/s]

Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.78it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.54it/s]
[INFO|modeling_utils.py:5131] 2025-08-30 13:48:45,650 >> All model checkpoint weights were used when initializing Qwen3ForCausalLM.

[INFO|modeling_utils.py:5139] 2025-08-30 13:48:45,650 >> All the weights of Qwen3ForCausalLM were initialized from the model checkpoint at /home/qianwenhao/LLM/Qwen3-1.7B.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen3ForCausalLM for predictions without further training.
[INFO|configuration_utils.py:1088] 2025-08-30 13:48:45,653 >> loading configuration file /home/qianwenhao/LLM/Qwen3-1.7B/generation_config.json
[INFO|configuration_utils.py:1135] 2025-08-30 13:48:45,653 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.6,
  "top_k": 20,
  "top_p": 0.95
}

[INFO|2025-08-30 13:48:45] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
[INFO|2025-08-30 13:48:45] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
[INFO|2025-08-30 13:48:45] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
[INFO|2025-08-30 13:48:45] llamafactory.model.adapter:143 >> Fine-tuning method: LoRA
[INFO|2025-08-30 13:48:46] llamafactory.model.loader:143 >> trainable params: 6,422,528 || all params: 1,726,997,504 || trainable%: 0.3719
[INFO|trainer.py:756] 2025-08-30 13:48:46,262 >> Using auto half precision backend
[INFO|trainer.py:1257] 2025-08-30 13:48:46,567 >> skipped Embedding(151936, 2048): 0.0M params
[INFO|trainer.py:1260] 2025-08-30 13:48:46,568 >> skipped: 0.0M params
[2025-08-30 13:48:46,574] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed info: version=0.16.9, git-hash=unknown, git-branch=unknown
[2025-08-30 13:48:46,574] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 4
[2025-08-30 13:48:46,587] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-08-30 13:48:46,589] [INFO] [logging.py:107:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2025-08-30 13:48:46,589] [INFO] [logging.py:107:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-08-30 13:48:46,593] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-08-30 13:48:46,593] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'bitsandbytes.optim.adamw.AdamW'>
[2025-08-30 13:48:46,593] [WARNING] [engine.py:1338:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****
[2025-08-30 13:48:46,594] [INFO] [logging.py:107:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2025-08-30 13:48:46,594] [INFO] [logging.py:107:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[2025-08-30 13:48:46,817] [INFO] [utils.py:781:see_memory_usage] Stage 3 initialize beginning
[2025-08-30 13:48:46,818] [INFO] [utils.py:782:see_memory_usage] MA 0.81 GB         Max_MA 2.54 GB         CA 0.84 GB         Max_CA 3 GB 
[2025-08-30 13:48:46,818] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 25.38 GB, percent = 10.1%
[2025-08-30 13:48:46,821] [INFO] [stage3.py:170:__init__] Reduce bucket size 4194304
[2025-08-30 13:48:46,821] [INFO] [stage3.py:171:__init__] Prefetch bucket size 3774873
[2025-08-30 13:48:47,044] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2025-08-30 13:48:47,044] [INFO] [utils.py:782:see_memory_usage] MA 0.81 GB         Max_MA 0.81 GB         CA 0.84 GB         Max_CA 1 GB 
[2025-08-30 13:48:47,045] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 25.37 GB, percent = 10.1%
Parameter Offload: Total persistent parameters: 123904 in 113 params
[2025-08-30 13:48:47,394] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2025-08-30 13:48:47,395] [INFO] [utils.py:782:see_memory_usage] MA 0.8 GB         Max_MA 0.81 GB         CA 0.84 GB         Max_CA 1 GB 
[2025-08-30 13:48:47,395] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 25.42 GB, percent = 10.1%
[2025-08-30 13:48:47,632] [INFO] [utils.py:781:see_memory_usage] Before creating fp16 partitions
[2025-08-30 13:48:47,633] [INFO] [utils.py:782:see_memory_usage] MA 0.8 GB         Max_MA 0.8 GB         CA 0.84 GB         Max_CA 1 GB 
[2025-08-30 13:48:47,633] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 25.37 GB, percent = 10.1%
[2025-08-30 13:48:48,130] [INFO] [utils.py:781:see_memory_usage] After creating fp16 partitions: 1
[2025-08-30 13:48:48,131] [INFO] [utils.py:782:see_memory_usage] MA 0.8 GB         Max_MA 0.8 GB         CA 0.82 GB         Max_CA 1 GB 
[2025-08-30 13:48:48,131] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 25.38 GB, percent = 10.1%
[2025-08-30 13:48:48,367] [INFO] [utils.py:781:see_memory_usage] Before creating fp32 partitions
[2025-08-30 13:48:48,368] [INFO] [utils.py:782:see_memory_usage] MA 0.8 GB         Max_MA 0.8 GB         CA 0.82 GB         Max_CA 1 GB 
[2025-08-30 13:48:48,368] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 25.38 GB, percent = 10.1%
[2025-08-30 13:48:48,653] [INFO] [utils.py:781:see_memory_usage] After creating fp32 partitions
[2025-08-30 13:48:48,654] [INFO] [utils.py:782:see_memory_usage] MA 0.81 GB         Max_MA 0.81 GB         CA 0.82 GB         Max_CA 1 GB 
[2025-08-30 13:48:48,654] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 25.38 GB, percent = 10.1%
[2025-08-30 13:48:48,987] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2025-08-30 13:48:48,987] [INFO] [utils.py:782:see_memory_usage] MA 0.81 GB         Max_MA 0.81 GB         CA 0.82 GB         Max_CA 1 GB 
[2025-08-30 13:48:48,988] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 25.38 GB, percent = 10.1%
[2025-08-30 13:48:49,236] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2025-08-30 13:48:49,237] [INFO] [utils.py:782:see_memory_usage] MA 0.81 GB         Max_MA 0.82 GB         CA 0.84 GB         Max_CA 1 GB 
[2025-08-30 13:48:49,237] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 25.38 GB, percent = 10.1%
[2025-08-30 13:48:49,237] [INFO] [stage3.py:534:_setup_for_real_optimizer] optimizer state initialized
[2025-08-30 13:48:49,545] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2025-08-30 13:48:49,546] [INFO] [utils.py:782:see_memory_usage] MA 0.82 GB         Max_MA 0.82 GB         CA 0.84 GB         Max_CA 1 GB 
[2025-08-30 13:48:49,546] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 25.62 GB, percent = 10.2%
[2025-08-30 13:48:49,546] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer_Stage3
[2025-08-30 13:48:49,546] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None
[2025-08-30 13:48:49,546] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-08-30 13:48:49,546] [INFO] [logging.py:107:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]
[2025-08-30 13:48:49,548] [INFO] [config.py:1003:print] DeepSpeedEngine configuration:
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   amp_enabled .................. False
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   amp_params ................... False
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   bfloat16_enabled ............. True
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   bfloat16_immediate_grad_update  True
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   checkpoint_parallel_write_pipeline  False
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   checkpoint_tag_validation_enabled  True
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   checkpoint_tag_validation_fail  False
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f55c56bf590>
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   communication_data_type ...... None
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   compile_config ............... deepcompile=False free_activation=False offload_activation=False offload_opt_states=False double_buffer=True symmetric_memory=False debug_log=False offload_parameters=False sync_before_reduce=False sync_after_reduce=False sync_before_allgather=False sync_after_allgather=False
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   curriculum_enabled_legacy .... False
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   curriculum_params_legacy ..... False
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   data_efficiency_enabled ...... False
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   dataloader_drop_last ......... False
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   disable_allgather ............ False
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   dump_state ................... False
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   dynamic_loss_scale_args ...... None
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   eigenvalue_enabled ........... False
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   eigenvalue_gas_boundary_resolution  1
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   eigenvalue_layer_num ......... 0
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   eigenvalue_max_iter .......... 100
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   eigenvalue_stability ......... 1e-06
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   eigenvalue_tol ............... 0.01
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   eigenvalue_verbose ........... False
[2025-08-30 13:48:49,549] [INFO] [config.py:1007:print]   elasticity_enabled ........... False
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   fp16_auto_cast ............... None
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   fp16_enabled ................. False
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   fp16_master_weights_and_gradients  False
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   global_rank .................. 0
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   grad_accum_dtype ............. None
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   gradient_accumulation_steps .. 2
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   gradient_clipping ............ 1.0
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   gradient_predivide_factor .... 1.0
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   graph_harvesting ............. False
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   initial_dynamic_scale ........ 1
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   load_universal_checkpoint .... False
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   loss_scale ................... 1.0
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   memory_breakdown ............. False
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   mics_hierarchial_params_gather  False
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   mics_shard_size .............. -1
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   optimizer_legacy_fusion ...... False
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   optimizer_name ............... None
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   optimizer_params ............. None
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   pld_enabled .................. False
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   pld_params ................... False
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   prescale_gradients ........... False
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   scheduler_name ............... None
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   scheduler_params ............. None
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   seq_parallel_communication_data_type  torch.float32
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   sparse_attention ............. None
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   sparse_gradients_enabled ..... False
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   steps_per_print .............. inf
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tp_overlap_comm=False tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   timers_config ................ enabled=True synchronized=True
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   train_batch_size ............. 64
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   train_micro_batch_size_per_gpu  8
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   use_data_before_expert_parallel_  False
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   use_node_local_storage ....... False
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   wall_clock_breakdown ......... False
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   weight_quantization_config ... None
[2025-08-30 13:48:49,550] [INFO] [config.py:1007:print]   world_size ................... 4
[2025-08-30 13:48:49,551] [INFO] [config.py:1007:print]   zero_allow_untested_optimizer  True
[2025-08-30 13:48:49,551] [INFO] [config.py:1007:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=4194304 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=3774873 param_persistence_threshold=20480 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[2025-08-30 13:48:49,551] [INFO] [config.py:1007:print]   zero_enabled ................. True
[2025-08-30 13:48:49,551] [INFO] [config.py:1007:print]   zero_force_ds_cpu_optimizer .. True
[2025-08-30 13:48:49,551] [INFO] [config.py:1007:print]   zero_optimization_stage ...... 3
[2025-08-30 13:48:49,551] [INFO] [config.py:993:print_user_config]   json = {
    "train_batch_size": 64, 
    "train_micro_batch_size_per_gpu": 8, 
    "gradient_accumulation_steps": 2, 
    "gradient_clipping": 1.0, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": false, 
        "loss_scale": 0, 
        "loss_scale_window": 1000, 
        "initial_scale_power": 16, 
        "hysteresis": 2, 
        "min_loss_scale": 1
    }, 
    "bf16": {
        "enabled": true
    }, 
    "zero_optimization": {
        "stage": 3, 
        "overlap_comm": false, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09, 
        "reduce_bucket_size": 4.194304e+06, 
        "stage3_prefetch_bucket_size": 3.774873e+06, 
        "stage3_param_persistence_threshold": 2.048000e+04, 
        "stage3_max_live_parameters": 1.000000e+09, 
        "stage3_max_reuse_distance": 1.000000e+09, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "steps_per_print": inf
}
[INFO|trainer.py:2409] 2025-08-30 13:48:49,553 >> ***** Running training *****
[INFO|trainer.py:2410] 2025-08-30 13:48:49,553 >>   Num examples = 126,285
[INFO|trainer.py:2411] 2025-08-30 13:48:49,553 >>   Num Epochs = 3
[INFO|trainer.py:2412] 2025-08-30 13:48:49,553 >>   Instantaneous batch size per device = 8
[INFO|trainer.py:2415] 2025-08-30 13:48:49,553 >>   Total train batch size (w. parallel, distributed & accumulation) = 64
[INFO|trainer.py:2416] 2025-08-30 13:48:49,553 >>   Gradient Accumulation steps = 2
[INFO|trainer.py:2417] 2025-08-30 13:48:49,553 >>   Total optimization steps = 5,922
[INFO|trainer.py:2418] 2025-08-30 13:48:49,555 >>   Number of trainable parameters = 6,422,528
  0%|          | 0/5922 [00:00<?, ?it/s]  0%|          | 1/5922 [00:09<15:14:36,  9.27s/it]  0%|          | 2/5922 [00:10<7:39:09,  4.65s/it]   0%|          | 3/5922 [00:12<5:12:59,  3.17s/it]  0%|          | 4/5922 [00:14<4:26:51,  2.71s/it]  0%|          | 5/5922 [00:16<3:59:58,  2.43s/it]  0%|          | 6/5922 [00:17<3:26:50,  2.10s/it]  0%|          | 7/5922 [00:19<3:39:10,  2.22s/it]  0%|          | 8/5922 [00:21<3:14:05,  1.97s/it]  0%|          | 9/5922 [00:22<2:57:11,  1.80s/it]  0%|          | 10/5922 [00:24<2:56:27,  1.79s/it]  0%|          | 11/5922 [00:26<3:13:58,  1.97s/it]  0%|          | 12/5922 [00:29<3:24:48,  2.08s/it]  0%|          | 13/5922 [00:30<3:05:33,  1.88s/it]  0%|          | 14/5922 [00:32<3:05:32,  1.88s/it]  0%|          | 15/5922 [00:35<3:23:02,  2.06s/it]  0%|          | 16/5922 [00:36<3:03:25,  1.86s/it]  0%|          | 17/5922 [00:37<2:49:48,  1.73s/it]  0%|          | 18/5922 [00:39<2:55:35,  1.78s/it]  0%|          | 19/5922 [00:41<3:00:07,  1.83s/it]  0%|          | 20/5922 [00:43<2:52:48,  1.76s/it]  0%|          | 21/5922 [00:45<2:52:51,  1.76s/it]  0%|          | 22/5922 [00:47<3:11:05,  1.94s/it]  0%|          | 23/5922 [00:48<2:54:39,  1.78s/it]  0%|          | 24/5922 [00:50<2:47:59,  1.71s/it]  0%|          | 25/5922 [00:51<2:38:20,  1.61s/it]                                                   {'loss': 2.2675, 'grad_norm': 2.5341562209533293, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.01}
  0%|          | 25/5922 [00:51<2:38:20,  1.61s/it]  0%|          | 26/5922 [00:53<2:32:21,  1.55s/it]  0%|          | 27/5922 [00:55<2:39:52,  1.63s/it]  0%|          | 28/5922 [00:56<2:47:54,  1.71s/it]  0%|          | 29/5922 [00:58<2:46:05,  1.69s/it]  1%|          | 30/5922 [00:59<2:36:36,  1.59s/it]  1%|          | 31/5922 [01:01<2:46:07,  1.69s/it]  1%|          | 32/5922 [01:03<2:49:53,  1.73s/it]  1%|          | 33/5922 [01:05<2:56:05,  1.79s/it]  1%|          | 34/5922 [01:08<3:13:37,  1.97s/it]  1%|          | 35/5922 [01:09<3:13:35,  1.97s/it]  1%|          | 36/5922 [01:11<3:12:00,  1.96s/it]  1%|          | 37/5922 [01:14<3:20:06,  2.04s/it]  1%|          | 38/5922 [01:15<3:13:28,  1.97s/it]  1%|          | 39/5922 [01:17<3:06:35,  1.90s/it]  1%|          | 40/5922 [01:19<2:51:42,  1.75s/it]  1%|          | 41/5922 [01:20<2:44:01,  1.67s/it]  1%|          | 42/5922 [01:22<2:51:07,  1.75s/it]  1%|          | 43/5922 [01:23<2:39:35,  1.63s/it]  1%|          | 44/5922 [01:25<2:42:57,  1.66s/it]  1%|          | 45/5922 [01:27<2:54:23,  1.78s/it]  1%|          | 46/5922 [01:29<2:52:02,  1.76s/it]  1%|          | 47/5922 [01:30<2:46:51,  1.70s/it]  1%|          | 48/5922 [01:32<2:53:48,  1.78s/it]  1%|          | 49/5922 [01:35<3:10:53,  1.95s/it]  1%|          | 50/5922 [01:36<2:56:37,  1.80s/it]                                                   {'loss': 1.9089, 'grad_norm': 2.4441177558711598, 'learning_rate': 1.6333333333333335e-05, 'epoch': 0.03}
  1%|          | 50/5922 [01:36<2:56:37,  1.80s/it]  1%|          | 51/5922 [01:38<3:01:05,  1.85s/it]  1%|          | 52/5922 [01:40<3:04:57,  1.89s/it]  1%|          | 53/5922 [01:42<2:51:16,  1.75s/it]  1%|          | 54/5922 [01:44<3:07:11,  1.91s/it]  1%|          | 55/5922 [01:46<3:19:51,  2.04s/it]  1%|          | 56/5922 [01:48<3:08:43,  1.93s/it]  1%|          | 57/5922 [01:49<2:53:11,  1.77s/it]  1%|          | 58/5922 [01:51<2:46:55,  1.71s/it]  1%|          | 59/5922 [01:52<2:45:26,  1.69s/it]  1%|          | 60/5922 [01:54<2:54:02,  1.78s/it]  1%|          | 61/5922 [01:56<2:58:10,  1.82s/it]  1%|          | 62/5922 [01:58<2:44:54,  1.69s/it]  1%|          | 63/5922 [01:59<2:42:14,  1.66s/it]  1%|          | 64/5922 [02:01<2:47:41,  1.72s/it]  1%|          | 65/5922 [02:03<2:38:14,  1.62s/it]  1%|          | 66/5922 [02:04<2:31:08,  1.55s/it]  1%|          | 67/5922 [02:06<2:43:30,  1.68s/it]  1%|          | 68/5922 [02:07<2:36:21,  1.60s/it]  1%|          | 69/5922 [02:10<2:57:02,  1.81s/it]  1%|          | 70/5922 [02:11<2:44:46,  1.69s/it]  1%|          | 71/5922 [02:13<2:51:20,  1.76s/it]  1%|          | 72/5922 [02:15<2:55:32,  1.80s/it]  1%|          | 73/5922 [02:16<2:43:41,  1.68s/it]  1%|          | 74/5922 [02:19<3:04:40,  1.89s/it]  1%|▏         | 75/5922 [02:21<3:01:53,  1.87s/it]                                                   {'loss': 1.0462, 'grad_norm': 1.8787369062374184, 'learning_rate': 1.9999732603473894e-05, 'epoch': 0.04}
  1%|▏         | 75/5922 [02:21<3:01:53,  1.87s/it]  1%|▏         | 76/5922 [02:23<3:16:24,  2.02s/it]  1%|▏         | 77/5922 [02:25<3:14:16,  1.99s/it]  1%|▏         | 78/5922 [02:27<3:12:57,  1.98s/it]  1%|▏         | 79/5922 [02:29<3:16:17,  2.02s/it]  1%|▏         | 80/5922 [02:30<2:57:56,  1.83s/it]  1%|▏         | 81/5922 [02:32<3:03:59,  1.89s/it]  1%|▏         | 82/5922 [02:34<2:53:42,  1.78s/it]  1%|▏         | 83/5922 [02:36<2:55:50,  1.81s/it]  1%|▏         | 84/5922 [02:37<2:44:02,  1.69s/it]  1%|▏         | 85/5922 [02:39<2:47:27,  1.72s/it]  1%|▏         | 86/5922 [02:40<2:37:42,  1.62s/it]  1%|▏         | 87/5922 [02:42<2:45:47,  1.70s/it]  1%|▏         | 88/5922 [02:44<2:51:24,  1.76s/it]  2%|▏         | 89/5922 [02:46<2:57:40,  1.83s/it]  2%|▏         | 90/5922 [02:47<2:44:35,  1.69s/it]  2%|▏         | 91/5922 [02:49<2:36:23,  1.61s/it]  2%|▏         | 92/5922 [02:50<2:29:21,  1.54s/it]  2%|▏         | 93/5922 [02:53<2:56:00,  1.81s/it]  2%|▏         | 94/5922 [02:54<2:55:04,  1.80s/it]  2%|▏         | 95/5922 [02:56<2:43:19,  1.68s/it]  2%|▏         | 96/5922 [02:58<2:47:12,  1.72s/it]  2%|▏         | 97/5922 [03:00<3:09:22,  1.95s/it]  2%|▏         | 98/5922 [03:02<2:53:55,  1.79s/it]  2%|▏         | 99/5922 [03:04<2:58:30,  1.84s/it]  2%|▏         | 100/5922 [03:05<3:01:30,  1.87s/it]                                                    {'loss': 0.3997, 'grad_norm': 0.39175915782445153, 'learning_rate': 1.9997925014192863e-05, 'epoch': 0.05}
  2%|▏         | 100/5922 [03:05<3:01:30,  1.87s/it]  2%|▏         | 101/5922 [03:07<2:50:46,  1.76s/it]  2%|▏         | 102/5922 [03:09<3:01:02,  1.87s/it]  2%|▏         | 103/5922 [03:11<3:04:02,  1.90s/it]  2%|▏         | 104/5922 [03:13<3:04:49,  1.91s/it]  2%|▏         | 105/5922 [03:15<3:04:53,  1.91s/it]  2%|▏         | 106/5922 [03:16<2:49:57,  1.75s/it]  2%|▏         | 107/5922 [03:18<2:49:39,  1.75s/it]  2%|▏         | 108/5922 [03:19<2:40:08,  1.65s/it]  2%|▏         | 109/5922 [03:21<2:47:03,  1.72s/it]  2%|▏         | 110/5922 [03:23<2:39:57,  1.65s/it]  2%|▏         | 111/5922 [03:25<3:03:49,  1.90s/it]  2%|▏         | 112/5922 [03:27<2:52:11,  1.78s/it]  2%|▏         | 113/5922 [03:28<2:40:33,  1.66s/it]  2%|▏         | 114/5922 [03:30<2:48:42,  1.74s/it]  2%|▏         | 115/5922 [03:32<2:40:22,  1.66s/it]  2%|▏         | 116/5922 [03:33<2:47:52,  1.73s/it]  2%|▏         | 117/5922 [03:35<2:48:11,  1.74s/it]  2%|▏         | 118/5922 [03:37<2:40:52,  1.66s/it]  2%|▏         | 119/5922 [03:39<2:48:40,  1.74s/it]  2%|▏         | 120/5922 [03:40<2:47:48,  1.74s/it]  2%|▏         | 121/5922 [03:42<2:38:17,  1.64s/it]  2%|▏         | 122/5922 [03:43<2:33:52,  1.59s/it]  2%|▏         | 123/5922 [03:45<2:27:47,  1.53s/it]  2%|▏         | 124/5922 [03:46<2:25:38,  1.51s/it]  2%|▏         | 125/5922 [03:48<2:38:09,  1.64s/it]                                                    {'loss': 0.2746, 'grad_norm': 0.25558284038468637, 'learning_rate': 1.999441247990885e-05, 'epoch': 0.06}
  2%|▏         | 125/5922 [03:48<2:38:09,  1.64s/it]  2%|▏         | 126/5922 [03:50<2:58:55,  1.85s/it]  2%|▏         | 127/5922 [03:53<3:13:21,  2.00s/it]  2%|▏         | 128/5922 [03:54<2:56:23,  1.83s/it]  2%|▏         | 129/5922 [03:56<2:59:53,  1.86s/it]  2%|▏         | 130/5922 [03:58<2:46:36,  1.73s/it]  2%|▏         | 131/5922 [04:00<3:08:04,  1.95s/it]  2%|▏         | 132/5922 [04:02<3:23:47,  2.11s/it]  2%|▏         | 133/5922 [04:04<3:08:18,  1.95s/it]  2%|▏         | 134/5922 [04:05<2:51:11,  1.77s/it]  2%|▏         | 135/5922 [04:07<2:55:28,  1.82s/it]  2%|▏         | 136/5922 [04:09<2:56:02,  1.83s/it]  2%|▏         | 137/5922 [04:11<2:43:38,  1.70s/it]  2%|▏         | 138/5922 [04:12<2:40:30,  1.67s/it]  2%|▏         | 139/5922 [04:14<2:31:35,  1.57s/it]  2%|▏         | 140/5922 [04:15<2:29:54,  1.56s/it]  2%|▏         | 141/5922 [04:17<2:42:51,  1.69s/it]  2%|▏         | 142/5922 [04:20<3:04:43,  1.92s/it]  2%|▏         | 143/5922 [04:22<3:09:32,  1.97s/it]  2%|▏         | 144/5922 [04:23<2:57:20,  1.84s/it]  2%|▏         | 145/5922 [04:25<2:47:49,  1.74s/it]  2%|▏         | 146/5922 [04:27<2:52:56,  1.80s/it]  2%|▏         | 147/5922 [04:29<3:05:06,  1.92s/it]  2%|▏         | 148/5922 [04:30<2:49:12,  1.76s/it]  3%|▎         | 149/5922 [04:32<2:39:25,  1.66s/it]  3%|▎         | 150/5922 [04:33<2:34:29,  1.61s/it]                                                    {'loss': 0.2657, 'grad_norm': 0.23945525230096004, 'learning_rate': 1.998919563114672e-05, 'epoch': 0.08}
  3%|▎         | 150/5922 [04:33<2:34:29,  1.61s/it]  3%|▎         | 151/5922 [04:36<2:59:11,  1.86s/it]  3%|▎         | 152/5922 [04:37<3:01:19,  1.89s/it]  3%|▎         | 153/5922 [04:39<2:46:29,  1.73s/it]  3%|▎         | 154/5922 [04:40<2:40:34,  1.67s/it]  3%|▎         | 155/5922 [04:42<2:33:20,  1.60s/it]  3%|▎         | 156/5922 [04:43<2:36:00,  1.62s/it]  3%|▎         | 157/5922 [04:45<2:45:37,  1.72s/it]  3%|▎         | 158/5922 [04:47<2:51:22,  1.78s/it]  3%|▎         | 159/5922 [04:49<2:39:33,  1.66s/it]  3%|▎         | 160/5922 [04:51<2:43:22,  1.70s/it]  3%|▎         | 161/5922 [04:52<2:47:38,  1.75s/it]  3%|▎         | 162/5922 [04:54<2:43:29,  1.70s/it]  3%|▎         | 163/5922 [04:56<2:47:46,  1.75s/it]  3%|▎         | 164/5922 [04:57<2:42:26,  1.69s/it]  3%|▎         | 165/5922 [04:59<2:48:45,  1.76s/it]  3%|▎         | 166/5922 [05:01<2:53:34,  1.81s/it]  3%|▎         | 167/5922 [05:03<2:57:22,  1.85s/it]  3%|▎         | 168/5922 [05:05<2:45:59,  1.73s/it]  3%|▎         | 169/5922 [05:06<2:35:43,  1.62s/it]  3%|▎         | 170/5922 [05:07<2:28:32,  1.55s/it]  3%|▎         | 171/5922 [05:09<2:32:53,  1.60s/it]  3%|▎         | 172/5922 [05:11<2:42:12,  1.69s/it]  3%|▎         | 173/5922 [05:13<2:47:20,  1.75s/it]  3%|▎         | 174/5922 [05:14<2:35:49,  1.63s/it]  3%|▎         | 175/5922 [05:16<2:45:20,  1.73s/it]                                                    {'loss': 0.2486, 'grad_norm': 0.263869694711281, 'learning_rate': 1.9982275404367876e-05, 'epoch': 0.09}
  3%|▎         | 175/5922 [05:16<2:45:20,  1.73s/it]  3%|▎         | 176/5922 [05:18<2:50:38,  1.78s/it]  3%|▎         | 177/5922 [05:20<2:54:36,  1.82s/it]  3%|▎         | 178/5922 [05:21<2:42:24,  1.70s/it]  3%|▎         | 179/5922 [05:23<2:33:20,  1.60s/it]  3%|▎         | 180/5922 [05:24<2:28:13,  1.55s/it]  3%|▎         | 181/5922 [05:26<2:24:15,  1.51s/it]  3%|▎         | 182/5922 [05:27<2:26:02,  1.53s/it]  3%|▎         | 183/5922 [05:30<2:52:00,  1.80s/it]  3%|▎         | 184/5922 [05:31<2:41:24,  1.69s/it]  3%|▎         | 185/5922 [05:32<2:32:40,  1.60s/it]  3%|▎         | 186/5922 [05:34<2:42:16,  1.70s/it]  3%|▎         | 187/5922 [05:36<2:49:15,  1.77s/it]  3%|▎         | 188/5922 [05:38<2:43:29,  1.71s/it]  3%|▎         | 189/5922 [05:40<2:49:36,  1.78s/it]  3%|▎         | 190/5922 [05:42<2:54:25,  1.83s/it]  3%|▎         | 191/5922 [05:43<2:47:56,  1.76s/it]  3%|▎         | 192/5922 [05:46<3:06:22,  1.95s/it]  3%|▎         | 193/5922 [05:47<2:49:48,  1.78s/it]  3%|▎         | 194/5922 [05:49<2:39:55,  1.68s/it]  3%|▎         | 195/5922 [05:51<3:02:47,  1.91s/it]  3%|▎         | 196/5922 [05:53<2:59:57,  1.89s/it]  3%|▎         | 197/5922 [05:54<2:50:26,  1.79s/it]  3%|▎         | 198/5922 [05:56<2:54:19,  1.83s/it]  3%|▎         | 199/5922 [05:58<2:47:42,  1.76s/it]  3%|▎         | 200/5922 [06:00<3:06:06,  1.95s/it]                                                    {'loss': 0.2458, 'grad_norm': 0.3139956465797477, 'learning_rate': 1.9973653041802177e-05, 'epoch': 0.1}
  3%|▎         | 200/5922 [06:00<3:06:06,  1.95s/it]  3%|▎         | 201/5922 [06:02<3:07:11,  1.96s/it]  3%|▎         | 202/5922 [06:04<3:05:26,  1.95s/it]  3%|▎         | 203/5922 [06:06<3:06:08,  1.95s/it]  3%|▎         | 204/5922 [06:08<3:05:59,  1.95s/it]  3%|▎         | 205/5922 [06:10<3:01:09,  1.90s/it]  3%|▎         | 206/5922 [06:12<3:03:19,  1.92s/it]  3%|▎         | 207/5922 [06:14<3:06:52,  1.96s/it]  4%|▎         | 208/5922 [06:15<2:51:46,  1.80s/it]  4%|▎         | 209/5922 [06:17<2:44:42,  1.73s/it]  4%|▎         | 210/5922 [06:19<2:40:50,  1.69s/it]  4%|▎         | 211/5922 [06:20<2:32:46,  1.60s/it]  4%|▎         | 212/5922 [06:21<2:27:47,  1.55s/it]  4%|▎         | 213/5922 [06:23<2:42:22,  1.71s/it]  4%|▎         | 214/5922 [06:25<2:49:52,  1.79s/it]  4%|▎         | 215/5922 [06:27<2:48:14,  1.77s/it]  4%|▎         | 216/5922 [06:29<2:37:27,  1.66s/it]  4%|▎         | 217/5922 [06:31<2:45:42,  1.74s/it]  4%|▎         | 218/5922 [06:32<2:52:00,  1.81s/it]  4%|▎         | 219/5922 [06:34<2:40:33,  1.69s/it]  4%|▎         | 220/5922 [06:36<2:50:51,  1.80s/it]  4%|▎         | 221/5922 [06:37<2:39:53,  1.68s/it]  4%|▎         | 222/5922 [06:39<2:31:07,  1.59s/it]  4%|▍         | 223/5922 [06:40<2:35:45,  1.64s/it]  4%|▍         | 224/5922 [06:42<2:43:09,  1.72s/it]  4%|▍         | 225/5922 [06:44<2:33:53,  1.62s/it]                                                    {'loss': 0.232, 'grad_norm': 0.39121714624268744, 'learning_rate': 1.996333009122495e-05, 'epoch': 0.11}
  4%|▍         | 225/5922 [06:44<2:33:53,  1.62s/it]  4%|▍         | 226/5922 [06:45<2:27:41,  1.56s/it]  4%|▍         | 227/5922 [06:47<2:36:16,  1.65s/it]  4%|▍         | 228/5922 [06:49<2:43:57,  1.73s/it]  4%|▍         | 229/5922 [06:51<2:50:35,  1.80s/it]  4%|▍         | 230/5922 [06:53<3:00:21,  1.90s/it]  4%|▍         | 231/5922 [06:55<2:50:40,  1.80s/it]  4%|▍         | 232/5922 [06:57<2:54:50,  1.84s/it]  4%|▍         | 233/5922 [06:58<2:42:29,  1.71s/it]  4%|▍         | 234/5922 [06:59<2:34:04,  1.63s/it]  4%|▍         | 235/5922 [07:01<2:38:47,  1.68s/it]  4%|▍         | 236/5922 [07:03<2:44:52,  1.74s/it]  4%|▍         | 237/5922 [07:04<2:34:53,  1.63s/it]  4%|▍         | 238/5922 [07:06<2:32:58,  1.61s/it]  4%|▍         | 239/5922 [07:08<2:31:13,  1.60s/it]  4%|▍         | 240/5922 [07:09<2:31:00,  1.59s/it]  4%|▍         | 241/5922 [07:11<2:35:40,  1.64s/it]  4%|▍         | 242/5922 [07:13<2:43:32,  1.73s/it]  4%|▍         | 243/5922 [07:15<3:04:41,  1.95s/it]  4%|▍         | 244/5922 [07:17<2:49:13,  1.79s/it]  4%|▍         | 245/5922 [07:18<2:38:50,  1.68s/it]  4%|▍         | 246/5922 [07:20<2:42:41,  1.72s/it]  4%|▍         | 247/5922 [07:22<2:47:27,  1.77s/it]  4%|▍         | 248/5922 [07:23<2:36:26,  1.65s/it]  4%|▍         | 249/5922 [07:25<2:40:23,  1.70s/it]  4%|▍         | 250/5922 [07:27<2:45:50,  1.75s/it]                                                    {'loss': 0.2153, 'grad_norm': 0.2441369523538509, 'learning_rate': 1.995130840567915e-05, 'epoch': 0.13}
  4%|▍         | 250/5922 [07:27<2:45:50,  1.75s/it]  4%|▍         | 251/5922 [07:29<2:49:48,  1.80s/it]  4%|▍         | 252/5922 [07:31<2:53:51,  1.84s/it]  4%|▍         | 253/5922 [07:32<2:49:10,  1.79s/it]  4%|▍         | 254/5922 [07:35<3:02:54,  1.94s/it]  4%|▍         | 255/5922 [07:36<2:47:25,  1.77s/it]  4%|▍         | 256/5922 [07:38<2:37:02,  1.66s/it]  4%|▍         | 257/5922 [07:39<2:40:41,  1.70s/it]  4%|▍         | 258/5922 [07:41<2:51:49,  1.82s/it]  4%|▍         | 259/5922 [07:43<2:54:55,  1.85s/it]  4%|▍         | 260/5922 [07:46<3:04:01,  1.95s/it]  4%|▍         | 261/5922 [07:47<2:56:28,  1.87s/it]  4%|▍         | 262/5922 [07:49<2:47:38,  1.78s/it]  4%|▍         | 263/5922 [07:51<3:04:26,  1.96s/it]  4%|▍         | 264/5922 [07:53<3:01:50,  1.93s/it]  4%|▍         | 265/5922 [07:54<2:47:05,  1.77s/it]  4%|▍         | 266/5922 [07:56<2:47:56,  1.78s/it]  5%|▍         | 267/5922 [07:58<2:47:35,  1.78s/it]  5%|▍         | 268/5922 [07:59<2:37:08,  1.67s/it]  5%|▍         | 269/5922 [08:01<2:48:36,  1.79s/it]  5%|▍         | 270/5922 [08:03<2:47:06,  1.77s/it]  5%|▍         | 271/5922 [08:05<2:36:36,  1.66s/it]  5%|▍         | 272/5922 [08:07<2:57:53,  1.89s/it]  5%|▍         | 273/5922 [08:08<2:45:44,  1.76s/it]  5%|▍         | 274/5922 [08:11<2:53:51,  1.85s/it]  5%|▍         | 275/5922 [08:12<2:42:16,  1.72s/it]                                                    {'loss': 0.2111, 'grad_norm': 0.2862153387587539, 'learning_rate': 1.9937590143142716e-05, 'epoch': 0.14}
  5%|▍         | 275/5922 [08:12<2:42:16,  1.72s/it]  5%|▍         | 276/5922 [08:14<2:49:39,  1.80s/it]  5%|▍         | 277/5922 [08:16<2:53:07,  1.84s/it]  5%|▍         | 278/5922 [08:18<2:54:39,  1.86s/it]  5%|▍         | 279/5922 [08:20<2:56:24,  1.88s/it]  5%|▍         | 280/5922 [08:22<2:59:55,  1.91s/it]  5%|▍         | 281/5922 [08:24<3:01:34,  1.93s/it]  5%|▍         | 282/5922 [08:26<3:01:39,  1.93s/it]  5%|▍         | 283/5922 [08:28<3:01:53,  1.94s/it]  5%|▍         | 284/5922 [08:29<3:00:18,  1.92s/it]  5%|▍         | 285/5922 [08:32<3:15:38,  2.08s/it]  5%|▍         | 286/5922 [08:34<3:11:01,  2.03s/it]  5%|▍         | 287/5922 [08:36<3:09:38,  2.02s/it]  5%|▍         | 288/5922 [08:38<3:06:06,  1.98s/it]  5%|▍         | 289/5922 [08:40<3:07:43,  2.00s/it]  5%|▍         | 290/5922 [08:41<2:51:34,  1.83s/it]  5%|▍         | 291/5922 [08:44<3:09:26,  2.02s/it]  5%|▍         | 292/5922 [08:46<3:07:43,  2.00s/it]  5%|▍         | 293/5922 [08:48<3:06:44,  1.99s/it]  5%|▍         | 294/5922 [08:49<2:57:17,  1.89s/it]  5%|▍         | 295/5922 [08:51<3:01:20,  1.93s/it]  5%|▍         | 296/5922 [08:53<2:58:35,  1.90s/it]  5%|▌         | 297/5922 [08:55<2:59:48,  1.92s/it]  5%|▌         | 298/5922 [08:57<3:01:07,  1.93s/it]  5%|▌         | 299/5922 [08:59<3:01:04,  1.93s/it]  5%|▌         | 300/5922 [09:01<2:59:06,  1.91s/it]                                                    {'loss': 0.2258, 'grad_norm': 0.32461818148697924, 'learning_rate': 1.9922177766141214e-05, 'epoch': 0.15}
  5%|▌         | 300/5922 [09:01<2:59:06,  1.91s/it]  5%|▌         | 301/5922 [09:03<3:00:29,  1.93s/it]  5%|▌         | 302/5922 [09:04<2:45:37,  1.77s/it]  5%|▌         | 303/5922 [09:06<2:50:03,  1.82s/it]  5%|▌         | 304/5922 [09:08<2:54:03,  1.86s/it]  5%|▌         | 305/5922 [09:09<2:40:55,  1.72s/it]  5%|▌         | 306/5922 [09:11<2:32:50,  1.63s/it]  5%|▌         | 307/5922 [09:13<2:41:25,  1.72s/it]  5%|▌         | 308/5922 [09:14<2:31:18,  1.62s/it]  5%|▌         | 309/5922 [09:17<2:51:44,  1.84s/it]  5%|▌         | 310/5922 [09:18<2:42:59,  1.74s/it]  5%|▌         | 311/5922 [09:20<2:58:45,  1.91s/it]  5%|▌         | 312/5922 [09:22<2:50:26,  1.82s/it]  5%|▌         | 313/5922 [09:24<3:04:32,  1.97s/it]  5%|▌         | 314/5922 [09:26<3:01:05,  1.94s/it]  5%|▌         | 315/5922 [09:28<2:46:08,  1.78s/it]  5%|▌         | 316/5922 [09:29<2:44:45,  1.76s/it]  5%|▌         | 317/5922 [09:31<2:34:39,  1.66s/it]  5%|▌         | 318/5922 [09:33<2:42:30,  1.74s/it]  5%|▌         | 319/5922 [09:35<2:47:23,  1.79s/it]  5%|▌         | 320/5922 [09:36<2:50:50,  1.83s/it]  5%|▌         | 321/5922 [09:38<2:39:16,  1.71s/it]  5%|▌         | 322/5922 [09:39<2:31:46,  1.63s/it]  5%|▌         | 323/5922 [09:41<2:38:43,  1.70s/it]  5%|▌         | 324/5922 [09:43<2:45:01,  1.77s/it]  5%|▌         | 325/5922 [09:45<2:34:43,  1.66s/it]                                                    {'loss': 0.2041, 'grad_norm': 0.31253549195106106, 'learning_rate': 1.990507404130579e-05, 'epoch': 0.16}
  5%|▌         | 325/5922 [09:45<2:34:43,  1.66s/it]  6%|▌         | 326/5922 [09:46<2:42:26,  1.74s/it]  6%|▌         | 327/5922 [09:49<2:57:39,  1.91s/it]  6%|▌         | 328/5922 [09:51<2:55:16,  1.88s/it]  6%|▌         | 329/5922 [09:52<2:56:36,  1.89s/it]  6%|▌         | 330/5922 [09:54<2:41:49,  1.74s/it]  6%|▌         | 331/5922 [09:56<2:53:24,  1.86s/it]  6%|▌         | 332/5922 [09:58<2:55:48,  1.89s/it]  6%|▌         | 333/5922 [09:59<2:44:14,  1.76s/it]  6%|▌         | 334/5922 [10:02<3:00:18,  1.94s/it]  6%|▌         | 335/5922 [10:03<2:46:16,  1.79s/it]  6%|▌         | 336/5922 [10:06<3:05:14,  1.99s/it]  6%|▌         | 337/5922 [10:08<3:03:16,  1.97s/it]  6%|▌         | 338/5922 [10:10<3:05:56,  2.00s/it]  6%|▌         | 339/5922 [10:11<3:00:10,  1.94s/it]  6%|▌         | 340/5922 [10:13<2:47:18,  1.80s/it]  6%|▌         | 341/5922 [10:15<2:51:30,  1.84s/it]  6%|▌         | 342/5922 [10:16<2:39:06,  1.71s/it]  6%|▌         | 343/5922 [10:19<2:54:08,  1.87s/it]  6%|▌         | 344/5922 [10:20<2:55:01,  1.88s/it]  6%|▌         | 345/5922 [10:22<2:51:34,  1.85s/it]  6%|▌         | 346/5922 [10:24<2:39:50,  1.72s/it]  6%|▌         | 347/5922 [10:25<2:31:52,  1.63s/it]  6%|▌         | 348/5922 [10:26<2:26:27,  1.58s/it]  6%|▌         | 349/5922 [10:28<2:26:57,  1.58s/it]  6%|▌         | 350/5922 [10:30<2:33:07,  1.65s/it]                                                    {'loss': 0.2209, 'grad_norm': 0.33645053159930777, 'learning_rate': 1.9886282038876536e-05, 'epoch': 0.18}
  6%|▌         | 350/5922 [10:30<2:33:07,  1.65s/it]  6%|▌         | 351/5922 [10:32<2:32:33,  1.64s/it]  6%|▌         | 352/5922 [10:34<2:52:42,  1.86s/it]  6%|▌         | 353/5922 [10:36<2:54:51,  1.88s/it]  6%|▌         | 354/5922 [10:38<2:56:06,  1.90s/it]  6%|▌         | 355/5922 [10:40<2:58:21,  1.92s/it]  6%|▌         | 356/5922 [10:41<2:48:43,  1.82s/it]  6%|▌         | 357/5922 [10:43<2:40:04,  1.73s/it]  6%|▌         | 358/5922 [10:45<2:46:26,  1.79s/it]  6%|▌         | 359/5922 [10:46<2:36:33,  1.69s/it]  6%|▌         | 360/5922 [10:48<2:44:13,  1.77s/it]  6%|▌         | 361/5922 [10:50<2:34:44,  1.67s/it]  6%|▌         | 362/5922 [10:51<2:28:19,  1.60s/it]  6%|▌         | 363/5922 [10:53<2:27:23,  1.59s/it]  6%|▌         | 364/5922 [10:54<2:23:14,  1.55s/it]  6%|▌         | 365/5922 [10:56<2:34:04,  1.66s/it]  6%|▌         | 366/5922 [10:57<2:27:19,  1.59s/it]  6%|▌         | 367/5922 [10:59<2:21:46,  1.53s/it]  6%|▌         | 368/5922 [11:01<2:39:11,  1.72s/it]  6%|▌         | 369/5922 [11:02<2:30:03,  1.62s/it]  6%|▌         | 370/5922 [11:04<2:24:11,  1.56s/it]  6%|▋         | 371/5922 [11:06<2:35:20,  1.68s/it]  6%|▋         | 372/5922 [11:07<2:28:35,  1.61s/it]  6%|▋         | 373/5922 [11:09<2:47:14,  1.81s/it]  6%|▋         | 374/5922 [11:11<2:51:40,  1.86s/it]  6%|▋         | 375/5922 [11:13<2:44:39,  1.78s/it]                                                    {'loss': 0.1809, 'grad_norm': 0.2451686852896239, 'learning_rate': 1.986580513215137e-05, 'epoch': 0.19}
  6%|▋         | 375/5922 [11:13<2:44:39,  1.78s/it]  6%|▋         | 376/5922 [11:14<2:33:49,  1.66s/it]  6%|▋         | 377/5922 [11:16<2:28:13,  1.60s/it]  6%|▋         | 378/5922 [11:17<2:24:04,  1.56s/it]  6%|▋         | 379/5922 [11:19<2:38:39,  1.72s/it]  6%|▋         | 380/5922 [11:21<2:34:07,  1.67s/it]  6%|▋         | 381/5922 [11:23<2:33:14,  1.66s/it]  6%|▋         | 382/5922 [11:24<2:36:51,  1.70s/it]  6%|▋         | 383/5922 [11:26<2:42:42,  1.76s/it]  6%|▋         | 384/5922 [11:28<2:50:49,  1.85s/it]  7%|▋         | 385/5922 [11:30<2:39:09,  1.72s/it]  7%|▋         | 386/5922 [11:31<2:34:45,  1.68s/it]  7%|▋         | 387/5922 [11:33<2:41:56,  1.76s/it]  7%|▋         | 388/5922 [11:35<2:46:08,  1.80s/it]  7%|▋         | 389/5922 [11:37<2:49:47,  1.84s/it]  7%|▋         | 390/5922 [11:39<2:50:27,  1.85s/it]  7%|▋         | 391/5922 [11:40<2:37:45,  1.71s/it]  7%|▋         | 392/5922 [11:43<2:58:11,  1.93s/it]  7%|▋         | 393/5922 [11:44<2:44:05,  1.78s/it]  7%|▋         | 394/5922 [11:46<2:34:43,  1.68s/it]  7%|▋         | 395/5922 [11:47<2:32:29,  1.66s/it]  7%|▋         | 396/5922 [11:49<2:28:49,  1.62s/it]  7%|▋         | 397/5922 [11:50<2:23:06,  1.55s/it]  7%|▋         | 398/5922 [11:52<2:33:05,  1.66s/it]  7%|▋         | 399/5922 [11:54<2:37:59,  1.72s/it]  7%|▋         | 400/5922 [11:57<2:59:21,  1.95s/it]                                                    {'loss': 0.1954, 'grad_norm': 1.410725355335053, 'learning_rate': 1.984364699688049e-05, 'epoch': 0.2}
  7%|▋         | 400/5922 [11:57<2:59:21,  1.95s/it]  7%|▋         | 401/5922 [11:58<2:56:40,  1.92s/it]  7%|▋         | 402/5922 [12:00<2:54:43,  1.90s/it]  7%|▋         | 403/5922 [12:02<2:56:21,  1.92s/it]  7%|▋         | 404/5922 [12:04<2:49:02,  1.84s/it]  7%|▋         | 405/5922 [12:06<2:52:08,  1.87s/it]  7%|▋         | 406/5922 [12:08<3:03:31,  2.00s/it]  7%|▋         | 407/5922 [12:10<2:59:25,  1.95s/it]  7%|▋         | 408/5922 [12:12<2:59:28,  1.95s/it]  7%|▋         | 409/5922 [12:13<2:48:18,  1.83s/it]  7%|▋         | 410/5922 [12:15<2:48:27,  1.83s/it]  7%|▋         | 411/5922 [12:17<2:38:32,  1.73s/it]  7%|▋         | 412/5922 [12:19<2:49:33,  1.85s/it]  7%|▋         | 413/5922 [12:20<2:37:59,  1.72s/it]  7%|▋         | 414/5922 [12:22<2:44:39,  1.79s/it]  7%|▋         | 415/5922 [12:24<2:50:13,  1.85s/it]  7%|▋         | 416/5922 [12:26<2:53:15,  1.89s/it]  7%|▋         | 417/5922 [12:28<2:54:38,  1.90s/it]  7%|▋         | 418/5922 [12:30<2:42:30,  1.77s/it]  7%|▋         | 419/5922 [12:31<2:34:01,  1.68s/it]  7%|▋         | 420/5922 [12:33<2:38:19,  1.73s/it]  7%|▋         | 421/5922 [12:34<2:33:17,  1.67s/it]  7%|▋         | 422/5922 [12:36<2:31:40,  1.65s/it]  7%|▋         | 423/5922 [12:38<2:26:57,  1.60s/it]  7%|▋         | 424/5922 [12:39<2:35:25,  1.70s/it]  7%|▋         | 425/5922 [12:41<2:44:22,  1.79s/it]                                                    {'loss': 0.2027, 'grad_norm': 0.3040340021953319, 'learning_rate': 1.9819811610606566e-05, 'epoch': 0.22}
  7%|▋         | 425/5922 [12:41<2:44:22,  1.79s/it]  7%|▋         | 426/5922 [12:43<2:42:11,  1.77s/it]  7%|▋         | 427/5922 [12:45<2:41:29,  1.76s/it]  7%|▋         | 428/5922 [12:47<2:37:51,  1.72s/it]  7%|▋         | 429/5922 [12:49<2:49:51,  1.86s/it]  7%|▋         | 430/5922 [12:51<3:09:49,  2.07s/it]  7%|▋         | 431/5922 [12:53<2:58:37,  1.95s/it]  7%|▋         | 432/5922 [12:55<2:53:54,  1.90s/it]  7%|▋         | 433/5922 [12:57<2:58:12,  1.95s/it]  7%|▋         | 434/5922 [12:59<3:02:03,  1.99s/it]  7%|▋         | 435/5922 [13:00<2:48:55,  1.85s/it]  7%|▋         | 436/5922 [13:02<2:51:27,  1.88s/it]  7%|▋         | 437/5922 [13:04<2:53:41,  1.90s/it]  7%|▋         | 438/5922 [13:06<2:46:27,  1.82s/it]  7%|▋         | 439/5922 [13:08<2:52:01,  1.88s/it]  7%|▋         | 440/5922 [13:10<2:53:58,  1.90s/it]  7%|▋         | 441/5922 [13:12<2:56:55,  1.94s/it]  7%|▋         | 442/5922 [13:14<3:08:27,  2.06s/it]  7%|▋         | 443/5922 [13:16<3:03:19,  2.01s/it]  7%|▋         | 444/5922 [13:18<3:06:27,  2.04s/it]  8%|▊         | 445/5922 [13:20<2:56:46,  1.94s/it]  8%|▊         | 446/5922 [13:22<2:48:35,  1.85s/it]  8%|▊         | 447/5922 [13:23<2:46:05,  1.82s/it]  8%|▊         | 448/5922 [13:25<2:47:26,  1.84s/it]  8%|▊         | 449/5922 [13:27<2:41:07,  1.77s/it]  8%|▊         | 450/5922 [13:28<2:32:01,  1.67s/it]                                                    {'loss': 0.1887, 'grad_norm': 0.2829340514974644, 'learning_rate': 1.979430325195074e-05, 'epoch': 0.23}
  8%|▊         | 450/5922 [13:28<2:32:01,  1.67s/it]  8%|▊         | 451/5922 [13:30<2:40:11,  1.76s/it]  8%|▊         | 452/5922 [13:32<2:38:35,  1.74s/it]  8%|▊         | 453/5922 [13:34<2:48:21,  1.85s/it]  8%|▊         | 454/5922 [13:36<2:40:40,  1.76s/it]  8%|▊         | 455/5922 [13:38<2:53:37,  1.91s/it]  8%|▊         | 456/5922 [13:39<2:42:56,  1.79s/it]  8%|▊         | 457/5922 [13:41<2:34:09,  1.69s/it]  8%|▊         | 458/5922 [13:43<2:55:55,  1.93s/it]  8%|▊         | 459/5922 [13:46<3:06:30,  2.05s/it]  8%|▊         | 460/5922 [13:47<2:54:00,  1.91s/it]  8%|▊         | 461/5922 [13:49<2:50:13,  1.87s/it]  8%|▊         | 462/5922 [13:51<2:55:43,  1.93s/it]  8%|▊         | 463/5922 [13:53<2:59:34,  1.97s/it]  8%|▊         | 464/5922 [13:55<2:54:07,  1.91s/it]  8%|▊         | 465/5922 [13:57<2:50:14,  1.87s/it]  8%|▊         | 466/5922 [13:58<2:45:58,  1.83s/it]  8%|▊         | 467/5922 [14:00<2:45:29,  1.82s/it]  8%|▊         | 468/5922 [14:02<2:41:27,  1.78s/it]  8%|▊         | 469/5922 [14:04<2:42:13,  1.79s/it]  8%|▊         | 470/5922 [14:05<2:34:39,  1.70s/it]  8%|▊         | 471/5922 [14:07<2:42:38,  1.79s/it]  8%|▊         | 472/5922 [14:09<2:47:50,  1.85s/it]  8%|▊         | 473/5922 [14:11<2:37:39,  1.74s/it]  8%|▊         | 474/5922 [14:13<2:43:48,  1.80s/it]  8%|▊         | 475/5922 [14:15<2:47:54,  1.85s/it]                                                    {'loss': 0.1815, 'grad_norm': 0.27133107125181183, 'learning_rate': 1.9767126499844564e-05, 'epoch': 0.24}
  8%|▊         | 475/5922 [14:15<2:47:54,  1.85s/it]  8%|▊         | 476/5922 [14:16<2:38:16,  1.74s/it]  8%|▊         | 477/5922 [14:18<2:46:30,  1.83s/it]  8%|▊         | 478/5922 [14:20<2:35:39,  1.72s/it]  8%|▊         | 479/5922 [14:22<2:53:12,  1.91s/it]  8%|▊         | 480/5922 [14:24<2:46:22,  1.83s/it]  8%|▊         | 481/5922 [14:26<2:49:11,  1.87s/it]  8%|▊         | 482/5922 [14:27<2:38:32,  1.75s/it]  8%|▊         | 483/5922 [14:29<2:32:23,  1.68s/it]  8%|▊         | 484/5922 [14:30<2:25:51,  1.61s/it]  8%|▊         | 485/5922 [14:32<2:23:15,  1.58s/it]  8%|▊         | 486/5922 [14:33<2:21:09,  1.56s/it]  8%|▊         | 487/5922 [14:35<2:32:43,  1.69s/it]  8%|▊         | 488/5922 [14:37<2:37:58,  1.74s/it]  8%|▊         | 489/5922 [14:39<2:42:23,  1.79s/it]  8%|▊         | 490/5922 [14:41<2:56:49,  1.95s/it]  8%|▊         | 491/5922 [14:43<2:54:24,  1.93s/it]  8%|▊         | 492/5922 [14:45<2:56:04,  1.95s/it]  8%|▊         | 493/5922 [14:47<2:57:03,  1.96s/it]  8%|▊         | 494/5922 [14:49<3:03:18,  2.03s/it]  8%|▊         | 495/5922 [14:51<2:50:18,  1.88s/it]  8%|▊         | 496/5922 [14:53<2:56:27,  1.95s/it]  8%|▊         | 497/5922 [14:55<2:51:38,  1.90s/it]  8%|▊         | 498/5922 [14:57<2:55:12,  1.94s/it]  8%|▊         | 499/5922 [14:58<2:43:31,  1.81s/it]  8%|▊         | 500/5922 [15:00<2:46:49,  1.85s/it]                                                    {'loss': 0.1793, 'grad_norm': 0.2684892864670811, 'learning_rate': 1.9738286232708084e-05, 'epoch': 0.25}
  8%|▊         | 500/5922 [15:00<2:46:49,  1.85s/it][INFO|trainer.py:3993] 2025-08-30 14:03:52,890 >> Saving model checkpoint to saves/qwen3-1.7B/lora/sft/checkpoint-500
[INFO|configuration_utils.py:696] 2025-08-30 14:03:52,904 >> loading configuration file /home/qianwenhao/LLM/Qwen3-1.7B/config.json
[INFO|configuration_utils.py:770] 2025-08-30 14:03:52,905 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "max_position_embeddings": 40960,
  "max_window_layers": 28,
  "model_type": "qwen3",
  "num_attention_heads": 16,
  "num_hidden_layers": 28,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|tokenization_utils_base.py:2356] 2025-08-30 14:03:52,923 >> chat template saved in saves/qwen3-1.7B/lora/sft/checkpoint-500/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-08-30 14:03:52,924 >> tokenizer config file saved in saves/qwen3-1.7B/lora/sft/checkpoint-500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-08-30 14:03:52,924 >> Special tokens file saved in saves/qwen3-1.7B/lora/sft/checkpoint-500/special_tokens_map.json
[2025-08-30 14:03:53,110] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step500 is about to be saved!
[2025-08-30 14:03:53,119] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: saves/qwen3-1.7B/lora/sft/checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-08-30 14:03:53,119] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-08-30 14:03:53,125] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-08-30 14:03:53,126] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-500/global_step500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-08-30 14:03:53,138] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-500/global_step500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-08-30 14:03:53,138] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved saves/qwen3-1.7B/lora/sft/checkpoint-500/global_step500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-08-30 14:03:53,149] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
  8%|▊         | 501/5922 [15:05<4:10:21,  2.77s/it]  8%|▊         | 502/5922 [15:07<3:48:57,  2.53s/it]  8%|▊         | 503/5922 [15:09<3:34:05,  2.37s/it]  9%|▊         | 504/5922 [15:11<3:32:23,  2.35s/it]  9%|▊         | 505/5922 [15:14<3:35:20,  2.39s/it]  9%|▊         | 506/5922 [15:16<3:23:03,  2.25s/it]  9%|▊         | 507/5922 [15:17<3:02:08,  2.02s/it]  9%|▊         | 508/5922 [15:19<2:54:31,  1.93s/it]  9%|▊         | 509/5922 [15:20<2:42:18,  1.80s/it]  9%|▊         | 510/5922 [15:22<2:46:22,  1.84s/it]  9%|▊         | 511/5922 [15:24<2:34:59,  1.72s/it]  9%|▊         | 512/5922 [15:25<2:27:22,  1.63s/it]  9%|▊         | 513/5922 [15:27<2:23:37,  1.59s/it]  9%|▊         | 514/5922 [15:28<2:17:53,  1.53s/it]  9%|▊         | 515/5922 [15:29<2:13:18,  1.48s/it]  9%|▊         | 516/5922 [15:31<2:25:58,  1.62s/it]  9%|▊         | 517/5922 [15:33<2:34:05,  1.71s/it]  9%|▊         | 518/5922 [15:35<2:41:38,  1.79s/it]  9%|▉         | 519/5922 [15:37<2:30:43,  1.67s/it]  9%|▉         | 520/5922 [15:39<2:37:00,  1.74s/it]  9%|▉         | 521/5922 [15:40<2:27:12,  1.64s/it]  9%|▉         | 522/5922 [15:41<2:20:46,  1.56s/it]  9%|▉         | 523/5922 [15:43<2:30:36,  1.67s/it]  9%|▉         | 524/5922 [15:45<2:22:24,  1.58s/it]  9%|▉         | 525/5922 [15:47<2:31:49,  1.69s/it]                                                    {'loss': 0.1865, 'grad_norm': 0.301868386016056, 'learning_rate': 1.97077876275741e-05, 'epoch': 0.27}
  9%|▉         | 525/5922 [15:47<2:31:49,  1.69s/it]  9%|▉         | 526/5922 [15:49<2:38:14,  1.76s/it]  9%|▉         | 527/5922 [15:50<2:37:03,  1.75s/it]  9%|▉         | 528/5922 [15:52<2:29:12,  1.66s/it]  9%|▉         | 529/5922 [15:53<2:24:10,  1.60s/it]  9%|▉         | 530/5922 [15:55<2:42:43,  1.81s/it]  9%|▉         | 531/5922 [15:57<2:32:10,  1.69s/it]  9%|▉         | 532/5922 [15:58<2:23:57,  1.60s/it]  9%|▉         | 533/5922 [16:00<2:18:27,  1.54s/it]  9%|▉         | 534/5922 [16:01<2:18:20,  1.54s/it]  9%|▉         | 535/5922 [16:03<2:19:03,  1.55s/it]  9%|▉         | 536/5922 [16:05<2:43:31,  1.82s/it]  9%|▉         | 537/5922 [16:07<2:47:09,  1.86s/it]  9%|▉         | 538/5922 [16:09<2:52:44,  1.93s/it]  9%|▉         | 539/5922 [16:11<2:52:16,  1.92s/it]  9%|▉         | 540/5922 [16:13<2:38:21,  1.77s/it]  9%|▉         | 541/5922 [16:14<2:30:58,  1.68s/it]  9%|▉         | 542/5922 [16:16<2:25:42,  1.62s/it]  9%|▉         | 543/5922 [16:17<2:20:31,  1.57s/it]  9%|▉         | 544/5922 [16:19<2:29:37,  1.67s/it]  9%|▉         | 545/5922 [16:21<2:37:43,  1.76s/it]  9%|▉         | 546/5922 [16:23<2:42:47,  1.82s/it]  9%|▉         | 547/5922 [16:25<2:42:45,  1.82s/it]  9%|▉         | 548/5922 [16:26<2:34:19,  1.72s/it]  9%|▉         | 549/5922 [16:28<2:40:02,  1.79s/it]  9%|▉         | 550/5922 [16:29<2:28:57,  1.66s/it]                                                    {'loss': 0.1752, 'grad_norm': 0.29352933145279003, 'learning_rate': 1.9675636159158853e-05, 'epoch': 0.28}
  9%|▉         | 550/5922 [16:29<2:28:57,  1.66s/it]  9%|▉         | 551/5922 [16:31<2:35:52,  1.74s/it]  9%|▉         | 552/5922 [16:33<2:26:20,  1.64s/it]  9%|▉         | 553/5922 [16:34<2:24:18,  1.61s/it]  9%|▉         | 554/5922 [16:36<2:18:43,  1.55s/it]  9%|▉         | 555/5922 [16:38<2:42:52,  1.82s/it]  9%|▉         | 556/5922 [16:40<2:45:43,  1.85s/it]  9%|▉         | 557/5922 [16:42<2:34:23,  1.73s/it]  9%|▉         | 558/5922 [16:43<2:26:27,  1.64s/it]  9%|▉         | 559/5922 [16:45<2:33:56,  1.72s/it]  9%|▉         | 560/5922 [16:47<2:50:03,  1.90s/it]  9%|▉         | 561/5922 [16:49<2:50:55,  1.91s/it]  9%|▉         | 562/5922 [16:51<2:40:39,  1.80s/it] 10%|▉         | 563/5922 [16:52<2:30:29,  1.68s/it] 10%|▉         | 564/5922 [16:54<2:35:07,  1.74s/it] 10%|▉         | 565/5922 [16:55<2:26:45,  1.64s/it] 10%|▉         | 566/5922 [16:57<2:21:39,  1.59s/it] 10%|▉         | 567/5922 [16:59<2:34:33,  1.73s/it] 10%|▉         | 568/5922 [17:00<2:30:14,  1.68s/it] 10%|▉         | 569/5922 [17:02<2:23:13,  1.61s/it] 10%|▉         | 570/5922 [17:04<2:25:25,  1.63s/it] 10%|▉         | 571/5922 [17:05<2:18:35,  1.55s/it] 10%|▉         | 572/5922 [17:07<2:28:59,  1.67s/it] 10%|▉         | 573/5922 [17:09<2:33:11,  1.72s/it] 10%|▉         | 574/5922 [17:10<2:32:36,  1.71s/it] 10%|▉         | 575/5922 [17:12<2:38:59,  1.78s/it]                                                    {'loss': 0.1674, 'grad_norm': 0.34459441299544413, 'learning_rate': 1.9641837598879304e-05, 'epoch': 0.29}
 10%|▉         | 575/5922 [17:12<2:38:59,  1.78s/it] 10%|▉         | 576/5922 [17:14<2:29:57,  1.68s/it] 10%|▉         | 577/5922 [17:16<2:50:40,  1.92s/it] 10%|▉         | 578/5922 [17:18<2:36:53,  1.76s/it] 10%|▉         | 579/5922 [17:20<2:41:35,  1.81s/it] 10%|▉         | 580/5922 [17:21<2:30:47,  1.69s/it] 10%|▉         | 581/5922 [17:22<2:23:14,  1.61s/it] 10%|▉         | 582/5922 [17:24<2:17:33,  1.55s/it] 10%|▉         | 583/5922 [17:25<2:13:18,  1.50s/it] 10%|▉         | 584/5922 [17:27<2:10:46,  1.47s/it] 10%|▉         | 585/5922 [17:29<2:28:33,  1.67s/it] 10%|▉         | 586/5922 [17:30<2:22:52,  1.61s/it] 10%|▉         | 587/5922 [17:32<2:31:49,  1.71s/it] 10%|▉         | 588/5922 [17:34<2:37:12,  1.77s/it] 10%|▉         | 589/5922 [17:36<2:27:15,  1.66s/it] 10%|▉         | 590/5922 [17:37<2:20:26,  1.58s/it] 10%|▉         | 591/5922 [17:39<2:44:46,  1.85s/it] 10%|▉         | 592/5922 [17:41<2:46:48,  1.88s/it] 10%|█         | 593/5922 [17:43<2:36:34,  1.76s/it] 10%|█         | 594/5922 [17:45<2:36:15,  1.76s/it] 10%|█         | 595/5922 [17:46<2:28:31,  1.67s/it] 10%|█         | 596/5922 [17:47<2:21:35,  1.60s/it] 10%|█         | 597/5922 [17:49<2:30:46,  1.70s/it] 10%|█         | 598/5922 [17:51<2:27:52,  1.67s/it] 10%|█         | 599/5922 [17:52<2:20:23,  1.58s/it] 10%|█         | 600/5922 [17:54<2:29:08,  1.68s/it]                                                    {'loss': 0.1856, 'grad_norm': 0.2856617211522434, 'learning_rate': 1.9606398013817086e-05, 'epoch': 0.3}
 10%|█         | 600/5922 [17:54<2:29:08,  1.68s/it] 10%|█         | 601/5922 [17:56<2:25:07,  1.64s/it] 10%|█         | 602/5922 [17:58<2:47:33,  1.89s/it] 10%|█         | 603/5922 [18:01<3:01:19,  2.05s/it] 10%|█         | 604/5922 [18:02<2:43:45,  1.85s/it] 10%|█         | 605/5922 [18:04<2:34:52,  1.75s/it] 10%|█         | 606/5922 [18:05<2:26:30,  1.65s/it] 10%|█         | 607/5922 [18:06<2:19:58,  1.58s/it] 10%|█         | 608/5922 [18:08<2:29:47,  1.69s/it] 10%|█         | 609/5922 [18:10<2:32:35,  1.72s/it] 10%|█         | 610/5922 [18:12<2:30:40,  1.70s/it] 10%|█         | 611/5922 [18:14<2:40:21,  1.81s/it] 10%|█         | 612/5922 [18:16<2:58:01,  2.01s/it] 10%|█         | 613/5922 [18:18<2:55:30,  1.98s/it] 10%|█         | 614/5922 [18:20<2:39:50,  1.81s/it] 10%|█         | 615/5922 [18:21<2:31:01,  1.71s/it] 10%|█         | 616/5922 [18:23<2:22:45,  1.61s/it] 10%|█         | 617/5922 [18:24<2:23:16,  1.62s/it] 10%|█         | 618/5922 [18:26<2:27:33,  1.67s/it] 10%|█         | 619/5922 [18:28<2:44:28,  1.86s/it] 10%|█         | 620/5922 [18:30<2:45:37,  1.87s/it] 10%|█         | 621/5922 [18:32<2:33:45,  1.74s/it] 11%|█         | 622/5922 [18:34<2:39:00,  1.80s/it] 11%|█         | 623/5922 [18:35<2:40:01,  1.81s/it] 11%|█         | 624/5922 [18:37<2:29:10,  1.69s/it] 11%|█         | 625/5922 [18:39<2:31:58,  1.72s/it]                                                    {'loss': 0.1806, 'grad_norm': 0.4321450776645911, 'learning_rate': 1.9569323765629448e-05, 'epoch': 0.32}
 11%|█         | 625/5922 [18:39<2:31:58,  1.72s/it] 11%|█         | 626/5922 [18:41<2:37:58,  1.79s/it] 11%|█         | 627/5922 [18:43<2:56:29,  2.00s/it] 11%|█         | 628/5922 [18:45<2:55:08,  1.98s/it] 11%|█         | 629/5922 [18:47<2:53:45,  1.97s/it] 11%|█         | 630/5922 [18:48<2:38:52,  1.80s/it] 11%|█         | 631/5922 [18:50<2:29:10,  1.69s/it] 11%|█         | 632/5922 [18:52<2:33:22,  1.74s/it] 11%|█         | 633/5922 [18:54<2:38:45,  1.80s/it] 11%|█         | 634/5922 [18:55<2:36:48,  1.78s/it] 11%|█         | 635/5922 [18:57<2:41:05,  1.83s/it] 11%|█         | 636/5922 [18:59<2:30:36,  1.71s/it] 11%|█         | 637/5922 [19:00<2:21:55,  1.61s/it] 11%|█         | 638/5922 [19:02<2:30:53,  1.71s/it] 11%|█         | 639/5922 [19:04<2:34:43,  1.76s/it] 11%|█         | 640/5922 [19:06<2:53:06,  1.97s/it] 11%|█         | 641/5922 [19:08<2:43:15,  1.85s/it] 11%|█         | 642/5922 [19:10<2:45:04,  1.88s/it] 11%|█         | 643/5922 [19:12<2:44:08,  1.87s/it] 11%|█         | 644/5922 [19:13<2:32:04,  1.73s/it] 11%|█         | 645/5922 [19:15<2:37:25,  1.79s/it] 11%|█         | 646/5922 [19:17<2:51:22,  1.95s/it] 11%|█         | 647/5922 [19:19<2:50:43,  1.94s/it] 11%|█         | 648/5922 [19:21<2:36:05,  1.78s/it] 11%|█         | 649/5922 [19:22<2:26:42,  1.67s/it] 11%|█         | 650/5922 [19:24<2:33:09,  1.74s/it]                                                    {'loss': 0.192, 'grad_norm': 0.29234906635336155, 'learning_rate': 1.9530621509407268e-05, 'epoch': 0.33}
 11%|█         | 650/5922 [19:24<2:33:09,  1.74s/it] 11%|█         | 651/5922 [19:26<2:32:44,  1.74s/it] 11%|█         | 652/5922 [19:28<2:50:55,  1.95s/it] 11%|█         | 653/5922 [19:30<2:49:43,  1.93s/it] 11%|█         | 654/5922 [19:31<2:36:06,  1.78s/it] 11%|█         | 655/5922 [19:34<2:44:34,  1.87s/it] 11%|█         | 656/5922 [19:36<2:51:47,  1.96s/it] 11%|█         | 657/5922 [19:37<2:40:29,  1.83s/it] 11%|█         | 658/5922 [19:39<2:29:48,  1.71s/it] 11%|█         | 659/5922 [19:40<2:22:56,  1.63s/it] 11%|█         | 660/5922 [19:42<2:17:51,  1.57s/it] 11%|█         | 661/5922 [19:43<2:17:10,  1.56s/it] 11%|█         | 662/5922 [19:45<2:24:01,  1.64s/it] 11%|█         | 663/5922 [19:46<2:20:56,  1.61s/it] 11%|█         | 664/5922 [19:48<2:29:16,  1.70s/it] 11%|█         | 665/5922 [19:50<2:35:30,  1.77s/it] 11%|█         | 666/5922 [19:52<2:28:53,  1.70s/it] 11%|█▏        | 667/5922 [19:53<2:21:22,  1.61s/it] 11%|█▏        | 668/5922 [19:55<2:16:32,  1.56s/it] 11%|█▏        | 669/5922 [19:56<2:12:58,  1.52s/it] 11%|█▏        | 670/5922 [19:58<2:24:44,  1.65s/it] 11%|█▏        | 671/5922 [20:00<2:19:10,  1.59s/it] 11%|█▏        | 672/5922 [20:01<2:26:09,  1.67s/it] 11%|█▏        | 673/5922 [20:03<2:32:45,  1.75s/it] 11%|█▏        | 674/5922 [20:05<2:33:25,  1.75s/it] 11%|█▏        | 675/5922 [20:07<2:38:22,  1.81s/it]                                                    {'loss': 0.17, 'grad_norm': 0.28984372751028864, 'learning_rate': 1.9490298192480438e-05, 'epoch': 0.34}
 11%|█▏        | 675/5922 [20:07<2:38:22,  1.81s/it] 11%|█▏        | 676/5922 [20:08<2:27:15,  1.68s/it] 11%|█▏        | 677/5922 [20:10<2:34:08,  1.76s/it] 11%|█▏        | 678/5922 [20:12<2:24:52,  1.66s/it] 11%|█▏        | 679/5922 [20:14<2:26:37,  1.68s/it] 11%|█▏        | 680/5922 [20:15<2:30:08,  1.72s/it] 11%|█▏        | 681/5922 [20:17<2:27:37,  1.69s/it] 12%|█▏        | 682/5922 [20:19<2:35:04,  1.78s/it] 12%|█▏        | 683/5922 [20:20<2:26:10,  1.67s/it] 12%|█▏        | 684/5922 [20:22<2:20:48,  1.61s/it] 12%|█▏        | 685/5922 [20:24<2:29:51,  1.72s/it] 12%|█▏        | 686/5922 [20:25<2:21:02,  1.62s/it] 12%|█▏        | 687/5922 [20:27<2:16:05,  1.56s/it] 12%|█▏        | 688/5922 [20:29<2:26:21,  1.68s/it] 12%|█▏        | 689/5922 [20:30<2:22:41,  1.64s/it] 12%|█▏        | 690/5922 [20:32<2:32:09,  1.74s/it] 12%|█▏        | 691/5922 [20:34<2:37:25,  1.81s/it] 12%|█▏        | 692/5922 [20:36<2:41:34,  1.85s/it] 12%|█▏        | 693/5922 [20:38<2:43:37,  1.88s/it] 12%|█▏        | 694/5922 [20:39<2:31:28,  1.74s/it] 12%|█▏        | 695/5922 [20:41<2:23:07,  1.64s/it] 12%|█▏        | 696/5922 [20:43<2:26:38,  1.68s/it] 12%|█▏        | 697/5922 [20:44<2:21:25,  1.62s/it] 12%|█▏        | 698/5922 [20:45<2:15:39,  1.56s/it] 12%|█▏        | 699/5922 [20:47<2:21:44,  1.63s/it] 12%|█▏        | 700/5922 [20:49<2:18:19,  1.59s/it]                                                    {'loss': 0.1796, 'grad_norm': 0.3401018523399196, 'learning_rate': 1.9448361053170753e-05, 'epoch': 0.35}
 12%|█▏        | 700/5922 [20:49<2:18:19,  1.59s/it] 12%|█▏        | 701/5922 [20:50<2:12:56,  1.53s/it] 12%|█▏        | 702/5922 [20:52<2:10:43,  1.50s/it] 12%|█▏        | 703/5922 [20:53<2:09:11,  1.49s/it] 12%|█▏        | 704/5922 [20:54<2:08:28,  1.48s/it] 12%|█▏        | 705/5922 [20:56<2:10:50,  1.50s/it] 12%|█▏        | 706/5922 [20:58<2:14:08,  1.54s/it] 12%|█▏        | 707/5922 [21:00<2:23:58,  1.66s/it] 12%|█▏        | 708/5922 [21:01<2:18:27,  1.59s/it] 12%|█▏        | 709/5922 [21:03<2:37:10,  1.81s/it] 12%|█▏        | 710/5922 [21:05<2:40:17,  1.85s/it] 12%|█▏        | 711/5922 [21:07<2:28:51,  1.71s/it] 12%|█▏        | 712/5922 [21:09<2:34:22,  1.78s/it] 12%|█▏        | 713/5922 [21:10<2:35:58,  1.80s/it] 12%|█▏        | 714/5922 [21:13<2:54:03,  2.01s/it] 12%|█▏        | 715/5922 [21:15<3:06:44,  2.15s/it] 12%|█▏        | 716/5922 [21:18<3:08:53,  2.18s/it] 12%|█▏        | 717/5922 [21:20<3:01:48,  2.10s/it] 12%|█▏        | 718/5922 [21:21<2:44:31,  1.90s/it] 12%|█▏        | 719/5922 [21:22<2:32:30,  1.76s/it] 12%|█▏        | 720/5922 [21:24<2:37:07,  1.81s/it] 12%|█▏        | 721/5922 [21:26<2:25:54,  1.68s/it] 12%|█▏        | 722/5922 [21:27<2:19:53,  1.61s/it] 12%|█▏        | 723/5922 [21:29<2:26:59,  1.70s/it] 12%|█▏        | 724/5922 [21:31<2:19:41,  1.61s/it] 12%|█▏        | 725/5922 [21:32<2:22:51,  1.65s/it]                                                    {'loss': 0.1815, 'grad_norm': 0.47235656686454897, 'learning_rate': 1.9404817619492614e-05, 'epoch': 0.37}
 12%|█▏        | 725/5922 [21:32<2:22:51,  1.65s/it] 12%|█▏        | 726/5922 [21:34<2:35:38,  1.80s/it] 12%|█▏        | 727/5922 [21:36<2:37:07,  1.81s/it] 12%|█▏        | 728/5922 [21:38<2:31:53,  1.75s/it] 12%|█▏        | 729/5922 [21:40<2:46:13,  1.92s/it] 12%|█▏        | 730/5922 [21:42<2:32:21,  1.76s/it] 12%|█▏        | 731/5922 [21:44<2:37:16,  1.82s/it] 12%|█▏        | 732/5922 [21:46<2:49:53,  1.96s/it] 12%|█▏        | 733/5922 [21:47<2:36:23,  1.81s/it] 12%|█▏        | 734/5922 [21:49<2:25:37,  1.68s/it] 12%|█▏        | 735/5922 [21:51<2:46:16,  1.92s/it] 12%|█▏        | 736/5922 [21:53<2:46:33,  1.93s/it] 12%|█▏        | 737/5922 [21:55<2:44:27,  1.90s/it] 12%|█▏        | 738/5922 [21:57<2:45:08,  1.91s/it] 12%|█▏        | 739/5922 [21:59<2:45:57,  1.92s/it] 12%|█▏        | 740/5922 [22:00<2:31:58,  1.76s/it] 13%|█▎        | 741/5922 [22:02<2:40:51,  1.86s/it] 13%|█▎        | 742/5922 [22:04<2:44:36,  1.91s/it] 13%|█▎        | 743/5922 [22:06<2:46:39,  1.93s/it] 13%|█▎        | 744/5922 [22:08<2:46:59,  1.94s/it] 13%|█▎        | 745/5922 [22:10<2:32:15,  1.76s/it] 13%|█▎        | 746/5922 [22:11<2:23:22,  1.66s/it] 13%|█▎        | 747/5922 [22:13<2:29:53,  1.74s/it] 13%|█▎        | 748/5922 [22:15<2:34:12,  1.79s/it] 13%|█▎        | 749/5922 [22:17<2:34:50,  1.80s/it] 13%|█▎        | 750/5922 [22:18<2:30:11,  1.74s/it]                                                    {'loss': 0.1809, 'grad_norm': 0.3131990397417998, 'learning_rate': 1.9359675707801634e-05, 'epoch': 0.38}
 13%|█▎        | 750/5922 [22:18<2:30:11,  1.74s/it] 13%|█▎        | 751/5922 [22:20<2:35:14,  1.80s/it] 13%|█▎        | 752/5922 [22:22<2:43:48,  1.90s/it] 13%|█▎        | 753/5922 [22:24<2:31:41,  1.76s/it] 13%|█▎        | 754/5922 [22:26<2:47:31,  1.94s/it] 13%|█▎        | 755/5922 [22:28<2:33:35,  1.78s/it] 13%|█▎        | 756/5922 [22:29<2:23:47,  1.67s/it] 13%|█▎        | 757/5922 [22:31<2:31:10,  1.76s/it] 13%|█▎        | 758/5922 [22:33<2:36:25,  1.82s/it] 13%|█▎        | 759/5922 [22:35<2:41:12,  1.87s/it] 13%|█▎        | 760/5922 [22:37<2:41:14,  1.87s/it] 13%|█▎        | 761/5922 [22:39<2:42:39,  1.89s/it] 13%|█▎        | 762/5922 [22:41<2:43:33,  1.90s/it] 13%|█▎        | 763/5922 [22:43<2:43:34,  1.90s/it] 13%|█▎        | 764/5922 [22:44<2:32:05,  1.77s/it] 13%|█▎        | 765/5922 [22:46<2:41:20,  1.88s/it] 13%|█▎        | 766/5922 [22:48<2:39:32,  1.86s/it] 13%|█▎        | 767/5922 [22:49<2:26:49,  1.71s/it] 13%|█▎        | 768/5922 [22:51<2:32:25,  1.77s/it] 13%|█▎        | 769/5922 [22:53<2:23:55,  1.68s/it] 13%|█▎        | 770/5922 [22:54<2:22:11,  1.66s/it] 13%|█▎        | 771/5922 [22:56<2:29:14,  1.74s/it] 13%|█▎        | 772/5922 [22:58<2:20:04,  1.63s/it] 13%|█▎        | 773/5922 [23:00<2:27:24,  1.72s/it] 13%|█▎        | 774/5922 [23:01<2:32:44,  1.78s/it] 13%|█▎        | 775/5922 [23:03<2:37:05,  1.83s/it]                                                    {'loss': 0.1789, 'grad_norm': 0.32909910696730166, 'learning_rate': 1.93129434213916e-05, 'epoch': 0.39}
 13%|█▎        | 775/5922 [23:03<2:37:05,  1.83s/it] 13%|█▎        | 776/5922 [23:05<2:38:09,  1.84s/it] 13%|█▎        | 777/5922 [23:07<2:45:10,  1.93s/it] 13%|█▎        | 778/5922 [23:09<2:45:51,  1.93s/it] 13%|█▎        | 779/5922 [23:11<2:31:31,  1.77s/it] 13%|█▎        | 780/5922 [23:13<2:33:12,  1.79s/it] 13%|█▎        | 781/5922 [23:15<2:50:20,  1.99s/it] 13%|█▎        | 782/5922 [23:17<2:46:33,  1.94s/it] 13%|█▎        | 783/5922 [23:18<2:36:14,  1.82s/it] 13%|█▎        | 784/5922 [23:20<2:25:15,  1.70s/it] 13%|█▎        | 785/5922 [23:22<2:45:21,  1.93s/it] 13%|█▎        | 786/5922 [23:24<2:45:38,  1.94s/it] 13%|█▎        | 787/5922 [23:26<2:48:11,  1.97s/it] 13%|█▎        | 788/5922 [23:28<2:41:58,  1.89s/it] 13%|█▎        | 789/5922 [23:29<2:31:35,  1.77s/it] 13%|█▎        | 790/5922 [23:31<2:22:29,  1.67s/it] 13%|█▎        | 791/5922 [23:32<2:15:42,  1.59s/it] 13%|█▎        | 792/5922 [23:34<2:13:47,  1.56s/it] 13%|█▎        | 793/5922 [23:35<2:08:15,  1.50s/it] 13%|█▎        | 794/5922 [23:37<2:05:25,  1.47s/it] 13%|█▎        | 795/5922 [23:38<2:13:33,  1.56s/it] 13%|█▎        | 796/5922 [23:41<2:37:08,  1.84s/it] 13%|█▎        | 797/5922 [23:42<2:30:12,  1.76s/it] 13%|█▎        | 798/5922 [23:44<2:21:49,  1.66s/it] 13%|█▎        | 799/5922 [23:45<2:14:34,  1.58s/it] 14%|█▎        | 800/5922 [23:47<2:13:44,  1.57s/it]                                                    {'loss': 0.1778, 'grad_norm': 0.3255051442365256, 'learning_rate': 1.926462914903987e-05, 'epoch': 0.41}
 14%|█▎        | 800/5922 [23:47<2:13:44,  1.57s/it] 14%|█▎        | 801/5922 [23:49<2:36:55,  1.84s/it] 14%|█▎        | 802/5922 [23:51<2:24:54,  1.70s/it] 14%|█▎        | 803/5922 [23:53<2:31:28,  1.78s/it] 14%|█▎        | 804/5922 [23:54<2:21:34,  1.66s/it] 14%|█▎        | 805/5922 [23:55<2:16:53,  1.61s/it] 14%|█▎        | 806/5922 [23:57<2:11:07,  1.54s/it] 14%|█▎        | 807/5922 [23:58<2:06:40,  1.49s/it] 14%|█▎        | 808/5922 [24:00<2:17:03,  1.61s/it] 14%|█▎        | 809/5922 [24:02<2:24:44,  1.70s/it] 14%|█▎        | 810/5922 [24:03<2:19:50,  1.64s/it] 14%|█▎        | 811/5922 [24:05<2:28:30,  1.74s/it] 14%|█▎        | 812/5922 [24:08<2:38:14,  1.86s/it] 14%|█▎        | 813/5922 [24:09<2:40:14,  1.88s/it] 14%|█▎        | 814/5922 [24:11<2:27:20,  1.73s/it] 14%|█▍        | 815/5922 [24:13<2:45:48,  1.95s/it] 14%|█▍        | 816/5922 [24:15<2:44:44,  1.94s/it] 14%|█▍        | 817/5922 [24:17<2:45:21,  1.94s/it] 14%|█▍        | 818/5922 [24:19<2:47:47,  1.97s/it] 14%|█▍        | 819/5922 [24:21<2:54:50,  2.06s/it] 14%|█▍        | 820/5922 [24:24<2:55:29,  2.06s/it] 14%|█▍        | 821/5922 [24:26<2:56:12,  2.07s/it] 14%|█▍        | 822/5922 [24:28<2:52:11,  2.03s/it] 14%|█▍        | 823/5922 [24:30<2:55:06,  2.06s/it] 14%|█▍        | 824/5922 [24:32<2:51:57,  2.02s/it] 14%|█▍        | 825/5922 [24:34<3:00:53,  2.13s/it]                                                    {'loss': 0.1949, 'grad_norm': 0.29466481363872354, 'learning_rate': 1.9214741563501495e-05, 'epoch': 0.42}
 14%|█▍        | 825/5922 [24:34<3:00:53,  2.13s/it] 14%|█▍        | 826/5922 [24:35<2:43:05,  1.92s/it] 14%|█▍        | 827/5922 [24:37<2:29:10,  1.76s/it] 14%|█▍        | 828/5922 [24:39<2:32:54,  1.80s/it] 14%|█▍        | 829/5922 [24:41<2:39:32,  1.88s/it] 14%|█▍        | 830/5922 [24:43<2:41:17,  1.90s/it] 14%|█▍        | 831/5922 [24:45<2:42:25,  1.91s/it] 14%|█▍        | 832/5922 [24:46<2:28:26,  1.75s/it] 14%|█▍        | 833/5922 [24:48<2:33:18,  1.81s/it] 14%|█▍        | 834/5922 [24:50<2:45:15,  1.95s/it] 14%|█▍        | 835/5922 [24:52<2:49:52,  2.00s/it] 14%|█▍        | 836/5922 [24:54<2:35:16,  1.83s/it] 14%|█▍        | 837/5922 [24:55<2:26:19,  1.73s/it] 14%|█▍        | 838/5922 [24:57<2:19:57,  1.65s/it] 14%|█▍        | 839/5922 [24:59<2:30:47,  1.78s/it] 14%|█▍        | 840/5922 [25:00<2:21:53,  1.68s/it] 14%|█▍        | 841/5922 [25:02<2:24:05,  1.70s/it] 14%|█▍        | 842/5922 [25:04<2:31:12,  1.79s/it] 14%|█▍        | 843/5922 [25:06<2:34:50,  1.83s/it] 14%|█▍        | 844/5922 [25:08<2:35:21,  1.84s/it] 14%|█▍        | 845/5922 [25:10<2:37:28,  1.86s/it] 14%|█▍        | 846/5922 [25:12<2:40:03,  1.89s/it] 14%|█▍        | 847/5922 [25:14<2:38:17,  1.87s/it] 14%|█▍        | 848/5922 [25:16<2:53:56,  2.06s/it] 14%|█▍        | 849/5922 [25:18<2:43:49,  1.94s/it] 14%|█▍        | 850/5922 [25:19<2:36:55,  1.86s/it]                                                    {'loss': 0.1701, 'grad_norm': 0.31431741918770467, 'learning_rate': 1.916328961995243e-05, 'epoch': 0.43}
 14%|█▍        | 850/5922 [25:19<2:36:55,  1.86s/it] 14%|█▍        | 851/5922 [25:21<2:25:40,  1.72s/it] 14%|█▍        | 852/5922 [25:23<2:39:58,  1.89s/it] 14%|█▍        | 853/5922 [25:25<2:33:49,  1.82s/it] 14%|█▍        | 854/5922 [25:26<2:23:25,  1.70s/it] 14%|█▍        | 855/5922 [25:28<2:18:55,  1.65s/it] 14%|█▍        | 856/5922 [25:29<2:12:38,  1.57s/it] 14%|█▍        | 857/5922 [25:31<2:22:28,  1.69s/it] 14%|█▍        | 858/5922 [25:33<2:32:02,  1.80s/it] 15%|█▍        | 859/5922 [25:35<2:37:45,  1.87s/it] 15%|█▍        | 860/5922 [25:37<2:39:47,  1.89s/it] 15%|█▍        | 861/5922 [25:39<2:40:47,  1.91s/it] 15%|█▍        | 862/5922 [25:40<2:29:42,  1.78s/it] 15%|█▍        | 863/5922 [25:42<2:20:05,  1.66s/it] 15%|█▍        | 864/5922 [25:44<2:26:12,  1.73s/it] 15%|█▍        | 865/5922 [25:45<2:17:49,  1.64s/it] 15%|█▍        | 866/5922 [25:47<2:12:03,  1.57s/it] 15%|█▍        | 867/5922 [25:48<2:10:25,  1.55s/it] 15%|█▍        | 868/5922 [25:50<2:29:02,  1.77s/it] 15%|█▍        | 869/5922 [25:52<2:20:32,  1.67s/it] 15%|█▍        | 870/5922 [25:54<2:26:56,  1.75s/it] 15%|█▍        | 871/5922 [25:56<2:32:16,  1.81s/it] 15%|█▍        | 872/5922 [25:57<2:29:40,  1.78s/it] 15%|█▍        | 873/5922 [25:59<2:20:58,  1.68s/it] 15%|█▍        | 874/5922 [26:00<2:18:44,  1.65s/it] 15%|█▍        | 875/5922 [26:02<2:25:09,  1.73s/it]                                                    {'loss': 0.1731, 'grad_norm': 0.39574749899020983, 'learning_rate': 1.9110282554381996e-05, 'epoch': 0.44}
 15%|█▍        | 875/5922 [26:02<2:25:09,  1.73s/it] 15%|█▍        | 876/5922 [26:04<2:23:49,  1.71s/it] 15%|█▍        | 877/5922 [26:06<2:24:01,  1.71s/it] 15%|█▍        | 878/5922 [26:07<2:22:11,  1.69s/it] 15%|█▍        | 879/5922 [26:10<2:41:41,  1.92s/it] 15%|█▍        | 880/5922 [26:12<2:47:43,  2.00s/it] 15%|█▍        | 881/5922 [26:14<2:45:35,  1.97s/it] 15%|█▍        | 882/5922 [26:15<2:32:10,  1.81s/it] 15%|█▍        | 883/5922 [26:18<2:42:22,  1.93s/it] 15%|█▍        | 884/5922 [26:19<2:32:26,  1.82s/it] 15%|█▍        | 885/5922 [26:21<2:25:59,  1.74s/it] 15%|█▍        | 886/5922 [26:22<2:24:29,  1.72s/it] 15%|█▍        | 887/5922 [26:25<2:41:40,  1.93s/it] 15%|█▍        | 888/5922 [26:27<2:42:02,  1.93s/it] 15%|█▌        | 889/5922 [26:29<2:41:52,  1.93s/it] 15%|█▌        | 890/5922 [26:31<2:55:02,  2.09s/it] 15%|█▌        | 891/5922 [26:33<2:51:25,  2.04s/it] 15%|█▌        | 892/5922 [26:34<2:34:32,  1.84s/it] 15%|█▌        | 893/5922 [26:37<2:50:09,  2.03s/it] 15%|█▌        | 894/5922 [26:39<2:47:02,  1.99s/it] 15%|█▌        | 895/5922 [26:41<2:50:21,  2.03s/it] 15%|█▌        | 896/5922 [26:43<2:47:58,  2.01s/it] 15%|█▌        | 897/5922 [26:44<2:36:32,  1.87s/it] 15%|█▌        | 898/5922 [26:46<2:26:44,  1.75s/it] 15%|█▌        | 899/5922 [26:48<2:39:06,  1.90s/it] 15%|█▌        | 900/5922 [26:49<2:26:26,  1.75s/it]                                                    {'loss': 0.1788, 'grad_norm': 0.3823713230526524, 'learning_rate': 1.905572988193497e-05, 'epoch': 0.46}
 15%|█▌        | 900/5922 [26:49<2:26:26,  1.75s/it] 15%|█▌        | 901/5922 [26:51<2:31:26,  1.81s/it] 15%|█▌        | 902/5922 [26:53<2:34:30,  1.85s/it] 15%|█▌        | 903/5922 [26:55<2:41:07,  1.93s/it] 15%|█▌        | 904/5922 [26:57<2:27:46,  1.77s/it] 15%|█▌        | 905/5922 [26:58<2:18:15,  1.65s/it] 15%|█▌        | 906/5922 [27:00<2:11:49,  1.58s/it] 15%|█▌        | 907/5922 [27:02<2:28:20,  1.77s/it] 15%|█▌        | 908/5922 [27:03<2:18:39,  1.66s/it] 15%|█▌        | 909/5922 [27:05<2:24:18,  1.73s/it] 15%|█▌        | 910/5922 [27:07<2:29:52,  1.79s/it] 15%|█▌        | 911/5922 [27:09<2:22:29,  1.71s/it] 15%|█▌        | 912/5922 [27:11<2:28:03,  1.77s/it] 15%|█▌        | 913/5922 [27:12<2:21:54,  1.70s/it] 15%|█▌        | 914/5922 [27:14<2:31:56,  1.82s/it] 15%|█▌        | 915/5922 [27:17<2:45:58,  1.99s/it] 15%|█▌        | 916/5922 [27:18<2:41:28,  1.94s/it] 15%|█▌        | 917/5922 [27:20<2:27:32,  1.77s/it] 16%|█▌        | 918/5922 [27:22<2:31:31,  1.82s/it] 16%|█▌        | 919/5922 [27:23<2:22:06,  1.70s/it] 16%|█▌        | 920/5922 [27:25<2:25:38,  1.75s/it] 16%|█▌        | 921/5922 [27:26<2:18:23,  1.66s/it] 16%|█▌        | 922/5922 [27:28<2:11:41,  1.58s/it] 16%|█▌        | 923/5922 [27:30<2:24:03,  1.73s/it] 16%|█▌        | 924/5922 [27:32<2:43:21,  1.96s/it] 16%|█▌        | 925/5922 [27:34<2:33:49,  1.85s/it]                                                    {'loss': 0.1689, 'grad_norm': 0.3814147135311434, 'learning_rate': 1.8999641395203543e-05, 'epoch': 0.47}
 16%|█▌        | 925/5922 [27:34<2:33:49,  1.85s/it] 16%|█▌        | 926/5922 [27:36<2:35:46,  1.87s/it] 16%|█▌        | 927/5922 [27:38<2:34:28,  1.86s/it] 16%|█▌        | 928/5922 [27:40<2:46:33,  2.00s/it] 16%|█▌        | 929/5922 [27:41<2:31:55,  1.83s/it] 16%|█▌        | 930/5922 [27:43<2:34:12,  1.85s/it] 16%|█▌        | 931/5922 [27:45<2:25:41,  1.75s/it] 16%|█▌        | 932/5922 [27:47<2:31:38,  1.82s/it] 16%|█▌        | 933/5922 [27:49<2:34:08,  1.85s/it] 16%|█▌        | 934/5922 [27:50<2:22:06,  1.71s/it] 16%|█▌        | 935/5922 [27:52<2:14:16,  1.62s/it] 16%|█▌        | 936/5922 [27:54<2:21:22,  1.70s/it] 16%|█▌        | 937/5922 [27:56<2:30:45,  1.81s/it] 16%|█▌        | 938/5922 [27:58<2:34:53,  1.86s/it] 16%|█▌        | 939/5922 [27:59<2:27:15,  1.77s/it] 16%|█▌        | 940/5922 [28:01<2:18:35,  1.67s/it] 16%|█▌        | 941/5922 [28:02<2:16:13,  1.64s/it] 16%|█▌        | 942/5922 [28:04<2:13:02,  1.60s/it] 16%|█▌        | 943/5922 [28:06<2:23:17,  1.73s/it] 16%|█▌        | 944/5922 [28:08<2:28:30,  1.79s/it] 16%|█▌        | 945/5922 [28:09<2:31:03,  1.82s/it] 16%|█▌        | 946/5922 [28:12<2:45:42,  2.00s/it] 16%|█▌        | 947/5922 [28:14<2:38:42,  1.91s/it] 16%|█▌        | 948/5922 [28:15<2:37:03,  1.89s/it] 16%|█▌        | 949/5922 [28:17<2:36:21,  1.89s/it] 16%|█▌        | 950/5922 [28:20<2:50:09,  2.05s/it]                                                    {'loss': 0.1768, 'grad_norm': 0.42640133275734876, 'learning_rate': 1.894202716246947e-05, 'epoch': 0.48}
 16%|█▌        | 950/5922 [28:20<2:50:09,  2.05s/it] 16%|█▌        | 951/5922 [28:22<2:47:43,  2.02s/it] 16%|█▌        | 952/5922 [28:24<2:45:30,  2.00s/it] 16%|█▌        | 953/5922 [28:26<2:43:34,  1.98s/it] 16%|█▌        | 954/5922 [28:27<2:28:52,  1.80s/it] 16%|█▌        | 955/5922 [28:29<2:31:56,  1.84s/it] 16%|█▌        | 956/5922 [28:31<2:34:02,  1.86s/it] 16%|█▌        | 957/5922 [28:33<2:35:53,  1.88s/it] 16%|█▌        | 958/5922 [28:35<2:40:19,  1.94s/it] 16%|█▌        | 959/5922 [28:37<2:33:49,  1.86s/it] 16%|█▌        | 960/5922 [28:39<2:38:09,  1.91s/it] 16%|█▌        | 961/5922 [28:41<2:40:10,  1.94s/it] 16%|█▌        | 962/5922 [28:42<2:40:06,  1.94s/it] 16%|█▋        | 963/5922 [28:44<2:40:07,  1.94s/it] 16%|█▋        | 964/5922 [28:46<2:31:43,  1.84s/it] 16%|█▋        | 965/5922 [28:48<2:24:46,  1.75s/it] 16%|█▋        | 966/5922 [28:49<2:15:56,  1.65s/it] 16%|█▋        | 967/5922 [28:51<2:23:15,  1.73s/it] 16%|█▋        | 968/5922 [28:52<2:14:24,  1.63s/it] 16%|█▋        | 969/5922 [28:54<2:24:03,  1.75s/it] 16%|█▋        | 970/5922 [28:56<2:20:20,  1.70s/it] 16%|█▋        | 971/5922 [28:58<2:19:23,  1.69s/it] 16%|█▋        | 972/5922 [28:59<2:12:47,  1.61s/it] 16%|█▋        | 973/5922 [29:00<2:07:01,  1.54s/it] 16%|█▋        | 974/5922 [29:02<2:03:39,  1.50s/it] 16%|█▋        | 975/5922 [29:04<2:25:40,  1.77s/it]                                                    {'loss': 0.1708, 'grad_norm': 0.2986324781652876, 'learning_rate': 1.8882897525896757e-05, 'epoch': 0.49}
 16%|█▋        | 975/5922 [29:04<2:25:40,  1.77s/it] 16%|█▋        | 976/5922 [29:06<2:29:06,  1.81s/it] 16%|█▋        | 977/5922 [29:07<2:19:23,  1.69s/it] 17%|█▋        | 978/5922 [29:09<2:26:03,  1.77s/it] 17%|█▋        | 979/5922 [29:11<2:28:19,  1.80s/it] 17%|█▋        | 980/5922 [29:13<2:33:17,  1.86s/it] 17%|█▋        | 981/5922 [29:15<2:35:20,  1.89s/it] 17%|█▋        | 982/5922 [29:17<2:35:08,  1.88s/it] 17%|█▋        | 983/5922 [29:19<2:25:37,  1.77s/it] 17%|█▋        | 984/5922 [29:21<2:29:17,  1.81s/it] 17%|█▋        | 985/5922 [29:23<2:44:36,  2.00s/it] 17%|█▋        | 986/5922 [29:25<2:43:05,  1.98s/it] 17%|█▋        | 987/5922 [29:27<2:54:24,  2.12s/it] 17%|█▋        | 988/5922 [29:29<2:41:25,  1.96s/it] 17%|█▋        | 989/5922 [29:31<2:35:30,  1.89s/it] 17%|█▋        | 990/5922 [29:33<2:48:02,  2.04s/it] 17%|█▋        | 991/5922 [29:35<2:34:13,  1.88s/it] 17%|█▋        | 992/5922 [29:36<2:23:59,  1.75s/it] 17%|█▋        | 993/5922 [29:39<2:42:13,  1.97s/it] 17%|█▋        | 994/5922 [29:41<2:53:41,  2.11s/it] 17%|█▋        | 995/5922 [29:43<2:38:59,  1.94s/it] 17%|█▋        | 996/5922 [29:44<2:27:18,  1.79s/it] 17%|█▋        | 997/5922 [29:46<2:31:01,  1.84s/it] 17%|█▋        | 998/5922 [29:47<2:20:44,  1.71s/it] 17%|█▋        | 999/5922 [29:49<2:16:47,  1.67s/it] 17%|█▋        | 1000/5922 [29:51<2:15:45,  1.66s/it]                                                     {'loss': 0.1669, 'grad_norm': 0.327442029487216, 'learning_rate': 1.882226309967516e-05, 'epoch': 0.51}
 17%|█▋        | 1000/5922 [29:51<2:15:45,  1.66s/it][INFO|trainer.py:3993] 2025-08-30 14:18:42,246 >> Saving model checkpoint to saves/qwen3-1.7B/lora/sft/checkpoint-1000
[INFO|configuration_utils.py:696] 2025-08-30 14:18:42,258 >> loading configuration file /home/qianwenhao/LLM/Qwen3-1.7B/config.json
[INFO|configuration_utils.py:770] 2025-08-30 14:18:42,259 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "max_position_embeddings": 40960,
  "max_window_layers": 28,
  "model_type": "qwen3",
  "num_attention_heads": 16,
  "num_hidden_layers": 28,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|tokenization_utils_base.py:2356] 2025-08-30 14:18:42,275 >> chat template saved in saves/qwen3-1.7B/lora/sft/checkpoint-1000/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-08-30 14:18:42,275 >> tokenizer config file saved in saves/qwen3-1.7B/lora/sft/checkpoint-1000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-08-30 14:18:42,276 >> Special tokens file saved in saves/qwen3-1.7B/lora/sft/checkpoint-1000/special_tokens_map.json
[2025-08-30 14:18:42,439] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step1000 is about to be saved!
[2025-08-30 14:18:42,447] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: saves/qwen3-1.7B/lora/sft/checkpoint-1000/global_step1000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-08-30 14:18:42,447] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-1000/global_step1000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-08-30 14:18:42,453] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-1000/global_step1000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-08-30 14:18:42,454] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-1000/global_step1000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-08-30 14:18:42,466] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-1000/global_step1000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-08-30 14:18:42,466] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved saves/qwen3-1.7B/lora/sft/checkpoint-1000/global_step1000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-08-30 14:18:42,474] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
 17%|█▋        | 1001/5922 [29:55<3:17:11,  2.40s/it] 17%|█▋        | 1002/5922 [29:57<3:19:59,  2.44s/it] 17%|█▋        | 1003/5922 [29:59<3:02:57,  2.23s/it] 17%|█▋        | 1004/5922 [30:00<2:43:49,  2.00s/it] 17%|█▋        | 1005/5922 [30:03<2:55:26,  2.14s/it] 17%|█▋        | 1006/5922 [30:04<2:39:03,  1.94s/it] 17%|█▋        | 1007/5922 [30:06<2:28:39,  1.81s/it] 17%|█▋        | 1008/5922 [30:08<2:42:25,  1.98s/it] 17%|█▋        | 1009/5922 [30:10<2:29:09,  1.82s/it] 17%|█▋        | 1010/5922 [30:12<2:32:48,  1.87s/it] 17%|█▋        | 1011/5922 [30:14<2:34:35,  1.89s/it] 17%|█▋        | 1012/5922 [30:15<2:24:53,  1.77s/it] 17%|█▋        | 1013/5922 [30:17<2:17:01,  1.67s/it] 17%|█▋        | 1014/5922 [30:18<2:15:00,  1.65s/it] 17%|█▋        | 1015/5922 [30:20<2:19:48,  1.71s/it] 17%|█▋        | 1016/5922 [30:22<2:30:33,  1.84s/it] 17%|█▋        | 1017/5922 [30:24<2:32:43,  1.87s/it] 17%|█▋        | 1018/5922 [30:26<2:27:01,  1.80s/it] 17%|█▋        | 1019/5922 [30:27<2:18:44,  1.70s/it] 17%|█▋        | 1020/5922 [30:29<2:24:18,  1.77s/it] 17%|█▋        | 1021/5922 [30:31<2:16:27,  1.67s/it] 17%|█▋        | 1022/5922 [30:32<2:12:08,  1.62s/it] 17%|█▋        | 1023/5922 [30:34<2:12:15,  1.62s/it] 17%|█▋        | 1024/5922 [30:36<2:34:11,  1.89s/it] 17%|█▋        | 1025/5922 [30:38<2:35:45,  1.91s/it]                                                     {'loss': 0.1596, 'grad_norm': 0.3201368002304941, 'learning_rate': 1.8760134768114867e-05, 'epoch': 0.52}
 17%|█▋        | 1025/5922 [30:38<2:35:45,  1.91s/it] 17%|█▋        | 1026/5922 [30:40<2:39:51,  1.96s/it] 17%|█▋        | 1027/5922 [30:42<2:29:36,  1.83s/it] 17%|█▋        | 1028/5922 [30:43<2:22:29,  1.75s/it] 17%|█▋        | 1029/5922 [30:45<2:19:33,  1.71s/it] 17%|█▋        | 1030/5922 [30:46<2:14:42,  1.65s/it] 17%|█▋        | 1031/5922 [30:48<2:08:58,  1.58s/it] 17%|█▋        | 1032/5922 [30:50<2:17:36,  1.69s/it] 17%|█▋        | 1033/5922 [30:52<2:24:04,  1.77s/it] 17%|█▋        | 1034/5922 [30:54<2:39:20,  1.96s/it] 17%|█▋        | 1035/5922 [30:56<2:38:30,  1.95s/it] 17%|█▋        | 1036/5922 [30:57<2:25:21,  1.78s/it] 18%|█▊        | 1037/5922 [31:00<2:41:57,  1.99s/it] 18%|█▊        | 1038/5922 [31:01<2:30:19,  1.85s/it] 18%|█▊        | 1039/5922 [31:03<2:32:28,  1.87s/it] 18%|█▊        | 1040/5922 [31:05<2:25:59,  1.79s/it] 18%|█▊        | 1041/5922 [31:06<2:18:11,  1.70s/it] 18%|█▊        | 1042/5922 [31:08<2:10:01,  1.60s/it] 18%|█▊        | 1043/5922 [31:09<2:08:12,  1.58s/it] 18%|█▊        | 1044/5922 [31:11<2:17:08,  1.69s/it] 18%|█▊        | 1045/5922 [31:13<2:25:11,  1.79s/it] 18%|█▊        | 1046/5922 [31:15<2:28:37,  1.83s/it] 18%|█▊        | 1047/5922 [31:17<2:18:28,  1.70s/it] 18%|█▊        | 1048/5922 [31:18<2:10:35,  1.61s/it] 18%|█▊        | 1049/5922 [31:20<2:14:24,  1.65s/it] 18%|█▊        | 1050/5922 [31:22<2:34:09,  1.90s/it]                                                     {'loss': 0.1652, 'grad_norm': 0.3891132515148719, 'learning_rate': 1.869652368369269e-05, 'epoch': 0.53}
 18%|█▊        | 1050/5922 [31:22<2:34:09,  1.90s/it] 18%|█▊        | 1051/5922 [31:24<2:23:58,  1.77s/it] 18%|█▊        | 1052/5922 [31:25<2:16:02,  1.68s/it] 18%|█▊        | 1053/5922 [31:27<2:22:42,  1.76s/it] 18%|█▊        | 1054/5922 [31:29<2:18:53,  1.71s/it] 18%|█▊        | 1055/5922 [31:30<2:12:01,  1.63s/it] 18%|█▊        | 1056/5922 [31:32<2:22:25,  1.76s/it] 18%|█▊        | 1057/5922 [31:34<2:19:09,  1.72s/it] 18%|█▊        | 1058/5922 [31:36<2:37:26,  1.94s/it] 18%|█▊        | 1059/5922 [31:38<2:24:47,  1.79s/it] 18%|█▊        | 1060/5922 [31:40<2:28:00,  1.83s/it] 18%|█▊        | 1061/5922 [31:42<2:43:36,  2.02s/it] 18%|█▊        | 1062/5922 [31:44<2:43:30,  2.02s/it] 18%|█▊        | 1063/5922 [31:46<2:29:02,  1.84s/it] 18%|█▊        | 1064/5922 [31:48<2:33:30,  1.90s/it] 18%|█▊        | 1065/5922 [31:50<2:38:43,  1.96s/it] 18%|█▊        | 1066/5922 [31:51<2:26:14,  1.81s/it] 18%|█▊        | 1067/5922 [31:53<2:17:20,  1.70s/it] 18%|█▊        | 1068/5922 [31:55<2:33:30,  1.90s/it] 18%|█▊        | 1069/5922 [31:56<2:22:36,  1.76s/it] 18%|█▊        | 1070/5922 [31:58<2:27:50,  1.83s/it] 18%|█▊        | 1071/5922 [32:00<2:19:27,  1.72s/it] 18%|█▊        | 1072/5922 [32:02<2:36:58,  1.94s/it] 18%|█▊        | 1073/5922 [32:04<2:28:24,  1.84s/it] 18%|█▊        | 1074/5922 [32:06<2:22:05,  1.76s/it] 18%|█▊        | 1075/5922 [32:07<2:13:39,  1.65s/it]                                                     {'loss': 0.1629, 'grad_norm': 0.3253757430568407, 'learning_rate': 1.8631441265050102e-05, 'epoch': 0.54}
 18%|█▊        | 1075/5922 [32:07<2:13:39,  1.65s/it] 18%|█▊        | 1076/5922 [32:08<2:08:08,  1.59s/it] 18%|█▊        | 1077/5922 [32:10<2:04:55,  1.55s/it] 18%|█▊        | 1078/5922 [32:11<2:03:16,  1.53s/it] 18%|█▊        | 1079/5922 [32:13<2:13:26,  1.65s/it] 18%|█▊        | 1080/5922 [32:15<2:23:26,  1.78s/it] 18%|█▊        | 1081/5922 [32:17<2:23:25,  1.78s/it] 18%|█▊        | 1082/5922 [32:18<2:13:38,  1.66s/it] 18%|█▊        | 1083/5922 [32:20<2:07:27,  1.58s/it] 18%|█▊        | 1084/5922 [32:21<2:03:47,  1.54s/it] 18%|█▊        | 1085/5922 [32:23<2:10:45,  1.62s/it] 18%|█▊        | 1086/5922 [32:25<2:05:23,  1.56s/it] 18%|█▊        | 1087/5922 [32:26<2:10:02,  1.61s/it] 18%|█▊        | 1088/5922 [32:28<2:16:27,  1.69s/it] 18%|█▊        | 1089/5922 [32:30<2:16:46,  1.70s/it] 18%|█▊        | 1090/5922 [32:32<2:22:44,  1.77s/it] 18%|█▊        | 1091/5922 [32:34<2:23:43,  1.79s/it] 18%|█▊        | 1092/5922 [32:36<2:27:17,  1.83s/it] 18%|█▊        | 1093/5922 [32:38<2:38:49,  1.97s/it] 18%|█▊        | 1094/5922 [32:39<2:23:32,  1.78s/it] 18%|█▊        | 1095/5922 [32:41<2:27:47,  1.84s/it] 19%|█▊        | 1096/5922 [32:43<2:17:32,  1.71s/it] 19%|█▊        | 1097/5922 [32:45<2:23:25,  1.78s/it] 19%|█▊        | 1098/5922 [32:46<2:15:03,  1.68s/it] 19%|█▊        | 1099/5922 [32:47<2:08:46,  1.60s/it] 19%|█▊        | 1100/5922 [32:49<2:03:56,  1.54s/it]                                                     {'loss': 0.1483, 'grad_norm': 0.3643457740004781, 'learning_rate': 1.856489919494352e-05, 'epoch': 0.56}
 19%|█▊        | 1100/5922 [32:49<2:03:56,  1.54s/it] 19%|█▊        | 1101/5922 [32:50<2:00:44,  1.50s/it] 19%|█▊        | 1102/5922 [32:52<2:17:10,  1.71s/it] 19%|█▊        | 1103/5922 [32:54<2:22:25,  1.77s/it] 19%|█▊        | 1104/5922 [32:56<2:16:10,  1.70s/it] 19%|█▊        | 1105/5922 [32:58<2:32:30,  1.90s/it] 19%|█▊        | 1106/5922 [33:00<2:36:42,  1.95s/it] 19%|█▊        | 1107/5922 [33:02<2:27:49,  1.84s/it] 19%|█▊        | 1108/5922 [33:04<2:31:08,  1.88s/it] 19%|█▊        | 1109/5922 [33:06<2:32:38,  1.90s/it] 19%|█▊        | 1110/5922 [33:08<2:32:41,  1.90s/it] 19%|█▉        | 1111/5922 [33:10<2:35:32,  1.94s/it] 19%|█▉        | 1112/5922 [33:11<2:23:05,  1.78s/it] 19%|█▉        | 1113/5922 [33:13<2:13:46,  1.67s/it] 19%|█▉        | 1114/5922 [33:14<2:16:51,  1.71s/it] 19%|█▉        | 1115/5922 [33:16<2:10:17,  1.63s/it] 19%|█▉        | 1116/5922 [33:17<2:06:21,  1.58s/it] 19%|█▉        | 1117/5922 [33:19<2:15:34,  1.69s/it] 19%|█▉        | 1118/5922 [33:21<2:09:51,  1.62s/it] 19%|█▉        | 1119/5922 [33:23<2:27:48,  1.85s/it] 19%|█▉        | 1120/5922 [33:24<2:16:43,  1.71s/it] 19%|█▉        | 1121/5922 [33:27<2:32:37,  1.91s/it] 19%|█▉        | 1122/5922 [33:28<2:27:49,  1.85s/it] 19%|█▉        | 1123/5922 [33:30<2:16:53,  1.71s/it] 19%|█▉        | 1124/5922 [33:32<2:23:34,  1.80s/it] 19%|█▉        | 1125/5922 [33:34<2:31:40,  1.90s/it]                                                     {'loss': 0.171, 'grad_norm': 0.3194494199480448, 'learning_rate': 1.8496909418147176e-05, 'epoch': 0.57}
 19%|█▉        | 1125/5922 [33:34<2:31:40,  1.90s/it] 19%|█▉        | 1126/5922 [33:36<2:40:43,  2.01s/it] 19%|█▉        | 1127/5922 [33:38<2:27:12,  1.84s/it] 19%|█▉        | 1128/5922 [33:40<2:29:37,  1.87s/it] 19%|█▉        | 1129/5922 [33:41<2:20:23,  1.76s/it] 19%|█▉        | 1130/5922 [33:43<2:12:13,  1.66s/it] 19%|█▉        | 1131/5922 [33:45<2:29:22,  1.87s/it] 19%|█▉        | 1132/5922 [33:47<2:31:51,  1.90s/it] 19%|█▉        | 1133/5922 [33:48<2:21:03,  1.77s/it] 19%|█▉        | 1134/5922 [33:50<2:15:28,  1.70s/it] 19%|█▉        | 1135/5922 [33:52<2:23:12,  1.79s/it] 19%|█▉        | 1136/5922 [33:53<2:17:16,  1.72s/it] 19%|█▉        | 1137/5922 [33:55<2:09:36,  1.63s/it] 19%|█▉        | 1138/5922 [33:57<2:25:12,  1.82s/it] 19%|█▉        | 1139/5922 [33:59<2:15:37,  1.70s/it] 19%|█▉        | 1140/5922 [34:00<2:09:05,  1.62s/it] 19%|█▉        | 1141/5922 [34:02<2:22:33,  1.79s/it] 19%|█▉        | 1142/5922 [34:04<2:30:18,  1.89s/it] 19%|█▉        | 1143/5922 [34:07<2:42:52,  2.04s/it] 19%|█▉        | 1144/5922 [34:09<2:37:42,  1.98s/it] 19%|█▉        | 1145/5922 [34:10<2:26:56,  1.85s/it] 19%|█▉        | 1146/5922 [34:12<2:30:41,  1.89s/it] 19%|█▉        | 1147/5922 [34:15<2:43:39,  2.06s/it] 19%|█▉        | 1148/5922 [34:17<2:51:42,  2.16s/it] 19%|█▉        | 1149/5922 [34:18<2:35:35,  1.96s/it] 19%|█▉        | 1150/5922 [34:21<2:48:06,  2.11s/it]                                                     {'loss': 0.1674, 'grad_norm': 0.3394030051543515, 'learning_rate': 1.8427484139308936e-05, 'epoch': 0.58}
 19%|█▉        | 1150/5922 [34:21<2:48:06,  2.11s/it] 19%|█▉        | 1151/5922 [34:23<2:56:13,  2.22s/it] 19%|█▉        | 1152/5922 [34:25<2:49:36,  2.13s/it] 19%|█▉        | 1153/5922 [34:27<2:45:03,  2.08s/it] 19%|█▉        | 1154/5922 [34:29<2:33:17,  1.93s/it] 20%|█▉        | 1155/5922 [34:31<2:33:12,  1.93s/it] 20%|█▉        | 1156/5922 [34:32<2:21:43,  1.78s/it] 20%|█▉        | 1157/5922 [34:35<2:36:40,  1.97s/it] 20%|█▉        | 1158/5922 [34:37<2:48:40,  2.12s/it] 20%|█▉        | 1159/5922 [34:39<2:36:23,  1.97s/it] 20%|█▉        | 1160/5922 [34:41<2:34:58,  1.95s/it] 20%|█▉        | 1161/5922 [34:43<2:34:28,  1.95s/it] 20%|█▉        | 1162/5922 [34:44<2:26:10,  1.84s/it] 20%|█▉        | 1163/5922 [34:46<2:15:21,  1.71s/it] 20%|█▉        | 1164/5922 [34:47<2:21:05,  1.78s/it] 20%|█▉        | 1165/5922 [34:49<2:12:21,  1.67s/it] 20%|█▉        | 1166/5922 [34:50<2:06:09,  1.59s/it] 20%|█▉        | 1167/5922 [34:52<2:17:00,  1.73s/it] 20%|█▉        | 1168/5922 [34:54<2:10:18,  1.64s/it] 20%|█▉        | 1169/5922 [34:56<2:18:02,  1.74s/it] 20%|█▉        | 1170/5922 [34:57<2:13:10,  1.68s/it] 20%|█▉        | 1171/5922 [34:59<2:09:00,  1.63s/it] 20%|█▉        | 1172/5922 [35:00<2:04:52,  1.58s/it] 20%|█▉        | 1173/5922 [35:02<2:15:25,  1.71s/it] 20%|█▉        | 1174/5922 [35:04<2:21:21,  1.79s/it] 20%|█▉        | 1175/5922 [35:06<2:22:19,  1.80s/it]                                                     {'loss': 0.1722, 'grad_norm': 0.40443906233689997, 'learning_rate': 1.8356635820759465e-05, 'epoch': 0.6}
 20%|█▉        | 1175/5922 [35:06<2:22:19,  1.80s/it] 20%|█▉        | 1176/5922 [35:08<2:22:21,  1.80s/it] 20%|█▉        | 1177/5922 [35:10<2:25:28,  1.84s/it] 20%|█▉        | 1178/5922 [35:12<2:27:28,  1.87s/it] 20%|█▉        | 1179/5922 [35:13<2:15:37,  1.72s/it] 20%|█▉        | 1180/5922 [35:15<2:20:07,  1.77s/it] 20%|█▉        | 1181/5922 [35:17<2:15:48,  1.72s/it] 20%|█▉        | 1182/5922 [35:19<2:20:52,  1.78s/it] 20%|█▉        | 1183/5922 [35:20<2:10:52,  1.66s/it] 20%|█▉        | 1184/5922 [35:22<2:16:58,  1.73s/it] 20%|██        | 1185/5922 [35:24<2:21:24,  1.79s/it] 20%|██        | 1186/5922 [35:25<2:12:25,  1.68s/it] 20%|██        | 1187/5922 [35:27<2:14:27,  1.70s/it] 20%|██        | 1188/5922 [35:28<2:07:46,  1.62s/it] 20%|██        | 1189/5922 [35:31<2:27:15,  1.87s/it] 20%|██        | 1190/5922 [35:32<2:19:56,  1.77s/it] 20%|██        | 1191/5922 [35:34<2:23:59,  1.83s/it] 20%|██        | 1192/5922 [35:36<2:13:53,  1.70s/it] 20%|██        | 1193/5922 [35:38<2:19:59,  1.78s/it] 20%|██        | 1194/5922 [35:39<2:12:04,  1.68s/it] 20%|██        | 1195/5922 [35:41<2:18:20,  1.76s/it] 20%|██        | 1196/5922 [35:43<2:22:12,  1.81s/it] 20%|██        | 1197/5922 [35:45<2:25:08,  1.84s/it] 20%|██        | 1198/5922 [35:47<2:25:58,  1.85s/it] 20%|██        | 1199/5922 [35:48<2:19:23,  1.77s/it] 20%|██        | 1200/5922 [35:50<2:11:56,  1.68s/it]                                                     {'loss': 0.1585, 'grad_norm': 0.3952011138938835, 'learning_rate': 1.8284377180275172e-05, 'epoch': 0.61}
 20%|██        | 1200/5922 [35:50<2:11:56,  1.68s/it] 20%|██        | 1201/5922 [35:52<2:18:10,  1.76s/it] 20%|██        | 1202/5922 [35:53<2:11:12,  1.67s/it] 20%|██        | 1203/5922 [35:55<2:04:35,  1.58s/it] 20%|██        | 1204/5922 [35:56<2:11:05,  1.67s/it] 20%|██        | 1205/5922 [35:58<2:17:09,  1.74s/it] 20%|██        | 1206/5922 [36:00<2:14:17,  1.71s/it] 20%|██        | 1207/5922 [36:02<2:26:34,  1.87s/it] 20%|██        | 1208/5922 [36:04<2:15:13,  1.72s/it] 20%|██        | 1209/5922 [36:06<2:19:19,  1.77s/it] 20%|██        | 1210/5922 [36:07<2:21:18,  1.80s/it] 20%|██        | 1211/5922 [36:10<2:37:30,  2.01s/it] 20%|██        | 1212/5922 [36:12<2:36:54,  2.00s/it] 20%|██        | 1213/5922 [36:13<2:23:52,  1.83s/it] 20%|██        | 1214/5922 [36:15<2:14:05,  1.71s/it] 21%|██        | 1215/5922 [36:16<2:09:44,  1.65s/it] 21%|██        | 1216/5922 [36:18<2:17:17,  1.75s/it] 21%|██        | 1217/5922 [36:20<2:21:18,  1.80s/it] 21%|██        | 1218/5922 [36:22<2:20:53,  1.80s/it] 21%|██        | 1219/5922 [36:23<2:12:28,  1.69s/it] 21%|██        | 1220/5922 [36:25<2:05:17,  1.60s/it] 21%|██        | 1221/5922 [36:26<2:00:49,  1.54s/it] 21%|██        | 1222/5922 [36:28<2:08:35,  1.64s/it] 21%|██        | 1223/5922 [36:30<2:05:16,  1.60s/it] 21%|██        | 1224/5922 [36:31<2:05:05,  1.60s/it] 21%|██        | 1225/5922 [36:33<2:13:40,  1.71s/it]                                                     {'loss': 0.1472, 'grad_norm': 0.3127341721868261, 'learning_rate': 1.8210721188795274e-05, 'epoch': 0.62}
 21%|██        | 1225/5922 [36:33<2:13:40,  1.71s/it] 21%|██        | 1226/5922 [36:35<2:20:16,  1.79s/it] 21%|██        | 1227/5922 [36:37<2:23:13,  1.83s/it] 21%|██        | 1228/5922 [36:39<2:37:35,  2.01s/it] 21%|██        | 1229/5922 [36:42<2:48:37,  2.16s/it] 21%|██        | 1230/5922 [36:45<2:59:53,  2.30s/it] 21%|██        | 1231/5922 [36:47<2:59:02,  2.29s/it] 21%|██        | 1232/5922 [36:49<3:00:14,  2.31s/it] 21%|██        | 1233/5922 [36:51<2:59:21,  2.30s/it] 21%|██        | 1234/5922 [36:54<3:05:18,  2.37s/it] 21%|██        | 1235/5922 [36:56<3:04:24,  2.36s/it] 21%|██        | 1236/5922 [36:59<3:00:44,  2.31s/it] 21%|██        | 1237/5922 [37:01<3:03:42,  2.35s/it] 21%|██        | 1238/5922 [37:04<3:08:42,  2.42s/it] 21%|██        | 1239/5922 [37:06<3:08:12,  2.41s/it] 21%|██        | 1240/5922 [37:08<3:06:51,  2.39s/it] 21%|██        | 1241/5922 [37:11<3:09:32,  2.43s/it] 21%|██        | 1242/5922 [37:13<3:08:13,  2.41s/it] 21%|██        | 1243/5922 [37:16<3:08:18,  2.41s/it] 21%|██        | 1244/5922 [37:18<3:07:05,  2.40s/it] 21%|██        | 1245/5922 [37:20<3:06:04,  2.39s/it] 21%|██        | 1246/5922 [37:23<3:13:23,  2.48s/it] 21%|██        | 1247/5922 [37:25<3:10:15,  2.44s/it] 21%|██        | 1248/5922 [37:30<3:51:38,  2.97s/it] 21%|██        | 1249/5922 [37:34<4:24:33,  3.40s/it] 21%|██        | 1250/5922 [37:38<4:32:34,  3.50s/it]                                                     {'loss': 0.1545, 'grad_norm': 0.3691216426646937, 'learning_rate': 1.813568106809341e-05, 'epoch': 0.63}
 21%|██        | 1250/5922 [37:38<4:32:34,  3.50s/it] 21%|██        | 1251/5922 [37:41<4:35:19,  3.54s/it] 21%|██        | 1252/5922 [37:43<3:58:33,  3.06s/it] 21%|██        | 1253/5922 [37:45<3:21:53,  2.59s/it] 21%|██        | 1254/5922 [37:47<3:02:38,  2.35s/it] 21%|██        | 1255/5922 [37:48<2:44:04,  2.11s/it] 21%|██        | 1256/5922 [37:50<2:39:29,  2.05s/it] 21%|██        | 1257/5922 [37:51<2:25:02,  1.87s/it] 21%|██        | 1258/5922 [37:53<2:26:43,  1.89s/it] 21%|██▏       | 1259/5922 [37:55<2:15:11,  1.74s/it] 21%|██▏       | 1260/5922 [37:56<2:08:10,  1.65s/it] 21%|██▏       | 1261/5922 [37:58<2:14:43,  1.73s/it] 21%|██▏       | 1262/5922 [38:00<2:20:01,  1.80s/it] 21%|██▏       | 1263/5922 [38:02<2:12:08,  1.70s/it] 21%|██▏       | 1264/5922 [38:04<2:17:43,  1.77s/it] 21%|██▏       | 1265/5922 [38:05<2:21:24,  1.82s/it] 21%|██▏       | 1266/5922 [38:08<2:37:15,  2.03s/it] 21%|██▏       | 1267/5922 [38:09<2:23:24,  1.85s/it] 21%|██▏       | 1268/5922 [38:11<2:26:02,  1.88s/it] 21%|██▏       | 1269/5922 [38:13<2:20:38,  1.81s/it] 21%|██▏       | 1270/5922 [38:15<2:23:24,  1.85s/it] 21%|██▏       | 1271/5922 [38:17<2:22:40,  1.84s/it] 21%|██▏       | 1272/5922 [38:19<2:32:11,  1.96s/it] 21%|██▏       | 1273/5922 [38:20<2:18:53,  1.79s/it] 22%|██▏       | 1274/5922 [38:22<2:13:28,  1.72s/it] 22%|██▏       | 1275/5922 [38:24<2:19:28,  1.80s/it]                                                     {'loss': 0.1602, 'grad_norm': 0.40851589178572323, 'learning_rate': 1.8059270288404256e-05, 'epoch': 0.65}
 22%|██▏       | 1275/5922 [38:24<2:19:28,  1.80s/it] 22%|██▏       | 1276/5922 [38:26<2:21:11,  1.82s/it] 22%|██▏       | 1277/5922 [38:28<2:21:11,  1.82s/it] 22%|██▏       | 1278/5922 [38:30<2:23:45,  1.86s/it] 22%|██▏       | 1279/5922 [38:32<2:25:54,  1.89s/it] 22%|██▏       | 1280/5922 [38:34<2:28:42,  1.92s/it] 22%|██▏       | 1281/5922 [38:35<2:22:01,  1.84s/it] 22%|██▏       | 1282/5922 [38:37<2:12:34,  1.71s/it] 22%|██▏       | 1283/5922 [38:38<2:05:28,  1.62s/it] 22%|██▏       | 1284/5922 [38:39<1:59:28,  1.55s/it] 22%|██▏       | 1285/5922 [38:41<2:08:23,  1.66s/it] 22%|██▏       | 1286/5922 [38:43<2:09:05,  1.67s/it] 22%|██▏       | 1287/5922 [38:44<2:02:28,  1.59s/it] 22%|██▏       | 1288/5922 [38:46<2:02:48,  1.59s/it] 22%|██▏       | 1289/5922 [38:48<2:10:16,  1.69s/it] 22%|██▏       | 1290/5922 [38:50<2:27:11,  1.91s/it] 22%|██▏       | 1291/5922 [38:52<2:28:25,  1.92s/it] 22%|██▏       | 1292/5922 [38:54<2:14:52,  1.75s/it] 22%|██▏       | 1293/5922 [38:56<2:18:57,  1.80s/it] 22%|██▏       | 1294/5922 [38:57<2:13:09,  1.73s/it] 22%|██▏       | 1295/5922 [38:59<2:17:19,  1.78s/it] 22%|██▏       | 1296/5922 [39:00<2:07:17,  1.65s/it] 22%|██▏       | 1297/5922 [39:02<2:01:08,  1.57s/it] 22%|██▏       | 1298/5922 [39:03<2:01:05,  1.57s/it] 22%|██▏       | 1299/5922 [39:05<2:01:58,  1.58s/it] 22%|██▏       | 1300/5922 [39:06<1:59:26,  1.55s/it]                                                     {'loss': 0.1491, 'grad_norm': 0.33650644752647585, 'learning_rate': 1.7981502566005497e-05, 'epoch': 0.66}
 22%|██▏       | 1300/5922 [39:06<1:59:26,  1.55s/it] 22%|██▏       | 1301/5922 [39:08<1:58:01,  1.53s/it] 22%|██▏       | 1302/5922 [39:10<2:07:20,  1.65s/it] 22%|██▏       | 1303/5922 [39:12<2:15:17,  1.76s/it] 22%|██▏       | 1304/5922 [39:14<2:29:09,  1.94s/it] 22%|██▏       | 1305/5922 [39:16<2:31:42,  1.97s/it] 22%|██▏       | 1306/5922 [39:19<2:47:29,  2.18s/it] 22%|██▏       | 1307/5922 [39:23<3:35:36,  2.80s/it] 22%|██▏       | 1308/5922 [39:27<3:53:12,  3.03s/it] 22%|██▏       | 1309/5922 [39:31<4:31:08,  3.53s/it] 22%|██▏       | 1310/5922 [39:40<6:24:18,  5.00s/it] 22%|██▏       | 1311/5922 [39:47<7:03:48,  5.51s/it] 22%|██▏       | 1312/5922 [39:51<6:31:23,  5.09s/it] 22%|██▏       | 1313/5922 [39:52<5:10:56,  4.05s/it] 22%|██▏       | 1314/5922 [39:54<4:20:25,  3.39s/it] 22%|██▏       | 1315/5922 [39:56<3:34:30,  2.79s/it] 22%|██▏       | 1316/5922 [39:57<3:09:01,  2.46s/it] 22%|██▏       | 1317/5922 [39:59<2:48:07,  2.19s/it] 22%|██▏       | 1318/5922 [40:01<2:42:19,  2.12s/it] 22%|██▏       | 1319/5922 [40:02<2:25:36,  1.90s/it] 22%|██▏       | 1320/5922 [40:05<2:38:47,  2.07s/it] 22%|██▏       | 1321/5922 [40:06<2:33:56,  2.01s/it] 22%|██▏       | 1322/5922 [40:09<2:35:02,  2.02s/it] 22%|██▏       | 1323/5922 [40:10<2:26:54,  1.92s/it] 22%|██▏       | 1324/5922 [40:12<2:27:22,  1.92s/it] 22%|██▏       | 1325/5922 [40:14<2:14:36,  1.76s/it]                                                     {'loss': 0.1534, 'grad_norm': 0.2954713452044247, 'learning_rate': 1.790239186075569e-05, 'epoch': 0.67}
 22%|██▏       | 1325/5922 [40:14<2:14:36,  1.76s/it] 22%|██▏       | 1326/5922 [40:15<2:18:08,  1.80s/it] 22%|██▏       | 1327/5922 [40:17<2:21:22,  1.85s/it] 22%|██▏       | 1328/5922 [40:19<2:24:01,  1.88s/it] 22%|██▏       | 1329/5922 [40:21<2:25:09,  1.90s/it] 22%|██▏       | 1330/5922 [40:23<2:26:26,  1.91s/it] 22%|██▏       | 1331/5922 [40:25<2:15:00,  1.76s/it] 22%|██▏       | 1332/5922 [40:26<2:10:35,  1.71s/it] 23%|██▎       | 1333/5922 [40:28<2:03:35,  1.62s/it] 23%|██▎       | 1334/5922 [40:30<2:11:32,  1.72s/it] 23%|██▎       | 1335/5922 [40:32<2:16:27,  1.78s/it] 23%|██▎       | 1336/5922 [40:33<2:06:56,  1.66s/it] 23%|██▎       | 1337/5922 [40:35<2:09:48,  1.70s/it] 23%|██▎       | 1338/5922 [40:37<2:24:55,  1.90s/it] 23%|██▎       | 1339/5922 [40:39<2:23:36,  1.88s/it] 23%|██▎       | 1340/5922 [40:41<2:20:33,  1.84s/it] 23%|██▎       | 1341/5922 [40:43<2:21:59,  1.86s/it] 23%|██▎       | 1342/5922 [40:44<2:13:04,  1.74s/it] 23%|██▎       | 1343/5922 [40:46<2:17:45,  1.81s/it] 23%|██▎       | 1344/5922 [40:47<2:10:54,  1.72s/it] 23%|██▎       | 1345/5922 [40:49<2:03:05,  1.61s/it] 23%|██▎       | 1346/5922 [40:51<2:20:25,  1.84s/it] 23%|██▎       | 1347/5922 [40:53<2:24:33,  1.90s/it] 23%|██▎       | 1348/5922 [40:55<2:26:24,  1.92s/it] 23%|██▎       | 1349/5922 [40:57<2:17:59,  1.81s/it] 23%|██▎       | 1350/5922 [40:58<2:08:30,  1.69s/it]                                                     {'loss': 0.1592, 'grad_norm': 0.4250835136083207, 'learning_rate': 1.7821952373588332e-05, 'epoch': 0.68}
 23%|██▎       | 1350/5922 [40:58<2:08:30,  1.69s/it] 23%|██▎       | 1351/5922 [41:00<2:07:43,  1.68s/it] 23%|██▎       | 1352/5922 [41:02<2:13:42,  1.76s/it] 23%|██▎       | 1353/5922 [41:03<2:07:03,  1.67s/it] 23%|██▎       | 1354/5922 [41:05<2:03:00,  1.62s/it] 23%|██▎       | 1355/5922 [41:06<1:57:27,  1.54s/it] 23%|██▎       | 1356/5922 [41:07<1:53:12,  1.49s/it] 23%|██▎       | 1357/5922 [41:09<2:05:26,  1.65s/it] 23%|██▎       | 1358/5922 [41:11<2:01:45,  1.60s/it] 23%|██▎       | 1359/5922 [41:12<1:58:15,  1.56s/it] 23%|██▎       | 1360/5922 [41:14<1:55:36,  1.52s/it] 23%|██▎       | 1361/5922 [41:16<2:03:44,  1.63s/it] 23%|██▎       | 1362/5922 [41:17<2:04:35,  1.64s/it] 23%|██▎       | 1363/5922 [41:19<2:03:42,  1.63s/it] 23%|██▎       | 1364/5922 [41:21<2:11:53,  1.74s/it] 23%|██▎       | 1365/5922 [41:23<2:28:38,  1.96s/it] 23%|██▎       | 1366/5922 [41:25<2:16:38,  1.80s/it] 23%|██▎       | 1367/5922 [41:27<2:15:45,  1.79s/it] 23%|██▎       | 1368/5922 [41:28<2:08:13,  1.69s/it] 23%|██▎       | 1369/5922 [41:30<2:11:01,  1.73s/it] 23%|██▎       | 1370/5922 [41:32<2:18:48,  1.83s/it] 23%|██▎       | 1371/5922 [41:34<2:21:46,  1.87s/it] 23%|██▎       | 1372/5922 [41:36<2:22:59,  1.89s/it] 23%|██▎       | 1373/5922 [41:37<2:14:46,  1.78s/it] 23%|██▎       | 1374/5922 [41:39<2:16:09,  1.80s/it] 23%|██▎       | 1375/5922 [41:41<2:06:59,  1.68s/it]                                                     {'loss': 0.1614, 'grad_norm': 0.33391325557329016, 'learning_rate': 1.7740198543962734e-05, 'epoch': 0.7}
 23%|██▎       | 1375/5922 [41:41<2:06:59,  1.68s/it] 23%|██▎       | 1376/5922 [41:43<2:12:24,  1.75s/it] 23%|██▎       | 1377/5922 [41:45<2:20:59,  1.86s/it] 23%|██▎       | 1378/5922 [41:46<2:10:31,  1.72s/it] 23%|██▎       | 1379/5922 [41:48<2:15:17,  1.79s/it] 23%|██▎       | 1380/5922 [41:49<2:05:50,  1.66s/it] 23%|██▎       | 1381/5922 [41:52<2:16:59,  1.81s/it] 23%|██▎       | 1382/5922 [41:53<2:19:58,  1.85s/it] 23%|██▎       | 1383/5922 [41:55<2:08:53,  1.70s/it] 23%|██▎       | 1384/5922 [41:57<2:22:36,  1.89s/it] 23%|██▎       | 1385/5922 [41:59<2:10:54,  1.73s/it] 23%|██▎       | 1386/5922 [42:01<2:25:30,  1.92s/it] 23%|██▎       | 1387/5922 [42:02<2:16:43,  1.81s/it] 23%|██▎       | 1388/5922 [42:04<2:07:38,  1.69s/it] 23%|██▎       | 1389/5922 [42:05<2:00:59,  1.60s/it] 23%|██▎       | 1390/5922 [42:07<2:12:28,  1.75s/it] 23%|██▎       | 1391/5922 [42:09<2:05:35,  1.66s/it] 24%|██▎       | 1392/5922 [42:11<2:06:52,  1.68s/it] 24%|██▎       | 1393/5922 [42:12<2:03:55,  1.64s/it] 24%|██▎       | 1394/5922 [42:14<2:06:59,  1.68s/it] 24%|██▎       | 1395/5922 [42:16<2:12:22,  1.75s/it] 24%|██▎       | 1396/5922 [42:18<2:25:17,  1.93s/it] 24%|██▎       | 1397/5922 [42:20<2:24:24,  1.91s/it] 24%|██▎       | 1398/5922 [42:22<2:20:04,  1.86s/it] 24%|██▎       | 1399/5922 [42:24<2:21:36,  1.88s/it] 24%|██▎       | 1400/5922 [42:25<2:10:57,  1.74s/it]                                                     {'loss': 0.1519, 'grad_norm': 0.4917152282293042, 'learning_rate': 1.7657145047272e-05, 'epoch': 0.71}
 24%|██▎       | 1400/5922 [42:25<2:10:57,  1.74s/it] 24%|██▎       | 1401/5922 [42:26<2:03:03,  1.63s/it] 24%|██▎       | 1402/5922 [42:28<2:09:08,  1.71s/it] 24%|██▎       | 1403/5922 [42:30<2:13:18,  1.77s/it] 24%|██▎       | 1404/5922 [42:32<2:13:10,  1.77s/it] 24%|██▎       | 1405/5922 [42:33<2:04:00,  1.65s/it] 24%|██▎       | 1406/5922 [42:35<2:11:23,  1.75s/it] 24%|██▍       | 1407/5922 [42:37<2:18:27,  1.84s/it] 24%|██▍       | 1408/5922 [42:39<2:23:48,  1.91s/it] 24%|██▍       | 1409/5922 [42:42<2:36:39,  2.08s/it] 24%|██▍       | 1410/5922 [42:43<2:22:50,  1.90s/it] 24%|██▍       | 1411/5922 [42:45<2:15:26,  1.80s/it] 24%|██▍       | 1412/5922 [42:46<2:08:04,  1.70s/it] 24%|██▍       | 1413/5922 [42:48<2:02:57,  1.64s/it] 24%|██▍       | 1414/5922 [42:49<1:59:14,  1.59s/it] 24%|██▍       | 1415/5922 [42:51<1:55:41,  1.54s/it] 24%|██▍       | 1416/5922 [42:53<2:00:53,  1.61s/it] 24%|██▍       | 1417/5922 [42:55<2:08:12,  1.71s/it] 24%|██▍       | 1418/5922 [42:56<2:05:30,  1.67s/it] 24%|██▍       | 1419/5922 [42:58<2:00:04,  1.60s/it] 24%|██▍       | 1420/5922 [43:00<2:07:39,  1.70s/it] 24%|██▍       | 1421/5922 [43:01<2:12:30,  1.77s/it] 24%|██▍       | 1422/5922 [43:03<2:11:42,  1.76s/it] 24%|██▍       | 1423/5922 [43:05<2:03:26,  1.65s/it] 24%|██▍       | 1424/5922 [43:06<1:58:20,  1.58s/it] 24%|██▍       | 1425/5922 [43:07<1:55:47,  1.54s/it]                                                     {'loss': 0.1568, 'grad_norm': 0.47080005633681277, 'learning_rate': 1.757280679220871e-05, 'epoch': 0.72}
 24%|██▍       | 1425/5922 [43:07<1:55:47,  1.54s/it] 24%|██▍       | 1426/5922 [43:10<2:15:13,  1.80s/it] 24%|██▍       | 1427/5922 [43:12<2:19:04,  1.86s/it] 24%|██▍       | 1428/5922 [43:14<2:20:32,  1.88s/it] 24%|██▍       | 1429/5922 [43:15<2:10:29,  1.74s/it] 24%|██▍       | 1430/5922 [43:17<2:05:42,  1.68s/it] 24%|██▍       | 1431/5922 [43:18<1:59:11,  1.59s/it] 24%|██▍       | 1432/5922 [43:20<1:59:28,  1.60s/it] 24%|██▍       | 1433/5922 [43:21<1:55:24,  1.54s/it] 24%|██▍       | 1434/5922 [43:23<1:52:27,  1.50s/it] 24%|██▍       | 1435/5922 [43:24<2:02:02,  1.63s/it] 24%|██▍       | 1436/5922 [43:27<2:17:00,  1.83s/it] 24%|██▍       | 1437/5922 [43:28<2:10:16,  1.74s/it] 24%|██▍       | 1438/5922 [43:30<2:06:29,  1.69s/it] 24%|██▍       | 1439/5922 [43:32<2:10:07,  1.74s/it] 24%|██▍       | 1440/5922 [43:34<2:13:57,  1.79s/it] 24%|██▍       | 1441/5922 [43:35<2:05:40,  1.68s/it] 24%|██▍       | 1442/5922 [43:37<2:11:24,  1.76s/it] 24%|██▍       | 1443/5922 [43:39<2:11:57,  1.77s/it] 24%|██▍       | 1444/5922 [43:40<2:07:33,  1.71s/it] 24%|██▍       | 1445/5922 [43:42<2:00:42,  1.62s/it] 24%|██▍       | 1446/5922 [43:44<2:09:57,  1.74s/it] 24%|██▍       | 1447/5922 [43:45<2:02:03,  1.64s/it] 24%|██▍       | 1448/5922 [43:47<2:08:55,  1.73s/it] 24%|██▍       | 1449/5922 [43:49<2:13:28,  1.79s/it] 24%|██▍       | 1450/5922 [43:50<2:04:25,  1.67s/it]                                                     {'loss': 0.145, 'grad_norm': 0.37341468476970535, 'learning_rate': 1.7487198918088693e-05, 'epoch': 0.73}
 24%|██▍       | 1450/5922 [43:50<2:04:25,  1.67s/it] 25%|██▍       | 1451/5922 [43:52<2:08:07,  1.72s/it] 25%|██▍       | 1452/5922 [43:54<2:12:07,  1.77s/it] 25%|██▍       | 1453/5922 [43:56<2:16:36,  1.83s/it] 25%|██▍       | 1454/5922 [43:58<2:10:12,  1.75s/it] 25%|██▍       | 1455/5922 [43:59<2:02:34,  1.65s/it] 25%|██▍       | 1456/5922 [44:01<2:08:47,  1.73s/it] 25%|██▍       | 1457/5922 [44:02<2:01:11,  1.63s/it] 25%|██▍       | 1458/5922 [44:04<2:08:29,  1.73s/it] 25%|██▍       | 1459/5922 [44:06<2:12:27,  1.78s/it] 25%|██▍       | 1460/5922 [44:08<2:11:43,  1.77s/it] 25%|██▍       | 1461/5922 [44:10<2:15:38,  1.82s/it] 25%|██▍       | 1462/5922 [44:12<2:27:53,  1.99s/it] 25%|██▍       | 1463/5922 [44:14<2:14:00,  1.80s/it] 25%|██▍       | 1464/5922 [44:16<2:17:01,  1.84s/it] 25%|██▍       | 1465/5922 [44:17<2:15:41,  1.83s/it] 25%|██▍       | 1466/5922 [44:19<2:07:20,  1.71s/it] 25%|██▍       | 1467/5922 [44:20<1:59:52,  1.61s/it] 25%|██▍       | 1468/5922 [44:22<2:07:58,  1.72s/it] 25%|██▍       | 1469/5922 [44:24<2:15:46,  1.83s/it] 25%|██▍       | 1470/5922 [44:26<2:21:02,  1.90s/it] 25%|██▍       | 1471/5922 [44:29<2:33:51,  2.07s/it] 25%|██▍       | 1472/5922 [44:30<2:18:15,  1.86s/it] 25%|██▍       | 1473/5922 [44:32<2:20:02,  1.89s/it] 25%|██▍       | 1474/5922 [44:34<2:22:11,  1.92s/it] 25%|██▍       | 1475/5922 [44:36<2:11:28,  1.77s/it]                                                     {'loss': 0.1572, 'grad_norm': 0.3536692723072068, 'learning_rate': 1.740033679213342e-05, 'epoch': 0.75}
 25%|██▍       | 1475/5922 [44:36<2:11:28,  1.77s/it] 25%|██▍       | 1476/5922 [44:38<2:12:55,  1.79s/it] 25%|██▍       | 1477/5922 [44:40<2:18:22,  1.87s/it] 25%|██▍       | 1478/5922 [44:41<2:18:27,  1.87s/it] 25%|██▍       | 1479/5922 [44:44<2:27:21,  1.99s/it] 25%|██▍       | 1480/5922 [44:46<2:25:52,  1.97s/it] 25%|██▌       | 1481/5922 [44:47<2:18:44,  1.87s/it] 25%|██▌       | 1482/5922 [44:50<2:31:27,  2.05s/it] 25%|██▌       | 1483/5922 [44:51<2:21:54,  1.92s/it] 25%|██▌       | 1484/5922 [44:53<2:10:14,  1.76s/it] 25%|██▌       | 1485/5922 [44:55<2:15:00,  1.83s/it] 25%|██▌       | 1486/5922 [44:57<2:29:12,  2.02s/it] 25%|██▌       | 1487/5922 [45:00<2:39:05,  2.15s/it] 25%|██▌       | 1488/5922 [45:02<2:33:47,  2.08s/it] 25%|██▌       | 1489/5922 [45:03<2:17:11,  1.86s/it] 25%|██▌       | 1490/5922 [45:05<2:12:36,  1.80s/it] 25%|██▌       | 1491/5922 [45:06<2:15:44,  1.84s/it] 25%|██▌       | 1492/5922 [45:08<2:05:33,  1.70s/it] 25%|██▌       | 1493/5922 [45:10<2:11:03,  1.78s/it] 25%|██▌       | 1494/5922 [45:12<2:14:14,  1.82s/it] 25%|██▌       | 1495/5922 [45:14<2:15:52,  1.84s/it] 25%|██▌       | 1496/5922 [45:16<2:27:35,  2.00s/it] 25%|██▌       | 1497/5922 [45:18<2:26:44,  1.99s/it] 25%|██▌       | 1498/5922 [45:20<2:20:24,  1.90s/it] 25%|██▌       | 1499/5922 [45:21<2:09:37,  1.76s/it] 25%|██▌       | 1500/5922 [45:24<2:24:48,  1.96s/it]                                                     {'loss': 0.16, 'grad_norm': 0.33893936992358265, 'learning_rate': 1.731223600671147e-05, 'epoch': 0.76}
 25%|██▌       | 1500/5922 [45:24<2:24:48,  1.96s/it][INFO|trainer.py:3993] 2025-08-30 14:34:15,278 >> Saving model checkpoint to saves/qwen3-1.7B/lora/sft/checkpoint-1500
[INFO|configuration_utils.py:696] 2025-08-30 14:34:15,291 >> loading configuration file /home/qianwenhao/LLM/Qwen3-1.7B/config.json
[INFO|configuration_utils.py:770] 2025-08-30 14:34:15,291 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "max_position_embeddings": 40960,
  "max_window_layers": 28,
  "model_type": "qwen3",
  "num_attention_heads": 16,
  "num_hidden_layers": 28,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|tokenization_utils_base.py:2356] 2025-08-30 14:34:15,307 >> chat template saved in saves/qwen3-1.7B/lora/sft/checkpoint-1500/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-08-30 14:34:15,307 >> tokenizer config file saved in saves/qwen3-1.7B/lora/sft/checkpoint-1500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-08-30 14:34:15,308 >> Special tokens file saved in saves/qwen3-1.7B/lora/sft/checkpoint-1500/special_tokens_map.json
[2025-08-30 14:34:15,472] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step1500 is about to be saved!
[2025-08-30 14:34:15,481] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: saves/qwen3-1.7B/lora/sft/checkpoint-1500/global_step1500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-08-30 14:34:15,481] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-1500/global_step1500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-08-30 14:34:15,487] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-1500/global_step1500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-08-30 14:34:15,488] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-1500/global_step1500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-08-30 14:34:15,499] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-1500/global_step1500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-08-30 14:34:15,499] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved saves/qwen3-1.7B/lora/sft/checkpoint-1500/global_step1500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-08-30 14:34:15,508] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
 25%|██▌       | 1501/5922 [45:27<3:00:45,  2.45s/it] 25%|██▌       | 1502/5922 [45:29<2:48:33,  2.29s/it] 25%|██▌       | 1503/5922 [45:31<2:33:56,  2.09s/it] 25%|██▌       | 1504/5922 [45:32<2:22:48,  1.94s/it] 25%|██▌       | 1505/5922 [45:34<2:21:44,  1.93s/it] 25%|██▌       | 1506/5922 [45:36<2:09:30,  1.76s/it] 25%|██▌       | 1507/5922 [45:37<2:12:40,  1.80s/it] 25%|██▌       | 1508/5922 [45:39<2:07:09,  1.73s/it] 25%|██▌       | 1509/5922 [45:41<2:11:37,  1.79s/it] 25%|██▌       | 1510/5922 [45:43<2:26:23,  1.99s/it] 26%|██▌       | 1511/5922 [45:45<2:12:38,  1.80s/it] 26%|██▌       | 1512/5922 [45:46<2:03:20,  1.68s/it] 26%|██▌       | 1513/5922 [45:47<1:56:34,  1.59s/it] 26%|██▌       | 1514/5922 [45:49<1:51:32,  1.52s/it] 26%|██▌       | 1515/5922 [45:51<1:57:45,  1.60s/it] 26%|██▌       | 1516/5922 [45:52<1:52:59,  1.54s/it] 26%|██▌       | 1517/5922 [45:54<2:04:43,  1.70s/it] 26%|██▌       | 1518/5922 [45:56<2:05:48,  1.71s/it] 26%|██▌       | 1519/5922 [45:58<2:10:36,  1.78s/it] 26%|██▌       | 1520/5922 [46:00<2:11:27,  1.79s/it] 26%|██▌       | 1521/5922 [46:02<2:25:03,  1.98s/it] 26%|██▌       | 1522/5922 [46:04<2:22:12,  1.94s/it] 26%|██▌       | 1523/5922 [46:05<2:11:16,  1.79s/it] 26%|██▌       | 1524/5922 [46:07<2:02:25,  1.67s/it] 26%|██▌       | 1525/5922 [46:08<1:55:53,  1.58s/it]                                                     {'loss': 0.1508, 'grad_norm': 0.4863409249323099, 'learning_rate': 1.7222912376539606e-05, 'epoch': 0.77}
 26%|██▌       | 1525/5922 [46:08<1:55:53,  1.58s/it] 26%|██▌       | 1526/5922 [46:10<2:11:28,  1.79s/it] 26%|██▌       | 1527/5922 [46:12<2:04:52,  1.70s/it] 26%|██▌       | 1528/5922 [46:13<1:57:40,  1.61s/it] 26%|██▌       | 1529/5922 [46:15<2:04:57,  1.71s/it] 26%|██▌       | 1530/5922 [46:17<2:12:11,  1.81s/it] 26%|██▌       | 1531/5922 [46:19<2:09:46,  1.77s/it] 26%|██▌       | 1532/5922 [46:20<2:02:24,  1.67s/it] 26%|██▌       | 1533/5922 [46:23<2:20:03,  1.91s/it] 26%|██▌       | 1534/5922 [46:25<2:17:27,  1.88s/it] 26%|██▌       | 1535/5922 [46:27<2:18:38,  1.90s/it] 26%|██▌       | 1536/5922 [46:29<2:27:33,  2.02s/it] 26%|██▌       | 1537/5922 [46:31<2:27:07,  2.01s/it] 26%|██▌       | 1538/5922 [46:33<2:27:33,  2.02s/it] 26%|██▌       | 1539/5922 [46:34<2:14:06,  1.84s/it] 26%|██▌       | 1540/5922 [46:36<2:04:03,  1.70s/it] 26%|██▌       | 1541/5922 [46:37<2:01:00,  1.66s/it] 26%|██▌       | 1542/5922 [46:40<2:18:39,  1.90s/it] 26%|██▌       | 1543/5922 [46:42<2:19:27,  1.91s/it] 26%|██▌       | 1544/5922 [46:43<2:09:42,  1.78s/it] 26%|██▌       | 1545/5922 [46:45<2:10:57,  1.80s/it] 26%|██▌       | 1546/5922 [46:47<2:07:18,  1.75s/it] 26%|██▌       | 1547/5922 [46:48<2:02:29,  1.68s/it] 26%|██▌       | 1548/5922 [46:49<1:55:49,  1.59s/it] 26%|██▌       | 1549/5922 [46:51<1:59:56,  1.65s/it] 26%|██▌       | 1550/5922 [46:53<2:09:22,  1.78s/it]                                                     {'loss': 0.1577, 'grad_norm': 0.35705258680786534, 'learning_rate': 1.7132381935843898e-05, 'epoch': 0.79}
 26%|██▌       | 1550/5922 [46:53<2:09:22,  1.78s/it] 26%|██▌       | 1551/5922 [46:55<2:12:22,  1.82s/it] 26%|██▌       | 1552/5922 [46:57<2:18:08,  1.90s/it] 26%|██▌       | 1553/5922 [46:59<2:14:58,  1.85s/it] 26%|██▌       | 1554/5922 [47:01<2:24:38,  1.99s/it] 26%|██▋       | 1555/5922 [47:03<2:24:38,  1.99s/it] 26%|██▋       | 1556/5922 [47:05<2:23:10,  1.97s/it] 26%|██▋       | 1557/5922 [47:07<2:15:45,  1.87s/it] 26%|██▋       | 1558/5922 [47:09<2:17:07,  1.89s/it] 26%|██▋       | 1559/5922 [47:11<2:18:39,  1.91s/it] 26%|██▋       | 1560/5922 [47:12<2:08:02,  1.76s/it] 26%|██▋       | 1561/5922 [47:15<2:23:40,  1.98s/it] 26%|██▋       | 1562/5922 [47:16<2:10:58,  1.80s/it] 26%|██▋       | 1563/5922 [47:18<2:13:49,  1.84s/it] 26%|██▋       | 1564/5922 [47:19<2:04:39,  1.72s/it] 26%|██▋       | 1565/5922 [47:21<2:09:09,  1.78s/it] 26%|██▋       | 1566/5922 [47:23<2:02:15,  1.68s/it] 26%|██▋       | 1567/5922 [47:25<2:07:52,  1.76s/it] 26%|██▋       | 1568/5922 [47:26<2:00:29,  1.66s/it] 26%|██▋       | 1569/5922 [47:28<2:06:11,  1.74s/it] 27%|██▋       | 1570/5922 [47:30<2:01:07,  1.67s/it] 27%|██▋       | 1571/5922 [47:31<1:56:08,  1.60s/it] 27%|██▋       | 1572/5922 [47:33<2:03:23,  1.70s/it] 27%|██▋       | 1573/5922 [47:34<1:56:29,  1.61s/it] 27%|██▋       | 1574/5922 [47:36<2:03:30,  1.70s/it] 27%|██▋       | 1575/5922 [47:38<2:12:03,  1.82s/it]                                                     {'loss': 0.1647, 'grad_norm': 0.38236324173097275, 'learning_rate': 1.7040660935481478e-05, 'epoch': 0.8}
 27%|██▋       | 1575/5922 [47:38<2:12:03,  1.82s/it] 27%|██▋       | 1576/5922 [47:40<2:14:22,  1.86s/it] 27%|██▋       | 1577/5922 [47:42<2:12:44,  1.83s/it] 27%|██▋       | 1578/5922 [47:44<2:03:18,  1.70s/it] 27%|██▋       | 1579/5922 [47:45<2:03:04,  1.70s/it] 27%|██▋       | 1580/5922 [47:47<1:59:29,  1.65s/it] 27%|██▋       | 1581/5922 [47:49<2:05:30,  1.73s/it] 27%|██▋       | 1582/5922 [47:50<2:02:39,  1.70s/it] 27%|██▋       | 1583/5922 [47:52<1:59:42,  1.66s/it] 27%|██▋       | 1584/5922 [47:54<2:17:21,  1.90s/it] 27%|██▋       | 1585/5922 [47:56<2:06:54,  1.76s/it] 27%|██▋       | 1586/5922 [47:57<1:59:19,  1.65s/it] 27%|██▋       | 1587/5922 [47:59<1:53:09,  1.57s/it] 27%|██▋       | 1588/5922 [48:00<1:49:10,  1.51s/it] 27%|██▋       | 1589/5922 [48:02<2:06:49,  1.76s/it] 27%|██▋       | 1590/5922 [48:04<2:09:51,  1.80s/it] 27%|██▋       | 1591/5922 [48:06<2:12:41,  1.84s/it] 27%|██▋       | 1592/5922 [48:08<2:03:17,  1.71s/it] 27%|██▋       | 1593/5922 [48:09<1:56:18,  1.61s/it] 27%|██▋       | 1594/5922 [48:11<2:14:58,  1.87s/it] 27%|██▋       | 1595/5922 [48:13<2:04:39,  1.73s/it] 27%|██▋       | 1596/5922 [48:15<2:05:24,  1.74s/it] 27%|██▋       | 1597/5922 [48:16<2:09:43,  1.80s/it] 27%|██▋       | 1598/5922 [48:18<2:13:09,  1.85s/it] 27%|██▋       | 1599/5922 [48:20<2:04:43,  1.73s/it] 27%|██▋       | 1600/5922 [48:21<1:58:05,  1.64s/it]                                                     {'loss': 0.1498, 'grad_norm': 0.4398329669628136, 'learning_rate': 1.6947765840023395e-05, 'epoch': 0.81}
 27%|██▋       | 1600/5922 [48:21<1:58:05,  1.64s/it] 27%|██▋       | 1601/5922 [48:24<2:15:40,  1.88s/it] 27%|██▋       | 1602/5922 [48:25<2:05:14,  1.74s/it] 27%|██▋       | 1603/5922 [48:27<1:58:03,  1.64s/it] 27%|██▋       | 1604/5922 [48:28<1:58:20,  1.64s/it] 27%|██▋       | 1605/5922 [48:30<2:02:56,  1.71s/it] 27%|██▋       | 1606/5922 [48:32<1:56:43,  1.62s/it] 27%|██▋       | 1607/5922 [48:33<1:51:55,  1.56s/it] 27%|██▋       | 1608/5922 [48:34<1:49:21,  1.52s/it] 27%|██▋       | 1609/5922 [48:36<1:58:39,  1.65s/it] 27%|██▋       | 1610/5922 [48:38<2:04:41,  1.74s/it] 27%|██▋       | 1611/5922 [48:40<2:03:56,  1.73s/it] 27%|██▋       | 1612/5922 [48:41<1:59:18,  1.66s/it] 27%|██▋       | 1613/5922 [48:43<1:54:02,  1.59s/it] 27%|██▋       | 1614/5922 [48:44<1:50:10,  1.53s/it] 27%|██▋       | 1615/5922 [48:46<1:59:51,  1.67s/it] 27%|██▋       | 1616/5922 [48:48<1:56:34,  1.62s/it] 27%|██▋       | 1617/5922 [48:50<2:03:27,  1.72s/it] 27%|██▋       | 1618/5922 [48:52<2:19:54,  1.95s/it] 27%|██▋       | 1619/5922 [48:54<2:19:33,  1.95s/it] 27%|██▋       | 1620/5922 [48:56<2:18:11,  1.93s/it] 27%|██▋       | 1621/5922 [48:57<2:06:58,  1.77s/it] 27%|██▋       | 1622/5922 [48:59<1:58:07,  1.65s/it] 27%|██▋       | 1623/5922 [49:00<1:52:06,  1.56s/it] 27%|██▋       | 1624/5922 [49:02<1:57:28,  1.64s/it] 27%|██▋       | 1625/5922 [49:03<1:51:34,  1.56s/it]                                                     {'loss': 0.1531, 'grad_norm': 0.35242356679085146, 'learning_rate': 1.685371332479912e-05, 'epoch': 0.82}
 27%|██▋       | 1625/5922 [49:03<1:51:34,  1.56s/it] 27%|██▋       | 1626/5922 [49:05<1:47:43,  1.50s/it] 27%|██▋       | 1627/5922 [49:07<1:57:09,  1.64s/it] 27%|██▋       | 1628/5922 [49:08<1:51:21,  1.56s/it] 28%|██▊       | 1629/5922 [49:10<1:58:59,  1.66s/it] 28%|██▊       | 1630/5922 [49:11<1:55:41,  1.62s/it] 28%|██▊       | 1631/5922 [49:13<2:01:57,  1.71s/it] 28%|██▊       | 1632/5922 [49:15<2:03:20,  1.73s/it] 28%|██▊       | 1633/5922 [49:17<2:00:00,  1.68s/it] 28%|██▊       | 1634/5922 [49:18<1:55:25,  1.62s/it] 28%|██▊       | 1635/5922 [49:21<2:14:49,  1.89s/it] 28%|██▊       | 1636/5922 [49:23<2:16:58,  1.92s/it] 28%|██▊       | 1637/5922 [49:24<2:09:03,  1.81s/it] 28%|██▊       | 1638/5922 [49:26<2:02:29,  1.72s/it] 28%|██▊       | 1639/5922 [49:28<2:17:18,  1.92s/it] 28%|██▊       | 1640/5922 [49:30<2:12:57,  1.86s/it] 28%|██▊       | 1641/5922 [49:32<2:09:14,  1.81s/it] 28%|██▊       | 1642/5922 [49:33<2:05:22,  1.76s/it] 28%|██▊       | 1643/5922 [49:35<1:58:14,  1.66s/it] 28%|██▊       | 1644/5922 [49:37<2:12:16,  1.86s/it] 28%|██▊       | 1645/5922 [49:38<2:04:01,  1.74s/it] 28%|██▊       | 1646/5922 [49:40<1:59:15,  1.67s/it] 28%|██▊       | 1647/5922 [49:42<2:05:18,  1.76s/it] 28%|██▊       | 1648/5922 [49:44<2:16:54,  1.92s/it] 28%|██▊       | 1649/5922 [49:46<2:15:01,  1.90s/it] 28%|██▊       | 1650/5922 [49:48<2:07:47,  1.79s/it]                                                     {'loss': 0.1497, 'grad_norm': 0.4621041385336183, 'learning_rate': 1.6758520272903174e-05, 'epoch': 0.84}
 28%|██▊       | 1650/5922 [49:48<2:07:47,  1.79s/it] 28%|██▊       | 1651/5922 [49:49<2:00:06,  1.69s/it] 28%|██▊       | 1652/5922 [49:51<2:06:09,  1.77s/it] 28%|██▊       | 1653/5922 [49:53<2:08:17,  1.80s/it] 28%|██▊       | 1654/5922 [49:54<2:03:47,  1.74s/it] 28%|██▊       | 1655/5922 [49:56<2:09:20,  1.82s/it] 28%|██▊       | 1656/5922 [49:58<2:12:49,  1.87s/it] 28%|██▊       | 1657/5922 [50:00<2:11:43,  1.85s/it] 28%|██▊       | 1658/5922 [50:02<2:05:17,  1.76s/it] 28%|██▊       | 1659/5922 [50:03<2:03:17,  1.74s/it] 28%|██▊       | 1660/5922 [50:05<1:58:06,  1.66s/it] 28%|██▊       | 1661/5922 [50:07<2:07:12,  1.79s/it] 28%|██▊       | 1662/5922 [50:09<2:11:32,  1.85s/it] 28%|██▊       | 1663/5922 [50:11<2:15:09,  1.90s/it] 28%|██▊       | 1664/5922 [50:13<2:06:05,  1.78s/it] 28%|██▊       | 1665/5922 [50:14<2:00:00,  1.69s/it] 28%|██▊       | 1666/5922 [50:16<2:05:43,  1.77s/it] 28%|██▊       | 1667/5922 [50:18<2:00:52,  1.70s/it] 28%|██▊       | 1668/5922 [50:19<2:00:34,  1.70s/it] 28%|██▊       | 1669/5922 [50:21<2:04:17,  1.75s/it] 28%|██▊       | 1670/5922 [50:23<1:58:28,  1.67s/it] 28%|██▊       | 1671/5922 [50:25<2:06:47,  1.79s/it] 28%|██▊       | 1672/5922 [50:26<2:00:21,  1.70s/it] 28%|██▊       | 1673/5922 [50:28<1:58:14,  1.67s/it] 28%|██▊       | 1674/5922 [50:29<1:55:13,  1.63s/it] 28%|██▊       | 1675/5922 [50:31<1:54:11,  1.61s/it]                                                     {'loss': 0.1363, 'grad_norm': 0.31875909326044194, 'learning_rate': 1.666220377216452e-05, 'epoch': 0.85}
 28%|██▊       | 1675/5922 [50:31<1:54:11,  1.61s/it] 28%|██▊       | 1676/5922 [50:32<1:52:12,  1.59s/it] 28%|██▊       | 1677/5922 [50:34<1:50:49,  1.57s/it] 28%|██▊       | 1678/5922 [50:36<1:56:01,  1.64s/it] 28%|██▊       | 1679/5922 [50:37<1:51:13,  1.57s/it] 28%|██▊       | 1680/5922 [50:39<1:58:43,  1.68s/it] 28%|██▊       | 1681/5922 [50:41<2:04:36,  1.76s/it] 28%|██▊       | 1682/5922 [50:44<2:19:31,  1.97s/it] 28%|██▊       | 1683/5922 [50:45<2:06:45,  1.79s/it] 28%|██▊       | 1684/5922 [50:46<1:58:30,  1.68s/it] 28%|██▊       | 1685/5922 [50:48<1:52:17,  1.59s/it] 28%|██▊       | 1686/5922 [50:49<1:52:44,  1.60s/it] 28%|██▊       | 1687/5922 [50:51<1:48:30,  1.54s/it] 29%|██▊       | 1688/5922 [50:52<1:48:45,  1.54s/it] 29%|██▊       | 1689/5922 [50:54<1:46:09,  1.50s/it] 29%|██▊       | 1690/5922 [50:55<1:45:00,  1.49s/it] 29%|██▊       | 1691/5922 [50:57<2:03:12,  1.75s/it] 29%|██▊       | 1692/5922 [50:59<2:01:07,  1.72s/it] 29%|██▊       | 1693/5922 [51:01<1:58:18,  1.68s/it] 29%|██▊       | 1694/5922 [51:03<2:03:37,  1.75s/it] 29%|██▊       | 1695/5922 [51:05<2:07:02,  1.80s/it] 29%|██▊       | 1696/5922 [51:07<2:14:11,  1.91s/it] 29%|██▊       | 1697/5922 [51:09<2:20:40,  2.00s/it] 29%|██▊       | 1698/5922 [51:11<2:19:34,  1.98s/it] 29%|██▊       | 1699/5922 [51:13<2:18:51,  1.97s/it] 29%|██▊       | 1700/5922 [51:15<2:17:52,  1.96s/it]                                                     {'loss': 0.1584, 'grad_norm': 0.4014893520177951, 'learning_rate': 1.6564781112079175e-05, 'epoch': 0.86}
 29%|██▊       | 1700/5922 [51:15<2:17:52,  1.96s/it] 29%|██▊       | 1701/5922 [51:17<2:23:15,  2.04s/it] 29%|██▊       | 1702/5922 [51:18<2:09:00,  1.83s/it] 29%|██▉       | 1703/5922 [51:21<2:22:18,  2.02s/it] 29%|██▉       | 1704/5922 [51:22<2:10:27,  1.86s/it] 29%|██▉       | 1705/5922 [51:24<2:04:07,  1.77s/it] 29%|██▉       | 1706/5922 [51:25<1:55:20,  1.64s/it] 29%|██▉       | 1707/5922 [51:27<2:04:19,  1.77s/it] 29%|██▉       | 1708/5922 [51:30<2:18:43,  1.98s/it] 29%|██▉       | 1709/5922 [51:31<2:11:15,  1.87s/it] 29%|██▉       | 1710/5922 [51:33<2:02:14,  1.74s/it] 29%|██▉       | 1711/5922 [51:35<2:06:29,  1.80s/it] 29%|██▉       | 1712/5922 [51:37<2:08:58,  1.84s/it] 29%|██▉       | 1713/5922 [51:39<2:11:08,  1.87s/it] 29%|██▉       | 1714/5922 [51:40<2:12:24,  1.89s/it] 29%|██▉       | 1715/5922 [51:42<2:12:44,  1.89s/it] 29%|██▉       | 1716/5922 [51:44<2:13:00,  1.90s/it] 29%|██▉       | 1717/5922 [51:46<2:09:21,  1.85s/it] 29%|██▉       | 1718/5922 [51:48<2:01:51,  1.74s/it] 29%|██▉       | 1719/5922 [51:49<1:54:19,  1.63s/it] 29%|██▉       | 1720/5922 [51:51<2:08:20,  1.83s/it] 29%|██▉       | 1721/5922 [51:53<2:17:18,  1.96s/it] 29%|██▉       | 1722/5922 [51:55<2:16:29,  1.95s/it] 29%|██▉       | 1723/5922 [51:58<2:22:12,  2.03s/it] 29%|██▉       | 1724/5922 [51:59<2:07:55,  1.83s/it] 29%|██▉       | 1725/5922 [52:01<2:21:14,  2.02s/it]                                                     {'loss': 0.1555, 'grad_norm': 0.38463766636756835, 'learning_rate': 1.6466269780706602e-05, 'epoch': 0.87}
 29%|██▉       | 1725/5922 [52:01<2:21:14,  2.02s/it] 29%|██▉       | 1726/5922 [52:03<2:22:13,  2.03s/it] 29%|██▉       | 1727/5922 [52:05<2:21:43,  2.03s/it] 29%|██▉       | 1728/5922 [52:07<2:19:38,  2.00s/it] 29%|██▉       | 1729/5922 [52:09<2:06:33,  1.81s/it] 29%|██▉       | 1730/5922 [52:11<2:09:00,  1.85s/it] 29%|██▉       | 1731/5922 [52:12<1:59:43,  1.71s/it] 29%|██▉       | 1732/5922 [52:13<1:52:02,  1.60s/it] 29%|██▉       | 1733/5922 [52:15<1:46:49,  1.53s/it] 29%|██▉       | 1734/5922 [52:17<1:54:21,  1.64s/it] 29%|██▉       | 1735/5922 [52:18<1:50:14,  1.58s/it] 29%|██▉       | 1736/5922 [52:20<1:48:48,  1.56s/it] 29%|██▉       | 1737/5922 [52:21<1:45:30,  1.51s/it] 29%|██▉       | 1738/5922 [52:24<2:05:23,  1.80s/it] 29%|██▉       | 1739/5922 [52:25<1:57:55,  1.69s/it] 29%|██▉       | 1740/5922 [52:26<1:51:15,  1.60s/it] 29%|██▉       | 1741/5922 [52:28<1:49:57,  1.58s/it] 29%|██▉       | 1742/5922 [52:30<1:54:22,  1.64s/it] 29%|██▉       | 1743/5922 [52:31<1:49:08,  1.57s/it] 29%|██▉       | 1744/5922 [52:33<1:56:38,  1.68s/it] 29%|██▉       | 1745/5922 [52:35<2:09:18,  1.86s/it] 29%|██▉       | 1746/5922 [52:37<2:10:41,  1.88s/it] 30%|██▉       | 1747/5922 [52:39<1:59:48,  1.72s/it] 30%|██▉       | 1748/5922 [52:41<2:04:01,  1.78s/it] 30%|██▉       | 1749/5922 [52:42<1:57:04,  1.68s/it] 30%|██▉       | 1750/5922 [52:43<1:50:53,  1.59s/it]                                                     {'loss': 0.1426, 'grad_norm': 0.3974191610932245, 'learning_rate': 1.6366687461530504e-05, 'epoch': 0.89}
 30%|██▉       | 1750/5922 [52:43<1:50:53,  1.59s/it] 30%|██▉       | 1751/5922 [52:45<1:57:42,  1.69s/it] 30%|██▉       | 1752/5922 [52:47<1:51:22,  1.60s/it] 30%|██▉       | 1753/5922 [52:49<1:58:15,  1.70s/it] 30%|██▉       | 1754/5922 [52:51<2:02:39,  1.77s/it] 30%|██▉       | 1755/5922 [52:53<2:17:30,  1.98s/it] 30%|██▉       | 1756/5922 [52:54<2:05:17,  1.80s/it] 30%|██▉       | 1757/5922 [52:56<1:56:52,  1.68s/it] 30%|██▉       | 1758/5922 [52:58<2:00:01,  1.73s/it] 30%|██▉       | 1759/5922 [52:59<2:02:45,  1.77s/it] 30%|██▉       | 1760/5922 [53:01<2:05:33,  1.81s/it] 30%|██▉       | 1761/5922 [53:04<2:12:08,  1.91s/it] 30%|██▉       | 1762/5922 [53:05<2:11:23,  1.90s/it] 30%|██▉       | 1763/5922 [53:07<2:14:53,  1.95s/it] 30%|██▉       | 1764/5922 [53:09<2:14:40,  1.94s/it] 30%|██▉       | 1765/5922 [53:11<2:03:24,  1.78s/it] 30%|██▉       | 1766/5922 [53:13<2:10:08,  1.88s/it] 30%|██▉       | 1767/5922 [53:14<2:04:03,  1.79s/it] 30%|██▉       | 1768/5922 [53:16<1:56:56,  1.69s/it] 30%|██▉       | 1769/5922 [53:17<1:50:43,  1.60s/it] 30%|██▉       | 1770/5922 [53:19<1:46:05,  1.53s/it] 30%|██▉       | 1771/5922 [53:21<1:52:45,  1.63s/it] 30%|██▉       | 1772/5922 [53:22<1:48:45,  1.57s/it] 30%|██▉       | 1773/5922 [53:23<1:45:12,  1.52s/it] 30%|██▉       | 1774/5922 [53:25<1:42:37,  1.48s/it] 30%|██▉       | 1775/5922 [53:26<1:41:01,  1.46s/it]                                                     {'loss': 0.1476, 'grad_norm': 0.35327456597522683, 'learning_rate': 1.6266052030284493e-05, 'epoch': 0.9}
 30%|██▉       | 1775/5922 [53:26<1:41:01,  1.46s/it] 30%|██▉       | 1776/5922 [53:28<1:40:00,  1.45s/it] 30%|███       | 1777/5922 [53:29<1:38:42,  1.43s/it] 30%|███       | 1778/5922 [53:30<1:37:28,  1.41s/it] 30%|███       | 1779/5922 [53:32<1:40:40,  1.46s/it] 30%|███       | 1780/5922 [53:33<1:41:25,  1.47s/it] 30%|███       | 1781/5922 [53:35<1:43:26,  1.50s/it] 30%|███       | 1782/5922 [53:36<1:42:02,  1.48s/it] 30%|███       | 1783/5922 [53:38<1:49:13,  1.58s/it] 30%|███       | 1784/5922 [53:40<2:00:15,  1.74s/it] 30%|███       | 1785/5922 [53:42<1:57:04,  1.70s/it] 30%|███       | 1786/5922 [53:44<2:01:27,  1.76s/it] 30%|███       | 1787/5922 [53:45<1:53:14,  1.64s/it] 30%|███       | 1788/5922 [53:47<1:48:27,  1.57s/it] 30%|███       | 1789/5922 [53:49<1:55:30,  1.68s/it] 30%|███       | 1790/5922 [53:50<1:50:11,  1.60s/it] 30%|███       | 1791/5922 [53:52<2:07:44,  1.86s/it] 30%|███       | 1792/5922 [53:55<2:20:15,  2.04s/it] 30%|███       | 1793/5922 [53:56<2:07:29,  1.85s/it] 30%|███       | 1794/5922 [53:58<2:10:15,  1.89s/it] 30%|███       | 1795/5922 [54:00<1:59:41,  1.74s/it] 30%|███       | 1796/5922 [54:01<1:53:10,  1.65s/it] 30%|███       | 1797/5922 [54:03<2:00:36,  1.75s/it] 30%|███       | 1798/5922 [54:05<2:04:21,  1.81s/it] 30%|███       | 1799/5922 [54:07<1:59:19,  1.74s/it] 30%|███       | 1800/5922 [54:08<1:52:11,  1.63s/it]                                                     {'loss': 0.1436, 'grad_norm': 0.46759066537056987, 'learning_rate': 1.616438155174329e-05, 'epoch': 0.91}
 30%|███       | 1800/5922 [54:08<1:52:11,  1.63s/it] 30%|███       | 1801/5922 [54:10<1:59:33,  1.74s/it] 30%|███       | 1802/5922 [54:13<2:15:06,  1.97s/it] 30%|███       | 1803/5922 [54:14<2:07:43,  1.86s/it] 30%|███       | 1804/5922 [54:16<1:57:59,  1.72s/it] 30%|███       | 1805/5922 [54:17<1:51:19,  1.62s/it] 30%|███       | 1806/5922 [54:19<1:56:59,  1.71s/it] 31%|███       | 1807/5922 [54:20<1:51:34,  1.63s/it] 31%|███       | 1808/5922 [54:22<1:58:31,  1.73s/it] 31%|███       | 1809/5922 [54:24<2:00:00,  1.75s/it] 31%|███       | 1810/5922 [54:26<2:02:46,  1.79s/it] 31%|███       | 1811/5922 [54:28<1:58:28,  1.73s/it] 31%|███       | 1812/5922 [54:29<2:01:27,  1.77s/it] 31%|███       | 1813/5922 [54:31<2:02:02,  1.78s/it] 31%|███       | 1814/5922 [54:33<2:08:59,  1.88s/it] 31%|███       | 1815/5922 [54:36<2:19:33,  2.04s/it] 31%|███       | 1816/5922 [54:38<2:16:44,  2.00s/it] 31%|███       | 1817/5922 [54:40<2:15:33,  1.98s/it] 31%|███       | 1818/5922 [54:42<2:21:15,  2.07s/it] 31%|███       | 1819/5922 [54:43<2:07:19,  1.86s/it] 31%|███       | 1820/5922 [54:45<1:59:40,  1.75s/it] 31%|███       | 1821/5922 [54:46<1:56:14,  1.70s/it] 31%|███       | 1822/5922 [54:48<2:05:17,  1.83s/it] 31%|███       | 1823/5922 [54:50<2:05:46,  1.84s/it] 31%|███       | 1824/5922 [54:52<1:57:33,  1.72s/it] 31%|███       | 1825/5922 [54:54<2:01:37,  1.78s/it]                                                     {'loss': 0.1498, 'grad_norm': 0.36769852268500397, 'learning_rate': 1.6061694276479942e-05, 'epoch': 0.92}
 31%|███       | 1825/5922 [54:54<2:01:37,  1.78s/it] 31%|███       | 1826/5922 [54:56<2:15:23,  1.98s/it] 31%|███       | 1827/5922 [54:58<2:08:16,  1.88s/it] 31%|███       | 1828/5922 [54:59<1:58:16,  1.73s/it] 31%|███       | 1829/5922 [55:01<2:00:50,  1.77s/it] 31%|███       | 1830/5922 [55:02<1:53:22,  1.66s/it] 31%|███       | 1831/5922 [55:04<1:47:34,  1.58s/it] 31%|███       | 1832/5922 [55:06<1:57:33,  1.72s/it] 31%|███       | 1833/5922 [55:07<1:50:55,  1.63s/it] 31%|███       | 1834/5922 [55:10<2:04:59,  1.83s/it] 31%|███       | 1835/5922 [55:11<1:56:23,  1.71s/it] 31%|███       | 1836/5922 [55:13<2:11:11,  1.93s/it] 31%|███       | 1837/5922 [55:15<2:05:45,  1.85s/it] 31%|███       | 1838/5922 [55:17<2:06:18,  1.86s/it] 31%|███       | 1839/5922 [55:19<2:16:28,  2.01s/it] 31%|███       | 1840/5922 [55:22<2:24:27,  2.12s/it] 31%|███       | 1841/5922 [55:23<2:09:03,  1.90s/it] 31%|███       | 1842/5922 [55:25<2:10:19,  1.92s/it] 31%|███       | 1843/5922 [55:27<2:10:43,  1.92s/it] 31%|███       | 1844/5922 [55:29<2:21:55,  2.09s/it] 31%|███       | 1845/5922 [55:31<2:07:40,  1.88s/it] 31%|███       | 1846/5922 [55:33<2:08:40,  1.89s/it] 31%|███       | 1847/5922 [55:35<2:08:54,  1.90s/it] 31%|███       | 1848/5922 [55:37<2:09:23,  1.91s/it] 31%|███       | 1849/5922 [55:39<2:20:45,  2.07s/it] 31%|███       | 1850/5922 [55:42<2:29:00,  2.20s/it]                                                     {'loss': 0.1587, 'grad_norm': 0.44762991694667903, 'learning_rate': 1.595800863758974e-05, 'epoch': 0.94}
 31%|███       | 1850/5922 [55:42<2:29:00,  2.20s/it] 31%|███▏      | 1851/5922 [55:43<2:12:40,  1.96s/it] 31%|███▏      | 1852/5922 [55:45<2:21:48,  2.09s/it] 31%|███▏      | 1853/5922 [55:47<2:08:03,  1.89s/it] 31%|███▏      | 1854/5922 [55:49<2:07:42,  1.88s/it] 31%|███▏      | 1855/5922 [55:51<2:08:29,  1.90s/it] 31%|███▏      | 1856/5922 [55:52<1:59:04,  1.76s/it] 31%|███▏      | 1857/5922 [55:54<1:54:49,  1.69s/it] 31%|███▏      | 1858/5922 [55:55<1:48:57,  1.61s/it] 31%|███▏      | 1859/5922 [55:56<1:45:01,  1.55s/it] 31%|███▏      | 1860/5922 [55:58<1:51:00,  1.64s/it] 31%|███▏      | 1861/5922 [56:00<1:45:47,  1.56s/it] 31%|███▏      | 1862/5922 [56:02<1:53:07,  1.67s/it] 31%|███▏      | 1863/5922 [56:03<1:50:03,  1.63s/it] 31%|███▏      | 1864/5922 [56:05<2:03:25,  1.83s/it] 31%|███▏      | 1865/5922 [56:07<1:59:05,  1.76s/it] 32%|███▏      | 1866/5922 [56:08<1:51:46,  1.65s/it] 32%|███▏      | 1867/5922 [56:10<1:57:54,  1.74s/it] 32%|███▏      | 1868/5922 [56:12<1:50:49,  1.64s/it] 32%|███▏      | 1869/5922 [56:14<1:54:50,  1.70s/it] 32%|███▏      | 1870/5922 [56:15<1:56:13,  1.72s/it] 32%|███▏      | 1871/5922 [56:18<2:11:05,  1.94s/it] 32%|███▏      | 1872/5922 [56:20<2:16:43,  2.03s/it] 32%|███▏      | 1873/5922 [56:22<2:17:46,  2.04s/it] 32%|███▏      | 1874/5922 [56:24<2:24:00,  2.13s/it] 32%|███▏      | 1875/5922 [56:26<2:19:31,  2.07s/it]                                                     {'loss': 0.1527, 'grad_norm': 0.4293487902522054, 'learning_rate': 1.5853343247381336e-05, 'epoch': 0.95}
 32%|███▏      | 1875/5922 [56:26<2:19:31,  2.07s/it] 32%|███▏      | 1876/5922 [56:28<2:14:15,  1.99s/it] 32%|███▏      | 1877/5922 [56:30<2:12:55,  1.97s/it] 32%|███▏      | 1878/5922 [56:32<2:14:47,  2.00s/it] 32%|███▏      | 1879/5922 [56:34<2:13:35,  1.98s/it] 32%|███▏      | 1880/5922 [56:36<2:06:06,  1.87s/it] 32%|███▏      | 1881/5922 [56:37<2:04:24,  1.85s/it] 32%|███▏      | 1882/5922 [56:39<1:59:32,  1.78s/it] 32%|███▏      | 1883/5922 [56:40<1:51:36,  1.66s/it] 32%|███▏      | 1884/5922 [56:42<1:51:07,  1.65s/it] 32%|███▏      | 1885/5922 [56:44<1:57:28,  1.75s/it] 32%|███▏      | 1886/5922 [56:46<1:51:26,  1.66s/it] 32%|███▏      | 1887/5922 [56:47<1:46:05,  1.58s/it] 32%|███▏      | 1888/5922 [56:49<1:53:37,  1.69s/it] 32%|███▏      | 1889/5922 [56:51<1:56:33,  1.73s/it] 32%|███▏      | 1890/5922 [56:52<1:49:25,  1.63s/it] 32%|███▏      | 1891/5922 [56:54<1:52:59,  1.68s/it] 32%|███▏      | 1892/5922 [56:56<1:58:45,  1.77s/it] 32%|███▏      | 1893/5922 [56:57<1:51:10,  1.66s/it] 32%|███▏      | 1894/5922 [56:59<1:48:24,  1.61s/it] 32%|███▏      | 1895/5922 [57:00<1:43:49,  1.55s/it] 32%|███▏      | 1896/5922 [57:02<1:40:51,  1.50s/it] 32%|███▏      | 1897/5922 [57:03<1:47:02,  1.60s/it] 32%|███▏      | 1898/5922 [57:05<1:43:40,  1.55s/it] 32%|███▏      | 1899/5922 [57:07<1:51:20,  1.66s/it] 32%|███▏      | 1900/5922 [57:08<1:46:42,  1.59s/it]                                                     {'loss': 0.1432, 'grad_norm': 0.40623761592536023, 'learning_rate': 1.5747716894035702e-05, 'epoch': 0.96}
 32%|███▏      | 1900/5922 [57:08<1:46:42,  1.59s/it] 32%|███▏      | 1901/5922 [57:10<1:42:11,  1.52s/it] 32%|███▏      | 1902/5922 [57:12<1:54:09,  1.70s/it] 32%|███▏      | 1903/5922 [57:14<2:02:04,  1.82s/it] 32%|███▏      | 1904/5922 [57:16<2:06:42,  1.89s/it] 32%|███▏      | 1905/5922 [57:18<2:07:18,  1.90s/it] 32%|███▏      | 1906/5922 [57:19<1:57:03,  1.75s/it] 32%|███▏      | 1907/5922 [57:21<2:00:06,  1.79s/it] 32%|███▏      | 1908/5922 [57:23<2:02:32,  1.83s/it] 32%|███▏      | 1909/5922 [57:24<1:54:47,  1.72s/it] 32%|███▏      | 1910/5922 [57:26<1:59:19,  1.78s/it] 32%|███▏      | 1911/5922 [57:28<2:02:08,  1.83s/it] 32%|███▏      | 1912/5922 [57:30<1:53:07,  1.69s/it] 32%|███▏      | 1913/5922 [57:32<2:01:55,  1.82s/it] 32%|███▏      | 1914/5922 [57:34<2:04:41,  1.87s/it] 32%|███▏      | 1915/5922 [57:35<2:01:01,  1.81s/it] 32%|███▏      | 1916/5922 [57:37<1:52:24,  1.68s/it] 32%|███▏      | 1917/5922 [57:38<1:46:00,  1.59s/it] 32%|███▏      | 1918/5922 [57:40<1:54:21,  1.71s/it] 32%|███▏      | 1919/5922 [57:42<1:57:03,  1.75s/it] 32%|███▏      | 1920/5922 [57:44<1:57:50,  1.77s/it] 32%|███▏      | 1921/5922 [57:46<2:01:31,  1.82s/it] 32%|███▏      | 1922/5922 [57:48<2:14:45,  2.02s/it] 32%|███▏      | 1923/5922 [57:50<2:12:34,  1.99s/it] 32%|███▏      | 1924/5922 [57:52<2:13:07,  2.00s/it] 33%|███▎      | 1925/5922 [57:54<2:17:17,  2.06s/it]                                                     {'loss': 0.1528, 'grad_norm': 0.3321845885240345, 'learning_rate': 1.5641148538233513e-05, 'epoch': 0.98}
 33%|███▎      | 1925/5922 [57:54<2:17:17,  2.06s/it] 33%|███▎      | 1926/5922 [57:56<2:15:08,  2.03s/it] 33%|███▎      | 1927/5922 [57:59<2:24:03,  2.16s/it] 33%|███▎      | 1928/5922 [58:00<2:11:16,  1.97s/it] 33%|███▎      | 1929/5922 [58:02<2:01:19,  1.82s/it] 33%|███▎      | 1930/5922 [58:03<1:54:42,  1.72s/it] 33%|███▎      | 1931/5922 [58:05<1:58:31,  1.78s/it] 33%|███▎      | 1932/5922 [58:07<1:52:37,  1.69s/it] 33%|███▎      | 1933/5922 [58:08<1:50:39,  1.66s/it] 33%|███▎      | 1934/5922 [58:10<1:55:44,  1.74s/it] 33%|███▎      | 1935/5922 [58:12<1:48:41,  1.64s/it] 33%|███▎      | 1936/5922 [58:14<1:56:05,  1.75s/it] 33%|███▎      | 1937/5922 [58:15<1:52:58,  1.70s/it] 33%|███▎      | 1938/5922 [58:17<1:46:57,  1.61s/it] 33%|███▎      | 1939/5922 [58:19<1:54:32,  1.73s/it] 33%|███▎      | 1940/5922 [58:20<1:52:25,  1.69s/it] 33%|███▎      | 1941/5922 [58:22<2:00:34,  1.82s/it] 33%|███▎      | 1942/5922 [58:25<2:12:59,  2.00s/it] 33%|███▎      | 1943/5922 [58:27<2:11:22,  1.98s/it] 33%|███▎      | 1944/5922 [58:29<2:19:56,  2.11s/it] 33%|███▎      | 1945/5922 [58:31<2:05:25,  1.89s/it] 33%|███▎      | 1946/5922 [58:32<1:55:51,  1.75s/it] 33%|███▎      | 1947/5922 [58:33<1:48:55,  1.64s/it] 33%|███▎      | 1948/5922 [58:36<2:04:21,  1.88s/it] 33%|███▎      | 1949/5922 [58:38<2:05:30,  1.90s/it] 33%|███▎      | 1950/5922 [58:39<1:55:24,  1.74s/it]                                                     {'loss': 0.1503, 'grad_norm': 0.35294398206880284, 'learning_rate': 1.5533657309751586e-05, 'epoch': 0.99}
 33%|███▎      | 1950/5922 [58:39<1:55:24,  1.74s/it] 33%|███▎      | 1951/5922 [58:41<1:56:16,  1.76s/it] 33%|███▎      | 1952/5922 [58:42<1:49:05,  1.65s/it] 33%|███▎      | 1953/5922 [58:44<1:53:07,  1.71s/it] 33%|███▎      | 1954/5922 [58:46<1:48:22,  1.64s/it] 33%|███▎      | 1955/5922 [58:47<1:43:57,  1.57s/it] 33%|███▎      | 1956/5922 [58:49<1:42:29,  1.55s/it] 33%|███▎      | 1957/5922 [58:50<1:39:41,  1.51s/it] 33%|███▎      | 1958/5922 [58:51<1:40:35,  1.52s/it] 33%|███▎      | 1959/5922 [58:53<1:39:23,  1.50s/it] 33%|███▎      | 1960/5922 [58:55<1:47:47,  1.63s/it] 33%|███▎      | 1961/5922 [58:57<1:52:42,  1.71s/it] 33%|███▎      | 1962/5922 [58:59<2:08:42,  1.95s/it] 33%|███▎      | 1963/5922 [59:01<2:01:22,  1.84s/it] 33%|███▎      | 1964/5922 [59:03<1:59:50,  1.82s/it] 33%|███▎      | 1965/5922 [59:05<2:07:38,  1.94s/it] 33%|███▎      | 1966/5922 [59:07<2:07:26,  1.93s/it] 33%|███▎      | 1967/5922 [59:09<2:09:20,  1.96s/it] 33%|███▎      | 1968/5922 [59:10<2:01:43,  1.85s/it] 33%|███▎      | 1969/5922 [59:12<1:57:28,  1.78s/it] 33%|███▎      | 1970/5922 [59:13<1:50:12,  1.67s/it] 33%|███▎      | 1971/5922 [59:16<2:05:47,  1.91s/it] 33%|███▎      | 1972/5922 [59:18<2:03:12,  1.87s/it] 33%|███▎      | 1973/5922 [59:20<2:14:57,  2.05s/it] 33%|███▎      | 1974/5922 [59:21<1:48:57,  1.66s/it] 33%|███▎      | 1975/5922 [59:23<1:55:52,  1.76s/it]                                                     {'loss': 0.1437, 'grad_norm': 0.5316684240377793, 'learning_rate': 1.5425262504028936e-05, 'epoch': 1.0}
 33%|███▎      | 1975/5922 [59:23<1:55:52,  1.76s/it] 33%|███▎      | 1976/5922 [59:25<1:59:38,  1.82s/it] 33%|███▎      | 1977/5922 [59:27<2:02:40,  1.87s/it] 33%|███▎      | 1978/5922 [59:29<2:04:51,  1.90s/it] 33%|███▎      | 1979/5922 [59:31<2:05:50,  1.92s/it] 33%|███▎      | 1980/5922 [59:32<1:55:38,  1.76s/it] 33%|███▎      | 1981/5922 [59:34<1:54:16,  1.74s/it] 33%|███▎      | 1982/5922 [59:36<1:58:28,  1.80s/it] 33%|███▎      | 1983/5922 [59:38<2:00:49,  1.84s/it] 34%|███▎      | 1984/5922 [59:39<1:56:01,  1.77s/it] 34%|███▎      | 1985/5922 [59:41<1:49:47,  1.67s/it] 34%|███▎      | 1986/5922 [59:42<1:48:57,  1.66s/it] 34%|███▎      | 1987/5922 [59:44<1:52:09,  1.71s/it] 34%|███▎      | 1988/5922 [59:46<1:50:08,  1.68s/it] 34%|███▎      | 1989/5922 [59:47<1:45:45,  1.61s/it] 34%|███▎      | 1990/5922 [59:49<1:43:59,  1.59s/it] 34%|███▎      | 1991/5922 [59:51<1:49:32,  1.67s/it] 34%|███▎      | 1992/5922 [59:53<1:56:15,  1.77s/it] 34%|███▎      | 1993/5922 [59:54<1:48:49,  1.66s/it] 34%|███▎      | 1994/5922 [59:55<1:44:01,  1.59s/it] 34%|███▎      | 1995/5922 [59:57<1:42:17,  1.56s/it] 34%|███▎      | 1996/5922 [59:58<1:38:53,  1.51s/it] 34%|███▎      | 1997/5922 [1:00:00<1:47:09,  1.64s/it] 34%|███▎      | 1998/5922 [1:00:02<1:53:11,  1.73s/it] 34%|███▍      | 1999/5922 [1:00:04<2:02:57,  1.88s/it] 34%|███▍      | 2000/5922 [1:00:06<1:58:44,  1.82s/it]                                                       {'loss': 0.1498, 'grad_norm': 0.38301918132621954, 'learning_rate': 1.5315983578703105e-05, 'epoch': 1.01}
 34%|███▍      | 2000/5922 [1:00:06<1:58:44,  1.82s/it][INFO|trainer.py:3993] 2025-08-30 14:48:57,900 >> Saving model checkpoint to saves/qwen3-1.7B/lora/sft/checkpoint-2000
[INFO|configuration_utils.py:696] 2025-08-30 14:48:57,912 >> loading configuration file /home/qianwenhao/LLM/Qwen3-1.7B/config.json
[INFO|configuration_utils.py:770] 2025-08-30 14:48:57,913 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "max_position_embeddings": 40960,
  "max_window_layers": 28,
  "model_type": "qwen3",
  "num_attention_heads": 16,
  "num_hidden_layers": 28,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|tokenization_utils_base.py:2356] 2025-08-30 14:48:57,928 >> chat template saved in saves/qwen3-1.7B/lora/sft/checkpoint-2000/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-08-30 14:48:57,929 >> tokenizer config file saved in saves/qwen3-1.7B/lora/sft/checkpoint-2000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-08-30 14:48:57,929 >> Special tokens file saved in saves/qwen3-1.7B/lora/sft/checkpoint-2000/special_tokens_map.json
[2025-08-30 14:48:58,091] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step1999 is about to be saved!
[2025-08-30 14:48:58,099] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: saves/qwen3-1.7B/lora/sft/checkpoint-2000/global_step1999/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-08-30 14:48:58,099] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-2000/global_step1999/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-08-30 14:48:58,105] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-2000/global_step1999/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-08-30 14:48:58,105] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-2000/global_step1999/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-08-30 14:48:58,117] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-2000/global_step1999/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-08-30 14:48:58,118] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved saves/qwen3-1.7B/lora/sft/checkpoint-2000/global_step1999/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-08-30 14:48:58,125] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1999 is ready now!
 34%|███▍      | 2001/5922 [1:00:10<2:40:04,  2.45s/it] 34%|███▍      | 2002/5922 [1:00:12<2:26:59,  2.25s/it] 34%|███▍      | 2003/5922 [1:00:14<2:23:32,  2.20s/it] 34%|███▍      | 2004/5922 [1:00:16<2:11:07,  2.01s/it] 34%|███▍      | 2005/5922 [1:00:17<2:10:09,  1.99s/it] 34%|███▍      | 2006/5922 [1:00:19<2:10:02,  1.99s/it] 34%|███▍      | 2007/5922 [1:00:21<2:07:03,  1.95s/it] 34%|███▍      | 2008/5922 [1:00:23<2:06:26,  1.94s/it] 34%|███▍      | 2009/5922 [1:00:26<2:12:58,  2.04s/it] 34%|███▍      | 2010/5922 [1:00:27<2:01:19,  1.86s/it] 34%|███▍      | 2011/5922 [1:00:29<1:55:21,  1.77s/it] 34%|███▍      | 2012/5922 [1:00:30<1:47:50,  1.65s/it] 34%|███▍      | 2013/5922 [1:00:31<1:45:06,  1.61s/it] 34%|███▍      | 2014/5922 [1:00:34<1:55:43,  1.78s/it] 34%|███▍      | 2015/5922 [1:00:35<1:58:18,  1.82s/it] 34%|███▍      | 2016/5922 [1:00:37<2:01:09,  1.86s/it] 34%|███▍      | 2017/5922 [1:00:40<2:06:00,  1.94s/it] 34%|███▍      | 2018/5922 [1:00:41<1:59:04,  1.83s/it] 34%|███▍      | 2019/5922 [1:00:43<2:02:00,  1.88s/it] 34%|███▍      | 2020/5922 [1:00:45<1:55:14,  1.77s/it] 34%|███▍      | 2021/5922 [1:00:46<1:54:31,  1.76s/it] 34%|███▍      | 2022/5922 [1:00:48<1:56:52,  1.80s/it] 34%|███▍      | 2023/5922 [1:00:50<1:59:51,  1.84s/it] 34%|███▍      | 2024/5922 [1:00:52<2:02:11,  1.88s/it] 34%|███▍      | 2025/5922 [1:00:54<2:02:37,  1.89s/it]                                                       {'loss': 0.1433, 'grad_norm': 0.36604350901891136, 'learning_rate': 1.5205840150117386e-05, 'epoch': 1.03}
 34%|███▍      | 2025/5922 [1:00:54<2:02:37,  1.89s/it] 34%|███▍      | 2026/5922 [1:00:56<2:03:11,  1.90s/it] 34%|███▍      | 2027/5922 [1:00:58<2:03:53,  1.91s/it] 34%|███▍      | 2028/5922 [1:01:00<2:04:19,  1.92s/it] 34%|███▍      | 2029/5922 [1:01:01<1:57:51,  1.82s/it] 34%|███▍      | 2030/5922 [1:01:03<1:49:59,  1.70s/it] 34%|███▍      | 2031/5922 [1:01:05<1:53:49,  1.76s/it] 34%|███▍      | 2032/5922 [1:01:07<2:04:53,  1.93s/it] 34%|███▍      | 2033/5922 [1:01:09<1:56:55,  1.80s/it] 34%|███▍      | 2034/5922 [1:01:10<1:49:03,  1.68s/it] 34%|███▍      | 2035/5922 [1:01:11<1:43:41,  1.60s/it] 34%|███▍      | 2036/5922 [1:01:13<1:50:07,  1.70s/it] 34%|███▍      | 2037/5922 [1:01:15<1:52:38,  1.74s/it] 34%|███▍      | 2038/5922 [1:01:17<1:54:38,  1.77s/it] 34%|███▍      | 2039/5922 [1:01:19<1:49:41,  1.70s/it] 34%|███▍      | 2040/5922 [1:01:20<1:49:46,  1.70s/it] 34%|███▍      | 2041/5922 [1:01:22<1:54:38,  1.77s/it] 34%|███▍      | 2042/5922 [1:01:24<1:47:45,  1.67s/it] 34%|███▍      | 2043/5922 [1:01:25<1:42:41,  1.59s/it] 35%|███▍      | 2044/5922 [1:01:27<1:46:28,  1.65s/it] 35%|███▍      | 2045/5922 [1:01:28<1:40:57,  1.56s/it] 35%|███▍      | 2046/5922 [1:01:30<1:46:18,  1.65s/it] 35%|███▍      | 2047/5922 [1:01:32<1:59:07,  1.84s/it] 35%|███▍      | 2048/5922 [1:01:34<1:50:29,  1.71s/it] 35%|███▍      | 2049/5922 [1:01:35<1:45:15,  1.63s/it] 35%|███▍      | 2050/5922 [1:01:38<2:01:33,  1.88s/it]                                                       {'loss': 0.1489, 'grad_norm': 0.501507913886598, 'learning_rate': 1.5094851989799552e-05, 'epoch': 1.04}
 35%|███▍      | 2050/5922 [1:01:38<2:01:33,  1.88s/it] 35%|███▍      | 2051/5922 [1:01:40<2:02:10,  1.89s/it] 35%|███▍      | 2052/5922 [1:01:41<2:02:27,  1.90s/it] 35%|███▍      | 2053/5922 [1:01:44<2:13:09,  2.07s/it] 35%|███▍      | 2054/5922 [1:01:45<2:03:23,  1.91s/it] 35%|███▍      | 2055/5922 [1:01:47<1:53:22,  1.76s/it] 35%|███▍      | 2056/5922 [1:01:49<1:54:39,  1.78s/it] 35%|███▍      | 2057/5922 [1:01:51<1:57:50,  1.83s/it] 35%|███▍      | 2058/5922 [1:01:52<1:49:50,  1.71s/it] 35%|███▍      | 2059/5922 [1:01:54<1:46:27,  1.65s/it] 35%|███▍      | 2060/5922 [1:01:56<1:51:45,  1.74s/it] 35%|███▍      | 2061/5922 [1:01:58<2:05:49,  1.96s/it] 35%|███▍      | 2062/5922 [1:02:00<2:04:48,  1.94s/it] 35%|███▍      | 2063/5922 [1:02:01<1:54:54,  1.79s/it] 35%|███▍      | 2064/5922 [1:02:03<1:48:04,  1.68s/it] 35%|███▍      | 2065/5922 [1:02:04<1:42:52,  1.60s/it] 35%|███▍      | 2066/5922 [1:02:06<1:39:21,  1.55s/it] 35%|███▍      | 2067/5922 [1:02:08<1:54:21,  1.78s/it] 35%|███▍      | 2068/5922 [1:02:09<1:50:25,  1.72s/it] 35%|███▍      | 2069/5922 [1:02:11<1:46:48,  1.66s/it] 35%|███▍      | 2070/5922 [1:02:12<1:41:41,  1.58s/it] 35%|███▍      | 2071/5922 [1:02:14<1:48:40,  1.69s/it] 35%|███▍      | 2072/5922 [1:02:16<1:54:26,  1.78s/it] 35%|███▌      | 2073/5922 [1:02:18<1:56:50,  1.82s/it] 35%|███▌      | 2074/5922 [1:02:20<1:50:34,  1.72s/it] 35%|███▌      | 2075/5922 [1:02:21<1:44:48,  1.63s/it]                                                       {'loss': 0.1481, 'grad_norm': 0.4557454511450197, 'learning_rate': 1.4983039020912722e-05, 'epoch': 1.05}
 35%|███▌      | 2075/5922 [1:02:21<1:44:48,  1.63s/it] 35%|███▌      | 2076/5922 [1:02:23<1:51:01,  1.73s/it] 35%|███▌      | 2077/5922 [1:02:25<1:53:51,  1.78s/it] 35%|███▌      | 2078/5922 [1:02:26<1:46:42,  1.67s/it] 35%|███▌      | 2079/5922 [1:02:29<1:55:25,  1.80s/it] 35%|███▌      | 2080/5922 [1:02:30<1:51:48,  1.75s/it] 35%|███▌      | 2081/5922 [1:02:32<1:45:39,  1.65s/it] 35%|███▌      | 2082/5922 [1:02:33<1:40:27,  1.57s/it] 35%|███▌      | 2083/5922 [1:02:35<1:57:51,  1.84s/it] 35%|███▌      | 2084/5922 [1:02:37<1:49:48,  1.72s/it] 35%|███▌      | 2085/5922 [1:02:39<2:04:28,  1.95s/it] 35%|███▌      | 2086/5922 [1:02:42<2:08:00,  2.00s/it] 35%|███▌      | 2087/5922 [1:02:43<1:58:36,  1.86s/it] 35%|███▌      | 2088/5922 [1:02:44<1:50:13,  1.73s/it] 35%|███▌      | 2089/5922 [1:02:46<1:44:54,  1.64s/it] 35%|███▌      | 2090/5922 [1:02:48<1:48:21,  1.70s/it] 35%|███▌      | 2091/5922 [1:02:50<1:52:55,  1.77s/it] 35%|███▌      | 2092/5922 [1:02:51<1:47:42,  1.69s/it] 35%|███▌      | 2093/5922 [1:02:53<1:42:41,  1.61s/it] 35%|███▌      | 2094/5922 [1:02:54<1:38:37,  1.55s/it] 35%|███▌      | 2095/5922 [1:02:55<1:35:59,  1.50s/it] 35%|███▌      | 2096/5922 [1:02:57<1:34:34,  1.48s/it] 35%|███▌      | 2097/5922 [1:02:59<1:49:17,  1.71s/it] 35%|███▌      | 2098/5922 [1:03:00<1:43:08,  1.62s/it] 35%|███▌      | 2099/5922 [1:03:02<1:46:57,  1.68s/it] 35%|███▌      | 2100/5922 [1:03:04<1:43:31,  1.63s/it]                                                       {'loss': 0.1495, 'grad_norm': 0.4380171776887184, 'learning_rate': 1.4870421314679004e-05, 'epoch': 1.06}
 35%|███▌      | 2100/5922 [1:03:04<1:43:31,  1.63s/it] 35%|███▌      | 2101/5922 [1:03:06<1:49:43,  1.72s/it] 35%|███▌      | 2102/5922 [1:03:08<2:03:07,  1.93s/it] 36%|███▌      | 2103/5922 [1:03:10<1:52:59,  1.78s/it] 36%|███▌      | 2104/5922 [1:03:11<1:53:50,  1.79s/it] 36%|███▌      | 2105/5922 [1:03:13<1:57:52,  1.85s/it] 36%|███▌      | 2106/5922 [1:03:15<1:59:25,  1.88s/it] 36%|███▌      | 2107/5922 [1:03:17<1:50:42,  1.74s/it] 36%|███▌      | 2108/5922 [1:03:19<2:01:28,  1.91s/it] 36%|███▌      | 2109/5922 [1:03:21<2:01:45,  1.92s/it] 36%|███▌      | 2110/5922 [1:03:23<2:01:52,  1.92s/it] 36%|███▌      | 2111/5922 [1:03:24<1:51:46,  1.76s/it] 36%|███▌      | 2112/5922 [1:03:26<1:45:47,  1.67s/it] 36%|███▌      | 2113/5922 [1:03:28<1:50:44,  1.74s/it] 36%|███▌      | 2114/5922 [1:03:29<1:46:33,  1.68s/it] 36%|███▌      | 2115/5922 [1:03:31<1:43:29,  1.63s/it] 36%|███▌      | 2116/5922 [1:03:33<1:57:40,  1.86s/it] 36%|███▌      | 2117/5922 [1:03:35<1:54:13,  1.80s/it] 36%|███▌      | 2118/5922 [1:03:37<1:56:37,  1.84s/it] 36%|███▌      | 2119/5922 [1:03:39<1:59:07,  1.88s/it] 36%|███▌      | 2120/5922 [1:03:40<1:50:12,  1.74s/it] 36%|███▌      | 2121/5922 [1:03:42<1:54:40,  1.81s/it] 36%|███▌      | 2122/5922 [1:03:44<1:50:33,  1.75s/it] 36%|███▌      | 2123/5922 [1:03:46<1:54:51,  1.81s/it] 36%|███▌      | 2124/5922 [1:03:48<2:07:06,  2.01s/it] 36%|███▌      | 2125/5922 [1:03:50<1:58:28,  1.87s/it]                                                       {'loss': 0.1427, 'grad_norm': 0.4442249547369015, 'learning_rate': 1.4757019086776587e-05, 'epoch': 1.08}
 36%|███▌      | 2125/5922 [1:03:50<1:58:28,  1.87s/it] 36%|███▌      | 2126/5922 [1:03:52<1:59:35,  1.89s/it] 36%|███▌      | 2127/5922 [1:03:53<1:50:48,  1.75s/it] 36%|███▌      | 2128/5922 [1:03:55<1:46:47,  1.69s/it] 36%|███▌      | 2129/5922 [1:03:56<1:41:42,  1.61s/it] 36%|███▌      | 2130/5922 [1:03:58<1:48:58,  1.72s/it] 36%|███▌      | 2131/5922 [1:03:59<1:42:32,  1.62s/it] 36%|███▌      | 2132/5922 [1:04:01<1:38:24,  1.56s/it] 36%|███▌      | 2133/5922 [1:04:02<1:37:12,  1.54s/it] 36%|███▌      | 2134/5922 [1:04:04<1:34:57,  1.50s/it] 36%|███▌      | 2135/5922 [1:04:06<1:43:36,  1.64s/it] 36%|███▌      | 2136/5922 [1:04:08<1:58:32,  1.88s/it] 36%|███▌      | 2137/5922 [1:04:10<1:56:57,  1.85s/it] 36%|███▌      | 2138/5922 [1:04:12<1:56:27,  1.85s/it] 36%|███▌      | 2139/5922 [1:04:14<1:58:09,  1.87s/it] 36%|███▌      | 2140/5922 [1:04:15<1:52:04,  1.78s/it] 36%|███▌      | 2141/5922 [1:04:17<1:47:55,  1.71s/it] 36%|███▌      | 2142/5922 [1:04:18<1:47:43,  1.71s/it] 36%|███▌      | 2143/5922 [1:04:20<1:51:54,  1.78s/it] 36%|███▌      | 2144/5922 [1:04:22<1:53:31,  1.80s/it] 36%|███▌      | 2145/5922 [1:04:24<1:45:54,  1.68s/it] 36%|███▌      | 2146/5922 [1:04:25<1:40:50,  1.60s/it] 36%|███▋      | 2147/5922 [1:04:26<1:36:57,  1.54s/it] 36%|███▋      | 2148/5922 [1:04:29<1:54:29,  1.82s/it] 36%|███▋      | 2149/5922 [1:04:30<1:46:32,  1.69s/it] 36%|███▋      | 2150/5922 [1:04:33<2:01:46,  1.94s/it]                                                       {'loss': 0.1488, 'grad_norm': 0.34677818792334114, 'learning_rate': 1.4642852693710853e-05, 'epoch': 1.09}
 36%|███▋      | 2150/5922 [1:04:33<2:01:46,  1.94s/it] 36%|███▋      | 2151/5922 [1:04:35<2:01:48,  1.94s/it] 36%|███▋      | 2152/5922 [1:04:36<1:57:28,  1.87s/it] 36%|███▋      | 2153/5922 [1:04:38<1:52:07,  1.79s/it] 36%|███▋      | 2154/5922 [1:04:40<2:00:47,  1.92s/it] 36%|███▋      | 2155/5922 [1:04:42<2:01:21,  1.93s/it] 36%|███▋      | 2156/5922 [1:04:44<1:52:40,  1.80s/it] 36%|███▋      | 2157/5922 [1:04:46<1:58:27,  1.89s/it] 36%|███▋      | 2158/5922 [1:04:47<1:49:26,  1.74s/it] 36%|███▋      | 2159/5922 [1:04:49<1:43:04,  1.64s/it] 36%|███▋      | 2160/5922 [1:04:51<1:58:04,  1.88s/it] 36%|███▋      | 2161/5922 [1:04:53<1:55:14,  1.84s/it] 37%|███▋      | 2162/5922 [1:04:55<2:00:33,  1.92s/it] 37%|███▋      | 2163/5922 [1:04:57<2:10:35,  2.08s/it] 37%|███▋      | 2164/5922 [1:04:59<2:06:30,  2.02s/it] 37%|███▋      | 2165/5922 [1:05:01<2:04:44,  1.99s/it] 37%|███▋      | 2166/5922 [1:05:04<2:12:11,  2.11s/it] 37%|███▋      | 2167/5922 [1:05:05<2:01:59,  1.95s/it] 37%|███▋      | 2168/5922 [1:05:07<2:00:07,  1.92s/it] 37%|███▋      | 2169/5922 [1:05:08<1:50:19,  1.76s/it] 37%|███▋      | 2170/5922 [1:05:10<1:45:39,  1.69s/it] 37%|███▋      | 2171/5922 [1:05:12<1:55:33,  1.85s/it] 37%|███▋      | 2172/5922 [1:05:14<1:49:53,  1.76s/it] 37%|███▋      | 2173/5922 [1:05:15<1:46:07,  1.70s/it] 37%|███▋      | 2174/5922 [1:05:17<1:45:59,  1.70s/it] 37%|███▋      | 2175/5922 [1:05:19<1:58:01,  1.89s/it]                                                       {'loss': 0.155, 'grad_norm': 0.3761463876664388, 'learning_rate': 1.4527942629160285e-05, 'epoch': 1.1}
 37%|███▋      | 2175/5922 [1:05:19<1:58:01,  1.89s/it] 37%|███▋      | 2176/5922 [1:05:21<1:58:27,  1.90s/it] 37%|███▋      | 2177/5922 [1:05:24<2:09:02,  2.07s/it] 37%|███▋      | 2178/5922 [1:05:26<2:08:26,  2.06s/it] 37%|███▋      | 2179/5922 [1:05:27<1:56:43,  1.87s/it] 37%|███▋      | 2180/5922 [1:05:29<1:54:58,  1.84s/it] 37%|███▋      | 2181/5922 [1:05:30<1:48:14,  1.74s/it] 37%|███▋      | 2182/5922 [1:05:32<1:45:16,  1.69s/it] 37%|███▋      | 2183/5922 [1:05:34<1:45:30,  1.69s/it] 37%|███▋      | 2184/5922 [1:05:36<1:47:22,  1.72s/it] 37%|███▋      | 2185/5922 [1:05:37<1:51:08,  1.78s/it] 37%|███▋      | 2186/5922 [1:05:39<1:55:01,  1.85s/it] 37%|███▋      | 2187/5922 [1:05:41<1:49:42,  1.76s/it] 37%|███▋      | 2188/5922 [1:05:43<1:52:48,  1.81s/it] 37%|███▋      | 2189/5922 [1:05:45<1:55:42,  1.86s/it] 37%|███▋      | 2190/5922 [1:05:46<1:47:37,  1.73s/it] 37%|███▋      | 2191/5922 [1:05:48<1:50:54,  1.78s/it] 37%|███▋      | 2192/5922 [1:05:50<1:50:23,  1.78s/it] 37%|███▋      | 2193/5922 [1:05:52<1:46:03,  1.71s/it] 37%|███▋      | 2194/5922 [1:05:54<1:50:57,  1.79s/it] 37%|███▋      | 2195/5922 [1:05:55<1:54:08,  1.84s/it] 37%|███▋      | 2196/5922 [1:05:58<2:05:07,  2.01s/it] 37%|███▋      | 2197/5922 [1:05:59<1:53:55,  1.84s/it] 37%|███▋      | 2198/5922 [1:06:01<1:57:52,  1.90s/it] 37%|███▋      | 2199/5922 [1:06:03<1:56:39,  1.88s/it] 37%|███▋      | 2200/5922 [1:06:05<1:52:24,  1.81s/it]                                                       {'loss': 0.1417, 'grad_norm': 0.4019405279962706, 'learning_rate': 1.441230952029766e-05, 'epoch': 1.11}
 37%|███▋      | 2200/5922 [1:06:05<1:52:24,  1.81s/it] 37%|███▋      | 2201/5922 [1:06:07<1:55:06,  1.86s/it] 37%|███▋      | 2202/5922 [1:06:09<2:06:21,  2.04s/it] 37%|███▋      | 2203/5922 [1:06:12<2:13:46,  2.16s/it] 37%|███▋      | 2204/5922 [1:06:13<2:00:06,  1.94s/it] 37%|███▋      | 2205/5922 [1:06:15<1:59:48,  1.93s/it] 37%|███▋      | 2206/5922 [1:06:17<2:00:01,  1.94s/it] 37%|███▋      | 2207/5922 [1:06:18<1:49:43,  1.77s/it] 37%|███▋      | 2208/5922 [1:06:21<2:01:39,  1.97s/it] 37%|███▋      | 2209/5922 [1:06:22<1:50:43,  1.79s/it] 37%|███▋      | 2210/5922 [1:06:24<1:43:04,  1.67s/it] 37%|███▋      | 2211/5922 [1:06:26<1:48:59,  1.76s/it] 37%|███▋      | 2212/5922 [1:06:27<1:50:33,  1.79s/it] 37%|███▋      | 2213/5922 [1:06:29<1:43:25,  1.67s/it] 37%|███▋      | 2214/5922 [1:06:30<1:40:50,  1.63s/it] 37%|███▋      | 2215/5922 [1:06:32<1:47:04,  1.73s/it] 37%|███▋      | 2216/5922 [1:06:34<1:45:41,  1.71s/it] 37%|███▋      | 2217/5922 [1:06:36<1:45:11,  1.70s/it] 37%|███▋      | 2218/5922 [1:06:38<1:52:38,  1.82s/it] 37%|███▋      | 2219/5922 [1:06:39<1:44:19,  1.69s/it] 37%|███▋      | 2220/5922 [1:06:41<1:39:32,  1.61s/it] 38%|███▊      | 2221/5922 [1:06:42<1:35:45,  1.55s/it] 38%|███▊      | 2222/5922 [1:06:44<1:36:07,  1.56s/it] 38%|███▊      | 2223/5922 [1:06:45<1:33:14,  1.51s/it] 38%|███▊      | 2224/5922 [1:06:47<1:37:44,  1.59s/it] 38%|███▊      | 2225/5922 [1:06:49<1:53:57,  1.85s/it]                                                       {'loss': 0.1515, 'grad_norm': 0.4400441442252029, 'learning_rate': 1.4295974124087351e-05, 'epoch': 1.13}
 38%|███▊      | 2225/5922 [1:06:49<1:53:57,  1.85s/it] 38%|███▊      | 2226/5922 [1:06:51<1:45:56,  1.72s/it] 38%|███▊      | 2227/5922 [1:06:52<1:42:42,  1.67s/it] 38%|███▊      | 2228/5922 [1:06:54<1:45:49,  1.72s/it] 38%|███▊      | 2229/5922 [1:06:55<1:40:25,  1.63s/it] 38%|███▊      | 2230/5922 [1:06:57<1:36:30,  1.57s/it] 38%|███▊      | 2231/5922 [1:06:59<1:42:50,  1.67s/it] 38%|███▊      | 2232/5922 [1:07:00<1:37:35,  1.59s/it] 38%|███▊      | 2233/5922 [1:07:02<1:43:22,  1.68s/it] 38%|███▊      | 2234/5922 [1:07:04<1:56:15,  1.89s/it] 38%|███▊      | 2235/5922 [1:07:06<1:57:12,  1.91s/it] 38%|███▊      | 2236/5922 [1:07:08<1:49:53,  1.79s/it] 38%|███▊      | 2237/5922 [1:07:10<1:57:58,  1.92s/it] 38%|███▊      | 2238/5922 [1:07:12<1:55:51,  1.89s/it] 38%|███▊      | 2239/5922 [1:07:14<1:50:55,  1.81s/it] 38%|███▊      | 2240/5922 [1:07:16<2:00:01,  1.96s/it] 38%|███▊      | 2241/5922 [1:07:18<1:59:44,  1.95s/it] 38%|███▊      | 2242/5922 [1:07:19<1:49:32,  1.79s/it] 38%|███▊      | 2243/5922 [1:07:22<2:01:59,  1.99s/it] 38%|███▊      | 2244/5922 [1:07:23<1:59:03,  1.94s/it] 38%|███▊      | 2245/5922 [1:07:25<1:48:44,  1.77s/it] 38%|███▊      | 2246/5922 [1:07:27<1:58:58,  1.94s/it] 38%|███▊      | 2247/5922 [1:07:29<1:55:51,  1.89s/it] 38%|███▊      | 2248/5922 [1:07:30<1:47:04,  1.75s/it] 38%|███▊      | 2249/5922 [1:07:32<1:41:37,  1.66s/it] 38%|███▊      | 2250/5922 [1:07:34<1:46:05,  1.73s/it]                                                       {'loss': 0.1401, 'grad_norm': 0.455468264507419, 'learning_rate': 1.4178957323559296e-05, 'epoch': 1.14}
 38%|███▊      | 2250/5922 [1:07:34<1:46:05,  1.73s/it] 38%|███▊      | 2251/5922 [1:07:36<1:49:19,  1.79s/it] 38%|███▊      | 2252/5922 [1:07:38<1:54:37,  1.87s/it] 38%|███▊      | 2253/5922 [1:07:40<1:53:52,  1.86s/it] 38%|███▊      | 2254/5922 [1:07:41<1:54:55,  1.88s/it] 38%|███▊      | 2255/5922 [1:07:43<1:48:32,  1.78s/it] 38%|███▊      | 2256/5922 [1:07:45<1:50:49,  1.81s/it] 38%|███▊      | 2257/5922 [1:07:47<1:53:27,  1.86s/it] 38%|███▊      | 2258/5922 [1:07:49<1:50:06,  1.80s/it] 38%|███▊      | 2259/5922 [1:07:50<1:50:09,  1.80s/it] 38%|███▊      | 2260/5922 [1:07:52<1:47:19,  1.76s/it] 38%|███▊      | 2261/5922 [1:07:54<1:54:04,  1.87s/it] 38%|███▊      | 2262/5922 [1:07:56<1:54:10,  1.87s/it] 38%|███▊      | 2263/5922 [1:07:57<1:45:26,  1.73s/it] 38%|███▊      | 2264/5922 [1:07:59<1:41:46,  1.67s/it] 38%|███▊      | 2265/5922 [1:08:00<1:37:35,  1.60s/it] 38%|███▊      | 2266/5922 [1:08:02<1:34:30,  1.55s/it] 38%|███▊      | 2267/5922 [1:08:04<1:37:30,  1.60s/it] 38%|███▊      | 2268/5922 [1:08:05<1:38:16,  1.61s/it] 38%|███▊      | 2269/5922 [1:08:07<1:43:31,  1.70s/it] 38%|███▊      | 2270/5922 [1:08:09<1:47:16,  1.76s/it] 38%|███▊      | 2271/5922 [1:08:11<1:43:39,  1.70s/it] 38%|███▊      | 2272/5922 [1:08:12<1:47:33,  1.77s/it] 38%|███▊      | 2273/5922 [1:08:14<1:46:08,  1.75s/it] 38%|███▊      | 2274/5922 [1:08:16<1:51:45,  1.84s/it] 38%|███▊      | 2275/5922 [1:08:18<1:44:47,  1.72s/it]                                                       {'loss': 0.1449, 'grad_norm': 0.3535210747787526, 'learning_rate': 1.4061280124060354e-05, 'epoch': 1.15}
 38%|███▊      | 2275/5922 [1:08:18<1:44:47,  1.72s/it] 38%|███▊      | 2276/5922 [1:08:19<1:46:39,  1.76s/it] 38%|███▊      | 2277/5922 [1:08:21<1:40:01,  1.65s/it] 38%|███▊      | 2278/5922 [1:08:22<1:35:50,  1.58s/it] 38%|███▊      | 2279/5922 [1:08:24<1:42:07,  1.68s/it] 39%|███▊      | 2280/5922 [1:08:26<1:44:35,  1.72s/it] 39%|███▊      | 2281/5922 [1:08:28<1:49:11,  1.80s/it] 39%|███▊      | 2282/5922 [1:08:30<2:00:56,  1.99s/it] 39%|███▊      | 2283/5922 [1:08:32<1:59:48,  1.98s/it] 39%|███▊      | 2284/5922 [1:08:34<1:49:12,  1.80s/it] 39%|███▊      | 2285/5922 [1:08:35<1:46:26,  1.76s/it] 39%|███▊      | 2286/5922 [1:08:37<1:49:04,  1.80s/it] 39%|███▊      | 2287/5922 [1:08:40<1:57:44,  1.94s/it] 39%|███▊      | 2288/5922 [1:08:41<1:47:55,  1.78s/it] 39%|███▊      | 2289/5922 [1:08:43<1:44:27,  1.73s/it] 39%|███▊      | 2290/5922 [1:08:45<1:58:09,  1.95s/it] 39%|███▊      | 2291/5922 [1:08:47<1:48:23,  1.79s/it] 39%|███▊      | 2292/5922 [1:08:48<1:41:22,  1.68s/it] 39%|███▊      | 2293/5922 [1:08:50<1:54:21,  1.89s/it] 39%|███▊      | 2294/5922 [1:08:52<1:57:32,  1.94s/it] 39%|███▉      | 2295/5922 [1:08:55<2:03:20,  2.04s/it] 39%|███▉      | 2296/5922 [1:08:56<1:55:31,  1.91s/it] 39%|███▉      | 2297/5922 [1:08:58<1:55:41,  1.91s/it] 39%|███▉      | 2298/5922 [1:09:00<1:55:21,  1.91s/it] 39%|███▉      | 2299/5922 [1:09:02<1:58:03,  1.96s/it] 39%|███▉      | 2300/5922 [1:09:04<1:56:44,  1.93s/it]                                                       {'loss': 0.1356, 'grad_norm': 0.5333736547956586, 'learning_rate': 1.394296364948368e-05, 'epoch': 1.17}
 39%|███▉      | 2300/5922 [1:09:04<1:56:44,  1.93s/it] 39%|███▉      | 2301/5922 [1:09:06<1:49:37,  1.82s/it] 39%|███▉      | 2302/5922 [1:09:08<1:53:17,  1.88s/it] 39%|███▉      | 2303/5922 [1:09:09<1:45:42,  1.75s/it] 39%|███▉      | 2304/5922 [1:09:11<1:47:49,  1.79s/it] 39%|███▉      | 2305/5922 [1:09:13<1:44:35,  1.74s/it] 39%|███▉      | 2306/5922 [1:09:14<1:38:56,  1.64s/it] 39%|███▉      | 2307/5922 [1:09:16<1:44:05,  1.73s/it] 39%|███▉      | 2308/5922 [1:09:17<1:38:53,  1.64s/it] 39%|███▉      | 2309/5922 [1:09:19<1:38:44,  1.64s/it] 39%|███▉      | 2310/5922 [1:09:21<1:51:09,  1.85s/it] 39%|███▉      | 2311/5922 [1:09:23<1:55:11,  1.91s/it] 39%|███▉      | 2312/5922 [1:09:25<1:51:22,  1.85s/it] 39%|███▉      | 2313/5922 [1:09:27<1:52:51,  1.88s/it] 39%|███▉      | 2314/5922 [1:09:28<1:44:06,  1.73s/it] 39%|███▉      | 2315/5922 [1:09:30<1:40:23,  1.67s/it] 39%|███▉      | 2316/5922 [1:09:32<1:45:29,  1.76s/it] 39%|███▉      | 2317/5922 [1:09:34<1:45:45,  1.76s/it] 39%|███▉      | 2318/5922 [1:09:36<1:48:26,  1.81s/it] 39%|███▉      | 2319/5922 [1:09:37<1:50:35,  1.84s/it] 39%|███▉      | 2320/5922 [1:09:39<1:51:40,  1.86s/it] 39%|███▉      | 2321/5922 [1:09:41<1:45:28,  1.76s/it] 39%|███▉      | 2322/5922 [1:09:43<1:49:45,  1.83s/it] 39%|███▉      | 2323/5922 [1:09:44<1:44:14,  1.74s/it] 39%|███▉      | 2324/5922 [1:09:46<1:44:56,  1.75s/it] 39%|███▉      | 2325/5922 [1:09:48<1:41:59,  1.70s/it]                                                       {'loss': 0.1407, 'grad_norm': 0.4171627540271279, 'learning_rate': 1.382402913847686e-05, 'epoch': 1.18}
 39%|███▉      | 2325/5922 [1:09:48<1:41:59,  1.70s/it] 39%|███▉      | 2326/5922 [1:09:49<1:39:05,  1.65s/it] 39%|███▉      | 2327/5922 [1:09:51<1:43:17,  1.72s/it] 39%|███▉      | 2328/5922 [1:09:53<1:47:04,  1.79s/it] 39%|███▉      | 2329/5922 [1:09:55<1:49:30,  1.83s/it] 39%|███▉      | 2330/5922 [1:09:57<1:45:23,  1.76s/it] 39%|███▉      | 2331/5922 [1:09:59<1:48:37,  1.81s/it] 39%|███▉      | 2332/5922 [1:10:00<1:40:27,  1.68s/it] 39%|███▉      | 2333/5922 [1:10:02<1:47:09,  1.79s/it] 39%|███▉      | 2334/5922 [1:10:03<1:40:01,  1.67s/it] 39%|███▉      | 2335/5922 [1:10:05<1:44:44,  1.75s/it] 39%|███▉      | 2336/5922 [1:10:07<1:45:48,  1.77s/it] 39%|███▉      | 2337/5922 [1:10:09<1:55:05,  1.93s/it] 39%|███▉      | 2338/5922 [1:10:11<1:55:32,  1.93s/it] 39%|███▉      | 2339/5922 [1:10:13<1:53:50,  1.91s/it] 40%|███▉      | 2340/5922 [1:10:15<1:45:08,  1.76s/it] 40%|███▉      | 2341/5922 [1:10:16<1:40:16,  1.68s/it] 40%|███▉      | 2342/5922 [1:10:18<1:41:53,  1.71s/it] 40%|███▉      | 2343/5922 [1:10:19<1:36:48,  1.62s/it] 40%|███▉      | 2344/5922 [1:10:21<1:35:39,  1.60s/it] 40%|███▉      | 2345/5922 [1:10:23<1:51:17,  1.87s/it] 40%|███▉      | 2346/5922 [1:10:25<1:52:28,  1.89s/it] 40%|███▉      | 2347/5922 [1:10:27<1:53:36,  1.91s/it] 40%|███▉      | 2348/5922 [1:10:29<1:46:57,  1.80s/it] 40%|███▉      | 2349/5922 [1:10:30<1:41:38,  1.71s/it] 40%|███▉      | 2350/5922 [1:10:32<1:39:12,  1.67s/it]                                                       {'loss': 0.1402, 'grad_norm': 0.489922410053475, 'learning_rate': 1.3704497940629392e-05, 'epoch': 1.19}
 40%|███▉      | 2350/5922 [1:10:32<1:39:12,  1.67s/it] 40%|███▉      | 2351/5922 [1:10:33<1:34:17,  1.58s/it] 40%|███▉      | 2352/5922 [1:10:35<1:31:08,  1.53s/it] 40%|███▉      | 2353/5922 [1:10:37<1:38:12,  1.65s/it] 40%|███▉      | 2354/5922 [1:10:38<1:34:01,  1.58s/it] 40%|███▉      | 2355/5922 [1:10:40<1:40:02,  1.68s/it] 40%|███▉      | 2356/5922 [1:10:42<1:54:03,  1.92s/it] 40%|███▉      | 2357/5922 [1:10:45<1:59:31,  2.01s/it] 40%|███▉      | 2358/5922 [1:10:46<1:51:56,  1.88s/it] 40%|███▉      | 2359/5922 [1:10:48<1:52:45,  1.90s/it] 40%|███▉      | 2360/5922 [1:10:50<1:52:37,  1.90s/it] 40%|███▉      | 2361/5922 [1:10:52<1:43:42,  1.75s/it] 40%|███▉      | 2362/5922 [1:10:53<1:37:25,  1.64s/it] 40%|███▉      | 2363/5922 [1:10:55<1:40:21,  1.69s/it] 40%|███▉      | 2364/5922 [1:10:57<1:43:01,  1.74s/it] 40%|███▉      | 2365/5922 [1:10:58<1:44:34,  1.76s/it] 40%|███▉      | 2366/5922 [1:11:01<1:54:31,  1.93s/it] 40%|███▉      | 2367/5922 [1:11:03<1:55:39,  1.95s/it] 40%|███▉      | 2368/5922 [1:11:04<1:45:03,  1.77s/it] 40%|████      | 2369/5922 [1:11:06<1:47:55,  1.82s/it] 40%|████      | 2370/5922 [1:11:07<1:40:23,  1.70s/it] 40%|████      | 2371/5922 [1:11:10<1:47:35,  1.82s/it] 40%|████      | 2372/5922 [1:11:11<1:43:29,  1.75s/it] 40%|████      | 2373/5922 [1:11:13<1:46:43,  1.80s/it] 40%|████      | 2374/5922 [1:11:15<1:42:56,  1.74s/it] 40%|████      | 2375/5922 [1:11:16<1:44:31,  1.77s/it]                                                       {'loss': 0.1388, 'grad_norm': 0.4022072067231961, 'learning_rate': 1.3584391512640318e-05, 'epoch': 1.2}
 40%|████      | 2375/5922 [1:11:16<1:44:31,  1.77s/it] 40%|████      | 2376/5922 [1:11:19<1:50:41,  1.87s/it] 40%|████      | 2377/5922 [1:11:20<1:44:32,  1.77s/it] 40%|████      | 2378/5922 [1:11:22<1:39:07,  1.68s/it] 40%|████      | 2379/5922 [1:11:23<1:33:45,  1.59s/it] 40%|████      | 2380/5922 [1:11:24<1:29:49,  1.52s/it] 40%|████      | 2381/5922 [1:11:26<1:27:27,  1.48s/it] 40%|████      | 2382/5922 [1:11:28<1:35:30,  1.62s/it] 40%|████      | 2383/5922 [1:11:30<1:40:41,  1.71s/it] 40%|████      | 2384/5922 [1:11:31<1:42:33,  1.74s/it] 40%|████      | 2385/5922 [1:11:33<1:39:52,  1.69s/it] 40%|████      | 2386/5922 [1:11:34<1:34:03,  1.60s/it] 40%|████      | 2387/5922 [1:11:37<1:48:12,  1.84s/it] 40%|████      | 2388/5922 [1:11:38<1:39:57,  1.70s/it] 40%|████      | 2389/5922 [1:11:40<1:37:23,  1.65s/it] 40%|████      | 2390/5922 [1:11:42<1:44:18,  1.77s/it] 40%|████      | 2391/5922 [1:11:43<1:40:35,  1.71s/it] 40%|████      | 2392/5922 [1:11:45<1:34:51,  1.61s/it] 40%|████      | 2393/5922 [1:11:46<1:35:57,  1.63s/it] 40%|████      | 2394/5922 [1:11:49<1:50:58,  1.89s/it] 40%|████      | 2395/5922 [1:11:50<1:43:31,  1.76s/it] 40%|████      | 2396/5922 [1:11:52<1:36:45,  1.65s/it] 40%|████      | 2397/5922 [1:11:53<1:33:42,  1.59s/it] 40%|████      | 2398/5922 [1:11:55<1:30:21,  1.54s/it] 41%|████      | 2399/5922 [1:11:56<1:28:22,  1.51s/it] 41%|████      | 2400/5922 [1:11:57<1:26:32,  1.47s/it]                                                       {'loss': 0.1387, 'grad_norm': 0.37775320700207465, 'learning_rate': 1.3463731414466563e-05, 'epoch': 1.22}
 41%|████      | 2400/5922 [1:11:57<1:26:32,  1.47s/it] 41%|████      | 2401/5922 [1:11:59<1:24:42,  1.44s/it] 41%|████      | 2402/5922 [1:12:01<1:32:53,  1.58s/it] 41%|████      | 2403/5922 [1:12:03<1:48:22,  1.85s/it] 41%|████      | 2404/5922 [1:12:05<1:57:44,  2.01s/it] 41%|████      | 2405/5922 [1:12:08<2:03:44,  2.11s/it] 41%|████      | 2406/5922 [1:12:09<1:54:53,  1.96s/it] 41%|████      | 2407/5922 [1:12:12<1:57:11,  2.00s/it] 41%|████      | 2408/5922 [1:12:13<1:52:32,  1.92s/it] 41%|████      | 2409/5922 [1:12:15<1:50:23,  1.89s/it] 41%|████      | 2410/5922 [1:12:17<1:50:55,  1.90s/it] 41%|████      | 2411/5922 [1:12:18<1:41:45,  1.74s/it] 41%|████      | 2412/5922 [1:12:20<1:38:30,  1.68s/it] 41%|████      | 2413/5922 [1:12:22<1:43:05,  1.76s/it] 41%|████      | 2414/5922 [1:12:23<1:39:51,  1.71s/it] 41%|████      | 2415/5922 [1:12:25<1:45:41,  1.81s/it] 41%|████      | 2416/5922 [1:12:27<1:41:20,  1.73s/it] 41%|████      | 2417/5922 [1:12:29<1:41:31,  1.74s/it] 41%|████      | 2418/5922 [1:12:31<1:44:43,  1.79s/it] 41%|████      | 2419/5922 [1:12:33<1:47:23,  1.84s/it] 41%|████      | 2420/5922 [1:12:35<1:49:19,  1.87s/it] 41%|████      | 2421/5922 [1:12:37<1:57:11,  2.01s/it] 41%|████      | 2422/5922 [1:12:39<1:55:37,  1.98s/it] 41%|████      | 2423/5922 [1:12:41<1:54:52,  1.97s/it] 41%|████      | 2424/5922 [1:12:42<1:45:23,  1.81s/it] 41%|████      | 2425/5922 [1:12:44<1:44:28,  1.79s/it]                                                       {'loss': 0.16, 'grad_norm': 0.4374226219918697, 'learning_rate': 1.3342539305452786e-05, 'epoch': 1.23}
 41%|████      | 2425/5922 [1:12:44<1:44:28,  1.79s/it] 41%|████      | 2426/5922 [1:12:46<1:46:42,  1.83s/it] 41%|████      | 2427/5922 [1:12:47<1:40:07,  1.72s/it] 41%|████      | 2428/5922 [1:12:49<1:41:54,  1.75s/it] 41%|████      | 2429/5922 [1:12:51<1:42:19,  1.76s/it] 41%|████      | 2430/5922 [1:12:53<1:38:25,  1.69s/it] 41%|████      | 2431/5922 [1:12:54<1:35:52,  1.65s/it] 41%|████      | 2432/5922 [1:12:55<1:30:53,  1.56s/it] 41%|████      | 2433/5922 [1:12:57<1:28:09,  1.52s/it] 41%|████      | 2434/5922 [1:12:58<1:25:53,  1.48s/it] 41%|████      | 2435/5922 [1:13:00<1:33:32,  1.61s/it] 41%|████      | 2436/5922 [1:13:02<1:30:06,  1.55s/it] 41%|████      | 2437/5922 [1:13:03<1:36:32,  1.66s/it] 41%|████      | 2438/5922 [1:13:06<1:43:01,  1.77s/it] 41%|████      | 2439/5922 [1:13:07<1:36:15,  1.66s/it] 41%|████      | 2440/5922 [1:13:09<1:39:33,  1.72s/it] 41%|████      | 2441/5922 [1:13:11<1:43:12,  1.78s/it] 41%|████      | 2442/5922 [1:13:13<1:45:29,  1.82s/it] 41%|████▏     | 2443/5922 [1:13:15<1:47:42,  1.86s/it] 41%|████▏     | 2444/5922 [1:13:16<1:45:43,  1.82s/it] 41%|████▏     | 2445/5922 [1:13:18<1:43:20,  1.78s/it] 41%|████▏     | 2446/5922 [1:13:19<1:37:18,  1.68s/it] 41%|████▏     | 2447/5922 [1:13:21<1:41:26,  1.75s/it] 41%|████▏     | 2448/5922 [1:13:23<1:41:39,  1.76s/it] 41%|████▏     | 2449/5922 [1:13:25<1:40:34,  1.74s/it] 41%|████▏     | 2450/5922 [1:13:27<1:43:39,  1.79s/it]                                                       {'loss': 0.1395, 'grad_norm': 0.42974330841851754, 'learning_rate': 1.3220836940443374e-05, 'epoch': 1.24}
 41%|████▏     | 2450/5922 [1:13:27<1:43:39,  1.79s/it] 41%|████▏     | 2451/5922 [1:13:28<1:43:38,  1.79s/it] 41%|████▏     | 2452/5922 [1:13:30<1:36:05,  1.66s/it] 41%|████▏     | 2453/5922 [1:13:31<1:33:50,  1.62s/it] 41%|████▏     | 2454/5922 [1:13:33<1:30:03,  1.56s/it] 41%|████▏     | 2455/5922 [1:13:35<1:35:56,  1.66s/it] 41%|████▏     | 2456/5922 [1:13:36<1:31:08,  1.58s/it] 41%|████▏     | 2457/5922 [1:13:38<1:34:50,  1.64s/it] 42%|████▏     | 2458/5922 [1:13:39<1:30:43,  1.57s/it] 42%|████▏     | 2459/5922 [1:13:41<1:35:15,  1.65s/it] 42%|████▏     | 2460/5922 [1:13:43<1:33:23,  1.62s/it] 42%|████▏     | 2461/5922 [1:13:44<1:29:28,  1.55s/it] 42%|████▏     | 2462/5922 [1:13:46<1:38:35,  1.71s/it] 42%|████▏     | 2463/5922 [1:13:48<1:33:17,  1.62s/it] 42%|████▏     | 2464/5922 [1:13:49<1:28:48,  1.54s/it] 42%|████▏     | 2465/5922 [1:13:50<1:25:34,  1.49s/it] 42%|████▏     | 2466/5922 [1:13:52<1:32:51,  1.61s/it] 42%|████▏     | 2467/5922 [1:13:54<1:37:53,  1.70s/it] 42%|████▏     | 2468/5922 [1:13:56<1:40:16,  1.74s/it] 42%|████▏     | 2469/5922 [1:13:58<1:41:59,  1.77s/it] 42%|████▏     | 2470/5922 [1:13:59<1:35:05,  1.65s/it] 42%|████▏     | 2471/5922 [1:14:02<1:49:06,  1.90s/it] 42%|████▏     | 2472/5922 [1:14:03<1:40:28,  1.75s/it] 42%|████▏     | 2473/5922 [1:14:05<1:46:56,  1.86s/it] 42%|████▏     | 2474/5922 [1:14:07<1:39:05,  1.72s/it] 42%|████▏     | 2475/5922 [1:14:08<1:33:48,  1.63s/it]                                                       {'loss': 0.1395, 'grad_norm': 0.34774928668662114, 'learning_rate': 1.3098646165877287e-05, 'epoch': 1.25}
 42%|████▏     | 2475/5922 [1:14:08<1:33:48,  1.63s/it] 42%|████▏     | 2476/5922 [1:14:09<1:29:25,  1.56s/it] 42%|████▏     | 2477/5922 [1:14:11<1:29:42,  1.56s/it] 42%|████▏     | 2478/5922 [1:14:12<1:26:55,  1.51s/it] 42%|████▏     | 2479/5922 [1:14:14<1:24:33,  1.47s/it] 42%|████▏     | 2480/5922 [1:14:15<1:23:08,  1.45s/it] 42%|████▏     | 2481/5922 [1:14:17<1:33:51,  1.64s/it] 42%|████▏     | 2482/5922 [1:14:19<1:29:41,  1.56s/it] 42%|████▏     | 2483/5922 [1:14:20<1:26:09,  1.50s/it] 42%|████▏     | 2484/5922 [1:14:22<1:33:05,  1.62s/it] 42%|████▏     | 2485/5922 [1:14:24<1:38:33,  1.72s/it] 42%|████▏     | 2486/5922 [1:14:26<1:41:57,  1.78s/it] 42%|████▏     | 2487/5922 [1:14:27<1:37:21,  1.70s/it] 42%|████▏     | 2488/5922 [1:14:30<1:50:26,  1.93s/it] 42%|████▏     | 2489/5922 [1:14:32<1:59:16,  2.08s/it] 42%|████▏     | 2490/5922 [1:14:34<1:57:41,  2.06s/it] 42%|████▏     | 2491/5922 [1:14:36<1:55:42,  2.02s/it] 42%|████▏     | 2492/5922 [1:14:37<1:44:45,  1.83s/it] 42%|████▏     | 2493/5922 [1:14:39<1:37:10,  1.70s/it] 42%|████▏     | 2494/5922 [1:14:40<1:32:51,  1.63s/it] 42%|████▏     | 2495/5922 [1:14:42<1:38:31,  1.72s/it] 42%|████▏     | 2496/5922 [1:14:45<1:51:12,  1.95s/it] 42%|████▏     | 2497/5922 [1:14:46<1:41:32,  1.78s/it] 42%|████▏     | 2498/5922 [1:14:47<1:34:51,  1.66s/it] 42%|████▏     | 2499/5922 [1:14:49<1:39:40,  1.75s/it] 42%|████▏     | 2500/5922 [1:14:52<1:51:42,  1.96s/it]                                                       {'loss': 0.1456, 'grad_norm': 0.3944023736740212, 'learning_rate': 1.2975988915866466e-05, 'epoch': 1.27}
 42%|████▏     | 2500/5922 [1:14:52<1:51:42,  1.96s/it][INFO|trainer.py:3993] 2025-08-30 15:03:43,583 >> Saving model checkpoint to saves/qwen3-1.7B/lora/sft/checkpoint-2500
[INFO|configuration_utils.py:696] 2025-08-30 15:03:43,596 >> loading configuration file /home/qianwenhao/LLM/Qwen3-1.7B/config.json
[INFO|configuration_utils.py:770] 2025-08-30 15:03:43,597 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "max_position_embeddings": 40960,
  "max_window_layers": 28,
  "model_type": "qwen3",
  "num_attention_heads": 16,
  "num_hidden_layers": 28,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|tokenization_utils_base.py:2356] 2025-08-30 15:03:43,614 >> chat template saved in saves/qwen3-1.7B/lora/sft/checkpoint-2500/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-08-30 15:03:43,614 >> tokenizer config file saved in saves/qwen3-1.7B/lora/sft/checkpoint-2500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-08-30 15:03:43,615 >> Special tokens file saved in saves/qwen3-1.7B/lora/sft/checkpoint-2500/special_tokens_map.json
[2025-08-30 15:03:43,779] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step2499 is about to be saved!
[2025-08-30 15:03:43,787] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: saves/qwen3-1.7B/lora/sft/checkpoint-2500/global_step2499/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-08-30 15:03:43,787] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-2500/global_step2499/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-08-30 15:03:43,793] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-2500/global_step2499/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-08-30 15:03:43,793] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-2500/global_step2499/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-08-30 15:03:43,806] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-2500/global_step2499/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-08-30 15:03:43,806] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved saves/qwen3-1.7B/lora/sft/checkpoint-2500/global_step2499/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-08-30 15:03:43,812] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2499 is ready now!
 42%|████▏     | 2501/5922 [1:14:56<2:33:16,  2.69s/it] 42%|████▏     | 2502/5922 [1:14:58<2:23:35,  2.52s/it] 42%|████▏     | 2503/5922 [1:15:00<2:07:51,  2.24s/it] 42%|████▏     | 2504/5922 [1:15:02<1:56:14,  2.04s/it] 42%|████▏     | 2505/5922 [1:15:03<1:45:14,  1.85s/it] 42%|████▏     | 2506/5922 [1:15:04<1:40:21,  1.76s/it] 42%|████▏     | 2507/5922 [1:15:06<1:35:35,  1.68s/it] 42%|████▏     | 2508/5922 [1:15:08<1:39:46,  1.75s/it] 42%|████▏     | 2509/5922 [1:15:09<1:33:30,  1.64s/it] 42%|████▏     | 2510/5922 [1:15:11<1:29:20,  1.57s/it] 42%|████▏     | 2511/5922 [1:15:13<1:44:14,  1.83s/it] 42%|████▏     | 2512/5922 [1:15:15<1:36:36,  1.70s/it] 42%|████▏     | 2513/5922 [1:15:16<1:40:33,  1.77s/it] 42%|████▏     | 2514/5922 [1:15:18<1:33:58,  1.65s/it] 42%|████▏     | 2515/5922 [1:15:20<1:39:16,  1.75s/it] 42%|████▏     | 2516/5922 [1:15:21<1:36:25,  1.70s/it] 43%|████▎     | 2517/5922 [1:15:23<1:30:47,  1.60s/it] 43%|████▎     | 2518/5922 [1:15:24<1:29:42,  1.58s/it] 43%|████▎     | 2519/5922 [1:15:26<1:32:29,  1.63s/it] 43%|████▎     | 2520/5922 [1:15:28<1:37:41,  1.72s/it] 43%|████▎     | 2521/5922 [1:15:30<1:40:51,  1.78s/it] 43%|████▎     | 2522/5922 [1:15:32<1:39:25,  1.75s/it] 43%|████▎     | 2523/5922 [1:15:34<1:42:19,  1.81s/it] 43%|████▎     | 2524/5922 [1:15:35<1:35:16,  1.68s/it] 43%|████▎     | 2525/5922 [1:15:37<1:45:03,  1.86s/it]                                                       {'loss': 0.1345, 'grad_norm': 0.38712991786775103, 'learning_rate': 1.285288720825852e-05, 'epoch': 1.28}
 43%|████▎     | 2525/5922 [1:15:37<1:45:03,  1.86s/it] 43%|████▎     | 2526/5922 [1:15:39<1:37:58,  1.73s/it] 43%|████▎     | 2527/5922 [1:15:41<1:41:23,  1.79s/it] 43%|████▎     | 2528/5922 [1:15:42<1:42:19,  1.81s/it] 43%|████▎     | 2529/5922 [1:15:44<1:35:03,  1.68s/it] 43%|████▎     | 2530/5922 [1:15:46<1:40:50,  1.78s/it] 43%|████▎     | 2531/5922 [1:15:48<1:43:25,  1.83s/it] 43%|████▎     | 2532/5922 [1:15:50<1:43:05,  1.82s/it] 43%|████▎     | 2533/5922 [1:15:51<1:44:42,  1.85s/it] 43%|████▎     | 2534/5922 [1:15:53<1:37:37,  1.73s/it] 43%|████▎     | 2535/5922 [1:15:54<1:31:57,  1.63s/it] 43%|████▎     | 2536/5922 [1:15:56<1:39:55,  1.77s/it] 43%|████▎     | 2537/5922 [1:15:58<1:36:55,  1.72s/it] 43%|████▎     | 2538/5922 [1:16:00<1:34:01,  1.67s/it] 43%|████▎     | 2539/5922 [1:16:02<1:39:14,  1.76s/it] 43%|████▎     | 2540/5922 [1:16:03<1:32:59,  1.65s/it] 43%|████▎     | 2541/5922 [1:16:05<1:35:33,  1.70s/it] 43%|████▎     | 2542/5922 [1:16:07<1:39:51,  1.77s/it] 43%|████▎     | 2543/5922 [1:16:09<1:43:01,  1.83s/it] 43%|████▎     | 2544/5922 [1:16:10<1:35:43,  1.70s/it] 43%|████▎     | 2545/5922 [1:16:12<1:40:00,  1.78s/it] 43%|████▎     | 2546/5922 [1:16:14<1:42:53,  1.83s/it] 43%|████▎     | 2547/5922 [1:16:16<1:44:11,  1.85s/it] 43%|████▎     | 2548/5922 [1:16:18<1:48:08,  1.92s/it] 43%|████▎     | 2549/5922 [1:16:19<1:40:30,  1.79s/it] 43%|████▎     | 2550/5922 [1:16:21<1:33:58,  1.67s/it]                                                       {'loss': 0.1339, 'grad_norm': 0.42310983664864016, 'learning_rate': 1.2729363140684337e-05, 'epoch': 1.29}
 43%|████▎     | 2550/5922 [1:16:21<1:33:58,  1.67s/it] 43%|████▎     | 2551/5922 [1:16:22<1:29:26,  1.59s/it] 43%|████▎     | 2552/5922 [1:16:24<1:32:24,  1.65s/it] 43%|████▎     | 2553/5922 [1:16:26<1:30:54,  1.62s/it] 43%|████▎     | 2554/5922 [1:16:27<1:29:36,  1.60s/it] 43%|████▎     | 2555/5922 [1:16:28<1:26:20,  1.54s/it] 43%|████▎     | 2556/5922 [1:16:31<1:42:34,  1.83s/it] 43%|████▎     | 2557/5922 [1:16:32<1:36:36,  1.72s/it] 43%|████▎     | 2558/5922 [1:16:34<1:40:34,  1.79s/it] 43%|████▎     | 2559/5922 [1:16:36<1:34:52,  1.69s/it] 43%|████▎     | 2560/5922 [1:16:38<1:39:01,  1.77s/it] 43%|████▎     | 2561/5922 [1:16:39<1:32:53,  1.66s/it] 43%|████▎     | 2562/5922 [1:16:41<1:36:52,  1.73s/it] 43%|████▎     | 2563/5922 [1:16:43<1:43:05,  1.84s/it] 43%|████▎     | 2564/5922 [1:16:45<1:35:46,  1.71s/it] 43%|████▎     | 2565/5922 [1:16:46<1:30:13,  1.61s/it] 43%|████▎     | 2566/5922 [1:16:48<1:28:50,  1.59s/it] 43%|████▎     | 2567/5922 [1:16:50<1:34:49,  1.70s/it] 43%|████▎     | 2568/5922 [1:16:51<1:30:06,  1.61s/it] 43%|████▎     | 2569/5922 [1:16:52<1:27:21,  1.56s/it] 43%|████▎     | 2570/5922 [1:16:55<1:40:45,  1.80s/it] 43%|████▎     | 2571/5922 [1:16:56<1:34:19,  1.69s/it] 43%|████▎     | 2572/5922 [1:16:58<1:38:13,  1.76s/it] 43%|████▎     | 2573/5922 [1:17:00<1:40:45,  1.81s/it] 43%|████▎     | 2574/5922 [1:17:02<1:42:53,  1.84s/it] 43%|████▎     | 2575/5922 [1:17:04<1:44:10,  1.87s/it]                                                       {'loss': 0.1443, 'grad_norm': 0.39657525680010836, 'learning_rate': 1.2605438886591433e-05, 'epoch': 1.3}
 43%|████▎     | 2575/5922 [1:17:04<1:44:10,  1.87s/it] 43%|████▎     | 2576/5922 [1:17:06<1:45:41,  1.90s/it] 44%|████▎     | 2577/5922 [1:17:08<1:45:47,  1.90s/it] 44%|████▎     | 2578/5922 [1:17:09<1:43:32,  1.86s/it] 44%|████▎     | 2579/5922 [1:17:12<1:47:03,  1.92s/it] 44%|████▎     | 2580/5922 [1:17:13<1:47:08,  1.92s/it] 44%|████▎     | 2581/5922 [1:17:15<1:47:42,  1.93s/it] 44%|████▎     | 2582/5922 [1:17:18<1:56:13,  2.09s/it] 44%|████▎     | 2583/5922 [1:17:20<1:53:21,  2.04s/it] 44%|████▎     | 2584/5922 [1:17:22<1:50:14,  1.98s/it] 44%|████▎     | 2585/5922 [1:17:23<1:45:00,  1.89s/it] 44%|████▎     | 2586/5922 [1:17:25<1:47:25,  1.93s/it] 44%|████▎     | 2587/5922 [1:17:27<1:39:14,  1.79s/it] 44%|████▎     | 2588/5922 [1:17:29<1:42:02,  1.84s/it] 44%|████▎     | 2589/5922 [1:17:31<1:44:39,  1.88s/it] 44%|████▎     | 2590/5922 [1:17:32<1:36:27,  1.74s/it] 44%|████▍     | 2591/5922 [1:17:34<1:42:38,  1.85s/it] 44%|████▍     | 2592/5922 [1:17:36<1:43:48,  1.87s/it] 44%|████▍     | 2593/5922 [1:17:38<1:37:54,  1.76s/it] 44%|████▍     | 2594/5922 [1:17:39<1:35:30,  1.72s/it] 44%|████▍     | 2595/5922 [1:17:41<1:38:41,  1.78s/it] 44%|████▍     | 2596/5922 [1:17:43<1:44:17,  1.88s/it] 44%|████▍     | 2597/5922 [1:17:45<1:42:39,  1.85s/it] 44%|████▍     | 2598/5922 [1:17:47<1:34:54,  1.71s/it] 44%|████▍     | 2599/5922 [1:17:48<1:38:39,  1.78s/it] 44%|████▍     | 2600/5922 [1:17:51<1:46:59,  1.93s/it]                                                       {'loss': 0.1356, 'grad_norm': 0.4055898643359105, 'learning_rate': 1.2481136691263636e-05, 'epoch': 1.32}
 44%|████▍     | 2600/5922 [1:17:51<1:46:59,  1.93s/it] 44%|████▍     | 2601/5922 [1:17:53<1:46:55,  1.93s/it] 44%|████▍     | 2602/5922 [1:17:55<1:46:31,  1.93s/it] 44%|████▍     | 2603/5922 [1:17:56<1:41:00,  1.83s/it] 44%|████▍     | 2604/5922 [1:17:59<1:51:45,  2.02s/it] 44%|████▍     | 2605/5922 [1:18:00<1:43:35,  1.87s/it] 44%|████▍     | 2606/5922 [1:18:02<1:36:07,  1.74s/it] 44%|████▍     | 2607/5922 [1:18:04<1:47:51,  1.95s/it] 44%|████▍     | 2608/5922 [1:18:06<1:46:49,  1.93s/it] 44%|████▍     | 2609/5922 [1:18:08<1:48:46,  1.97s/it] 44%|████▍     | 2610/5922 [1:18:10<1:54:49,  2.08s/it] 44%|████▍     | 2611/5922 [1:18:12<1:43:52,  1.88s/it] 44%|████▍     | 2612/5922 [1:18:13<1:35:54,  1.74s/it] 44%|████▍     | 2613/5922 [1:18:15<1:30:40,  1.64s/it] 44%|████▍     | 2614/5922 [1:18:17<1:35:19,  1.73s/it] 44%|████▍     | 2615/5922 [1:18:18<1:29:20,  1.62s/it] 44%|████▍     | 2616/5922 [1:18:19<1:25:05,  1.54s/it] 44%|████▍     | 2617/5922 [1:18:21<1:31:51,  1.67s/it] 44%|████▍     | 2618/5922 [1:18:23<1:34:53,  1.72s/it] 44%|████▍     | 2619/5922 [1:18:25<1:45:34,  1.92s/it] 44%|████▍     | 2620/5922 [1:18:27<1:37:34,  1.77s/it] 44%|████▍     | 2621/5922 [1:18:29<1:38:39,  1.79s/it] 44%|████▍     | 2622/5922 [1:18:30<1:31:56,  1.67s/it] 44%|████▍     | 2623/5922 [1:18:32<1:34:40,  1.72s/it] 44%|████▍     | 2624/5922 [1:18:33<1:29:01,  1.62s/it] 44%|████▍     | 2625/5922 [1:18:35<1:34:04,  1.71s/it]                                                       {'loss': 0.1355, 'grad_norm': 0.36055133951223056, 'learning_rate': 1.2356478867827922e-05, 'epoch': 1.33}
 44%|████▍     | 2625/5922 [1:18:35<1:34:04,  1.71s/it] 44%|████▍     | 2626/5922 [1:18:37<1:39:14,  1.81s/it] 44%|████▍     | 2627/5922 [1:18:39<1:35:46,  1.74s/it] 44%|████▍     | 2628/5922 [1:18:41<1:47:13,  1.95s/it] 44%|████▍     | 2629/5922 [1:18:43<1:43:55,  1.89s/it] 44%|████▍     | 2630/5922 [1:18:44<1:35:46,  1.75s/it] 44%|████▍     | 2631/5922 [1:18:47<1:47:23,  1.96s/it] 44%|████▍     | 2632/5922 [1:18:49<1:51:32,  2.03s/it] 44%|████▍     | 2633/5922 [1:18:51<1:46:32,  1.94s/it] 44%|████▍     | 2634/5922 [1:18:52<1:38:23,  1.80s/it] 44%|████▍     | 2635/5922 [1:18:54<1:40:32,  1.84s/it] 45%|████▍     | 2636/5922 [1:18:56<1:36:55,  1.77s/it] 45%|████▍     | 2637/5922 [1:18:57<1:31:41,  1.67s/it] 45%|████▍     | 2638/5922 [1:18:59<1:35:48,  1.75s/it] 45%|████▍     | 2639/5922 [1:19:01<1:30:44,  1.66s/it] 45%|████▍     | 2640/5922 [1:19:02<1:28:01,  1.61s/it] 45%|████▍     | 2641/5922 [1:19:04<1:35:09,  1.74s/it] 45%|████▍     | 2642/5922 [1:19:06<1:30:02,  1.65s/it] 45%|████▍     | 2643/5922 [1:19:08<1:35:13,  1.74s/it] 45%|████▍     | 2644/5922 [1:19:09<1:30:53,  1.66s/it] 45%|████▍     | 2645/5922 [1:19:11<1:38:04,  1.80s/it] 45%|████▍     | 2646/5922 [1:19:13<1:37:00,  1.78s/it] 45%|████▍     | 2647/5922 [1:19:15<1:40:47,  1.85s/it] 45%|████▍     | 2648/5922 [1:19:17<1:37:29,  1.79s/it] 45%|████▍     | 2649/5922 [1:19:18<1:35:16,  1.75s/it] 45%|████▍     | 2650/5922 [1:19:20<1:30:05,  1.65s/it]                                                       {'loss': 0.135, 'grad_norm': 0.38617818075621263, 'learning_rate': 1.2231487793249024e-05, 'epoch': 1.34}
 45%|████▍     | 2650/5922 [1:19:20<1:30:05,  1.65s/it] 45%|████▍     | 2651/5922 [1:19:22<1:35:15,  1.75s/it] 45%|████▍     | 2652/5922 [1:19:24<1:47:02,  1.96s/it] 45%|████▍     | 2653/5922 [1:19:26<1:44:05,  1.91s/it] 45%|████▍     | 2654/5922 [1:19:28<1:44:07,  1.91s/it] 45%|████▍     | 2655/5922 [1:19:30<1:43:43,  1.91s/it] 45%|████▍     | 2656/5922 [1:19:32<1:42:45,  1.89s/it] 45%|████▍     | 2657/5922 [1:19:34<1:52:08,  2.06s/it] 45%|████▍     | 2658/5922 [1:19:35<1:41:20,  1.86s/it] 45%|████▍     | 2659/5922 [1:19:37<1:42:55,  1.89s/it] 45%|████▍     | 2660/5922 [1:19:40<1:51:42,  2.05s/it] 45%|████▍     | 2661/5922 [1:19:41<1:41:54,  1.88s/it] 45%|████▍     | 2662/5922 [1:19:43<1:42:50,  1.89s/it] 45%|████▍     | 2663/5922 [1:19:45<1:45:19,  1.94s/it] 45%|████▍     | 2664/5922 [1:19:48<1:54:05,  2.10s/it] 45%|████▌     | 2665/5922 [1:19:50<1:50:41,  2.04s/it] 45%|████▌     | 2666/5922 [1:19:51<1:40:25,  1.85s/it] 45%|████▌     | 2667/5922 [1:19:53<1:34:45,  1.75s/it] 45%|████▌     | 2668/5922 [1:19:54<1:34:36,  1.74s/it] 45%|████▌     | 2669/5922 [1:19:56<1:36:14,  1.78s/it] 45%|████▌     | 2670/5922 [1:19:58<1:38:32,  1.82s/it] 45%|████▌     | 2671/5922 [1:20:00<1:34:33,  1.75s/it] 45%|████▌     | 2672/5922 [1:20:02<1:38:10,  1.81s/it] 45%|████▌     | 2673/5922 [1:20:04<1:43:44,  1.92s/it] 45%|████▌     | 2674/5922 [1:20:05<1:38:01,  1.81s/it] 45%|████▌     | 2675/5922 [1:20:07<1:40:27,  1.86s/it]                                                       {'loss': 0.1347, 'grad_norm': 0.39122539420395097, 'learning_rate': 1.210618590431263e-05, 'epoch': 1.36}
 45%|████▌     | 2675/5922 [1:20:07<1:40:27,  1.86s/it] 45%|████▌     | 2676/5922 [1:20:09<1:35:15,  1.76s/it] 45%|████▌     | 2677/5922 [1:20:11<1:39:00,  1.83s/it] 45%|████▌     | 2678/5922 [1:20:12<1:31:32,  1.69s/it] 45%|████▌     | 2679/5922 [1:20:14<1:28:59,  1.65s/it] 45%|████▌     | 2680/5922 [1:20:15<1:24:23,  1.56s/it] 45%|████▌     | 2681/5922 [1:20:17<1:23:44,  1.55s/it] 45%|████▌     | 2682/5922 [1:20:18<1:24:05,  1.56s/it] 45%|████▌     | 2683/5922 [1:20:20<1:29:39,  1.66s/it] 45%|████▌     | 2684/5922 [1:20:21<1:25:31,  1.58s/it] 45%|████▌     | 2685/5922 [1:20:24<1:39:57,  1.85s/it] 45%|████▌     | 2686/5922 [1:20:25<1:32:04,  1.71s/it] 45%|████▌     | 2687/5922 [1:20:28<1:44:04,  1.93s/it] 45%|████▌     | 2688/5922 [1:20:30<1:44:02,  1.93s/it] 45%|████▌     | 2689/5922 [1:20:32<1:52:31,  2.09s/it] 45%|████▌     | 2690/5922 [1:20:34<1:40:45,  1.87s/it] 45%|████▌     | 2691/5922 [1:20:36<1:48:28,  2.01s/it] 45%|████▌     | 2692/5922 [1:20:38<1:47:08,  1.99s/it] 45%|████▌     | 2693/5922 [1:20:39<1:37:21,  1.81s/it] 45%|████▌     | 2694/5922 [1:20:41<1:40:12,  1.86s/it] 46%|████▌     | 2695/5922 [1:20:43<1:41:45,  1.89s/it] 46%|████▌     | 2696/5922 [1:20:45<1:39:38,  1.85s/it] 46%|████▌     | 2697/5922 [1:20:46<1:34:06,  1.75s/it] 46%|████▌     | 2698/5922 [1:20:48<1:37:56,  1.82s/it] 46%|████▌     | 2699/5922 [1:20:50<1:32:05,  1.71s/it] 46%|████▌     | 2700/5922 [1:20:52<1:41:56,  1.90s/it]                                                       {'loss': 0.1356, 'grad_norm': 0.417383650317623, 'learning_rate': 1.1980595693597818e-05, 'epoch': 1.37}
 46%|████▌     | 2700/5922 [1:20:52<1:41:56,  1.90s/it] 46%|████▌     | 2701/5922 [1:20:54<1:33:52,  1.75s/it] 46%|████▌     | 2702/5922 [1:20:55<1:30:57,  1.69s/it] 46%|████▌     | 2703/5922 [1:20:57<1:34:34,  1.76s/it] 46%|████▌     | 2704/5922 [1:20:59<1:36:34,  1.80s/it] 46%|████▌     | 2705/5922 [1:21:01<1:36:28,  1.80s/it] 46%|████▌     | 2706/5922 [1:21:03<1:41:41,  1.90s/it] 46%|████▌     | 2707/5922 [1:21:05<1:50:40,  2.07s/it] 46%|████▌     | 2708/5922 [1:21:07<1:40:22,  1.87s/it] 46%|████▌     | 2709/5922 [1:21:08<1:35:12,  1.78s/it] 46%|████▌     | 2710/5922 [1:21:11<1:43:40,  1.94s/it] 46%|████▌     | 2711/5922 [1:21:13<1:52:18,  2.10s/it] 46%|████▌     | 2712/5922 [1:21:15<1:41:05,  1.89s/it] 46%|████▌     | 2713/5922 [1:21:16<1:40:07,  1.87s/it] 46%|████▌     | 2714/5922 [1:21:18<1:32:22,  1.73s/it] 46%|████▌     | 2715/5922 [1:21:19<1:26:26,  1.62s/it] 46%|████▌     | 2716/5922 [1:21:21<1:24:26,  1.58s/it] 46%|████▌     | 2717/5922 [1:21:23<1:29:39,  1.68s/it] 46%|████▌     | 2718/5922 [1:21:25<1:35:52,  1.80s/it] 46%|████▌     | 2719/5922 [1:21:26<1:33:05,  1.74s/it] 46%|████▌     | 2720/5922 [1:21:28<1:27:20,  1.64s/it] 46%|████▌     | 2721/5922 [1:21:30<1:31:47,  1.72s/it] 46%|████▌     | 2722/5922 [1:21:31<1:32:57,  1.74s/it] 46%|████▌     | 2723/5922 [1:21:33<1:35:33,  1.79s/it] 46%|████▌     | 2724/5922 [1:21:35<1:37:50,  1.84s/it] 46%|████▌     | 2725/5922 [1:21:37<1:31:27,  1.72s/it]                                                       {'loss': 0.1426, 'grad_norm': 0.4067005223137959, 'learning_rate': 1.1854739705439462e-05, 'epoch': 1.38}
 46%|████▌     | 2725/5922 [1:21:37<1:31:27,  1.72s/it] 46%|████▌     | 2726/5922 [1:21:38<1:29:22,  1.68s/it] 46%|████▌     | 2727/5922 [1:21:40<1:33:20,  1.75s/it] 46%|████▌     | 2728/5922 [1:21:42<1:36:53,  1.82s/it] 46%|████▌     | 2729/5922 [1:21:44<1:42:07,  1.92s/it] 46%|████▌     | 2730/5922 [1:21:46<1:33:56,  1.77s/it] 46%|████▌     | 2731/5922 [1:21:47<1:29:46,  1.69s/it] 46%|████▌     | 2732/5922 [1:21:49<1:24:59,  1.60s/it] 46%|████▌     | 2733/5922 [1:21:51<1:36:46,  1.82s/it] 46%|████▌     | 2734/5922 [1:21:52<1:32:55,  1.75s/it] 46%|████▌     | 2735/5922 [1:21:54<1:27:05,  1.64s/it] 46%|████▌     | 2736/5922 [1:21:56<1:31:54,  1.73s/it] 46%|████▌     | 2737/5922 [1:21:58<1:34:39,  1.78s/it] 46%|████▌     | 2738/5922 [1:22:00<1:36:43,  1.82s/it] 46%|████▋     | 2739/5922 [1:22:01<1:30:14,  1.70s/it] 46%|████▋     | 2740/5922 [1:22:02<1:25:24,  1.61s/it] 46%|████▋     | 2741/5922 [1:22:04<1:28:21,  1.67s/it] 46%|████▋     | 2742/5922 [1:22:06<1:23:57,  1.58s/it] 46%|████▋     | 2743/5922 [1:22:07<1:27:41,  1.66s/it] 46%|████▋     | 2744/5922 [1:22:09<1:31:06,  1.72s/it] 46%|████▋     | 2745/5922 [1:22:11<1:34:33,  1.79s/it] 46%|████▋     | 2746/5922 [1:22:13<1:28:24,  1.67s/it] 46%|████▋     | 2747/5922 [1:22:14<1:24:28,  1.60s/it] 46%|████▋     | 2748/5922 [1:22:16<1:30:08,  1.70s/it] 46%|████▋     | 2749/5922 [1:22:18<1:42:16,  1.93s/it] 46%|████▋     | 2750/5922 [1:22:20<1:42:30,  1.94s/it]                                                       {'loss': 0.1448, 'grad_norm': 0.4858556916446884, 'learning_rate': 1.1728640531881384e-05, 'epoch': 1.39}
 46%|████▋     | 2750/5922 [1:22:20<1:42:30,  1.94s/it] 46%|████▋     | 2751/5922 [1:22:23<1:45:39,  2.00s/it] 46%|████▋     | 2752/5922 [1:22:24<1:38:37,  1.87s/it] 46%|████▋     | 2753/5922 [1:22:26<1:40:08,  1.90s/it] 47%|████▋     | 2754/5922 [1:22:28<1:41:08,  1.92s/it] 47%|████▋     | 2755/5922 [1:22:30<1:40:50,  1.91s/it] 47%|████▋     | 2756/5922 [1:22:31<1:32:43,  1.76s/it] 47%|████▋     | 2757/5922 [1:22:33<1:29:53,  1.70s/it] 47%|████▋     | 2758/5922 [1:22:34<1:24:20,  1.60s/it] 47%|████▋     | 2759/5922 [1:22:36<1:29:29,  1.70s/it] 47%|████▋     | 2760/5922 [1:22:38<1:24:28,  1.60s/it] 47%|████▋     | 2761/5922 [1:22:39<1:21:02,  1.54s/it] 47%|████▋     | 2762/5922 [1:22:40<1:18:15,  1.49s/it] 47%|████▋     | 2763/5922 [1:22:42<1:16:41,  1.46s/it] 47%|████▋     | 2764/5922 [1:22:43<1:16:58,  1.46s/it] 47%|████▋     | 2765/5922 [1:22:45<1:19:10,  1.50s/it] 47%|████▋     | 2766/5922 [1:22:47<1:28:01,  1.67s/it] 47%|████▋     | 2767/5922 [1:22:49<1:31:31,  1.74s/it] 47%|████▋     | 2768/5922 [1:22:51<1:34:02,  1.79s/it] 47%|████▋     | 2769/5922 [1:22:53<1:36:37,  1.84s/it] 47%|████▋     | 2770/5922 [1:22:54<1:36:09,  1.83s/it] 47%|████▋     | 2771/5922 [1:22:56<1:31:37,  1.74s/it] 47%|████▋     | 2772/5922 [1:22:58<1:35:25,  1.82s/it] 47%|████▋     | 2773/5922 [1:23:00<1:37:35,  1.86s/it] 47%|████▋     | 2774/5922 [1:23:02<1:36:01,  1.83s/it] 47%|████▋     | 2775/5922 [1:23:04<1:37:15,  1.85s/it]                                                       {'loss': 0.1375, 'grad_norm': 0.3119134837963495, 'learning_rate': 1.1602320808620906e-05, 'epoch': 1.41}
 47%|████▋     | 2775/5922 [1:23:04<1:37:15,  1.85s/it] 47%|████▋     | 2776/5922 [1:23:06<1:38:42,  1.88s/it] 47%|████▋     | 2777/5922 [1:23:07<1:36:59,  1.85s/it] 47%|████▋     | 2778/5922 [1:23:09<1:37:00,  1.85s/it] 47%|████▋     | 2779/5922 [1:23:11<1:36:20,  1.84s/it] 47%|████▋     | 2780/5922 [1:23:13<1:37:46,  1.87s/it] 47%|████▋     | 2781/5922 [1:23:14<1:32:05,  1.76s/it] 47%|████▋     | 2782/5922 [1:23:16<1:31:04,  1.74s/it] 47%|████▋     | 2783/5922 [1:23:19<1:40:58,  1.93s/it] 47%|████▋     | 2784/5922 [1:23:20<1:40:20,  1.92s/it] 47%|████▋     | 2785/5922 [1:23:22<1:34:03,  1.80s/it] 47%|████▋     | 2786/5922 [1:23:24<1:30:38,  1.73s/it] 47%|████▋     | 2787/5922 [1:23:25<1:33:31,  1.79s/it] 47%|████▋     | 2788/5922 [1:23:27<1:35:21,  1.83s/it] 47%|████▋     | 2789/5922 [1:23:29<1:35:51,  1.84s/it] 47%|████▋     | 2790/5922 [1:23:31<1:28:42,  1.70s/it] 47%|████▋     | 2791/5922 [1:23:33<1:32:18,  1.77s/it] 47%|████▋     | 2792/5922 [1:23:34<1:34:31,  1.81s/it] 47%|████▋     | 2793/5922 [1:23:37<1:38:43,  1.89s/it] 47%|████▋     | 2794/5922 [1:23:38<1:30:28,  1.74s/it] 47%|████▋     | 2795/5922 [1:23:40<1:42:01,  1.96s/it] 47%|████▋     | 2796/5922 [1:23:42<1:39:44,  1.91s/it] 47%|████▋     | 2797/5922 [1:23:44<1:38:36,  1.89s/it] 47%|████▋     | 2798/5922 [1:23:45<1:30:39,  1.74s/it] 47%|████▋     | 2799/5922 [1:23:47<1:26:47,  1.67s/it] 47%|████▋     | 2800/5922 [1:23:49<1:30:40,  1.74s/it]                                                       {'loss': 0.1523, 'grad_norm': 0.45603982047169983, 'learning_rate': 1.1475803210945593e-05, 'epoch': 1.42}
 47%|████▋     | 2800/5922 [1:23:49<1:30:40,  1.74s/it] 47%|████▋     | 2801/5922 [1:23:51<1:33:44,  1.80s/it] 47%|████▋     | 2802/5922 [1:23:52<1:28:56,  1.71s/it] 47%|████▋     | 2803/5922 [1:23:54<1:26:33,  1.67s/it] 47%|████▋     | 2804/5922 [1:23:55<1:23:53,  1.61s/it] 47%|████▋     | 2805/5922 [1:23:57<1:29:17,  1.72s/it] 47%|████▋     | 2806/5922 [1:23:59<1:29:36,  1.73s/it] 47%|████▋     | 2807/5922 [1:24:01<1:32:45,  1.79s/it] 47%|████▋     | 2808/5922 [1:24:03<1:37:04,  1.87s/it] 47%|████▋     | 2809/5922 [1:24:05<1:38:02,  1.89s/it] 47%|████▋     | 2810/5922 [1:24:06<1:30:50,  1.75s/it] 47%|████▋     | 2811/5922 [1:24:08<1:26:53,  1.68s/it] 47%|████▋     | 2812/5922 [1:24:10<1:30:43,  1.75s/it] 48%|████▊     | 2813/5922 [1:24:11<1:25:21,  1.65s/it] 48%|████▊     | 2814/5922 [1:24:13<1:29:54,  1.74s/it] 48%|████▊     | 2815/5922 [1:24:15<1:24:29,  1.63s/it] 48%|████▊     | 2816/5922 [1:24:16<1:21:57,  1.58s/it] 48%|████▊     | 2817/5922 [1:24:18<1:23:09,  1.61s/it] 48%|████▊     | 2818/5922 [1:24:19<1:21:47,  1.58s/it] 48%|████▊     | 2819/5922 [1:24:21<1:27:18,  1.69s/it] 48%|████▊     | 2820/5922 [1:24:23<1:37:31,  1.89s/it] 48%|████▊     | 2821/5922 [1:24:25<1:29:44,  1.74s/it] 48%|████▊     | 2822/5922 [1:24:26<1:24:22,  1.63s/it] 48%|████▊     | 2823/5922 [1:24:28<1:23:20,  1.61s/it] 48%|████▊     | 2824/5922 [1:24:29<1:19:08,  1.53s/it] 48%|████▊     | 2825/5922 [1:24:31<1:26:35,  1.68s/it]                                                       {'loss': 0.1382, 'grad_norm': 0.38264172598799917, 'learning_rate': 1.1349110449662873e-05, 'epoch': 1.43}
 48%|████▊     | 2825/5922 [1:24:31<1:26:35,  1.68s/it] 48%|████▊     | 2826/5922 [1:24:33<1:22:02,  1.59s/it] 48%|████▊     | 2827/5922 [1:24:34<1:20:01,  1.55s/it] 48%|████▊     | 2828/5922 [1:24:36<1:28:01,  1.71s/it] 48%|████▊     | 2829/5922 [1:24:37<1:23:19,  1.62s/it] 48%|████▊     | 2830/5922 [1:24:39<1:28:07,  1.71s/it] 48%|████▊     | 2831/5922 [1:24:41<1:33:46,  1.82s/it] 48%|████▊     | 2832/5922 [1:24:43<1:29:35,  1.74s/it] 48%|████▊     | 2833/5922 [1:24:45<1:32:29,  1.80s/it] 48%|████▊     | 2834/5922 [1:24:47<1:29:38,  1.74s/it] 48%|████▊     | 2835/5922 [1:24:48<1:29:06,  1.73s/it] 48%|████▊     | 2836/5922 [1:24:50<1:23:39,  1.63s/it] 48%|████▊     | 2837/5922 [1:24:52<1:27:57,  1.71s/it] 48%|████▊     | 2838/5922 [1:24:53<1:29:04,  1.73s/it] 48%|████▊     | 2839/5922 [1:24:55<1:24:29,  1.64s/it] 48%|████▊     | 2840/5922 [1:24:57<1:28:11,  1.72s/it] 48%|████▊     | 2841/5922 [1:24:59<1:30:58,  1.77s/it] 48%|████▊     | 2842/5922 [1:25:00<1:32:43,  1.81s/it] 48%|████▊     | 2843/5922 [1:25:02<1:32:42,  1.81s/it] 48%|████▊     | 2844/5922 [1:25:04<1:26:28,  1.69s/it] 48%|████▊     | 2845/5922 [1:25:05<1:26:40,  1.69s/it] 48%|████▊     | 2846/5922 [1:25:07<1:21:56,  1.60s/it] 48%|████▊     | 2847/5922 [1:25:08<1:22:11,  1.60s/it] 48%|████▊     | 2848/5922 [1:25:10<1:27:29,  1.71s/it] 48%|████▊     | 2849/5922 [1:25:12<1:23:12,  1.62s/it] 48%|████▊     | 2850/5922 [1:25:13<1:19:54,  1.56s/it]                                                       {'loss': 0.1405, 'grad_norm': 0.3518687446123292, 'learning_rate': 1.1222265267023278e-05, 'epoch': 1.44}
 48%|████▊     | 2850/5922 [1:25:13<1:19:54,  1.56s/it] 48%|████▊     | 2851/5922 [1:25:15<1:23:09,  1.62s/it] 48%|████▊     | 2852/5922 [1:25:17<1:22:26,  1.61s/it] 48%|████▊     | 2853/5922 [1:25:18<1:24:07,  1.64s/it] 48%|████▊     | 2854/5922 [1:25:20<1:28:06,  1.72s/it] 48%|████▊     | 2855/5922 [1:25:22<1:31:42,  1.79s/it] 48%|████▊     | 2856/5922 [1:25:24<1:25:22,  1.67s/it] 48%|████▊     | 2857/5922 [1:25:26<1:31:46,  1.80s/it] 48%|████▊     | 2858/5922 [1:25:27<1:25:36,  1.68s/it] 48%|████▊     | 2859/5922 [1:25:28<1:21:24,  1.59s/it] 48%|████▊     | 2860/5922 [1:25:30<1:19:53,  1.57s/it] 48%|████▊     | 2861/5922 [1:25:32<1:31:13,  1.79s/it] 48%|████▊     | 2862/5922 [1:25:34<1:33:19,  1.83s/it] 48%|████▊     | 2863/5922 [1:25:36<1:29:36,  1.76s/it] 48%|████▊     | 2864/5922 [1:25:38<1:31:37,  1.80s/it] 48%|████▊     | 2865/5922 [1:25:39<1:32:20,  1.81s/it] 48%|████▊     | 2866/5922 [1:25:41<1:26:26,  1.70s/it] 48%|████▊     | 2867/5922 [1:25:42<1:22:02,  1.61s/it] 48%|████▊     | 2868/5922 [1:25:44<1:18:43,  1.55s/it] 48%|████▊     | 2869/5922 [1:25:45<1:16:19,  1.50s/it] 48%|████▊     | 2870/5922 [1:25:46<1:14:28,  1.46s/it] 48%|████▊     | 2871/5922 [1:25:48<1:21:43,  1.61s/it] 48%|████▊     | 2872/5922 [1:25:50<1:26:30,  1.70s/it] 49%|████▊     | 2873/5922 [1:25:52<1:22:30,  1.62s/it] 49%|████▊     | 2874/5922 [1:25:53<1:20:00,  1.58s/it] 49%|████▊     | 2875/5922 [1:25:55<1:16:31,  1.51s/it]                                                       {'loss': 0.14, 'grad_norm': 0.41372056922479883, 'learning_rate': 1.1095290432638071e-05, 'epoch': 1.46}
 49%|████▊     | 2875/5922 [1:25:55<1:16:31,  1.51s/it] 49%|████▊     | 2876/5922 [1:25:56<1:21:27,  1.60s/it] 49%|████▊     | 2877/5922 [1:25:58<1:18:40,  1.55s/it] 49%|████▊     | 2878/5922 [1:26:00<1:24:13,  1.66s/it] 49%|████▊     | 2879/5922 [1:26:01<1:19:57,  1.58s/it] 49%|████▊     | 2880/5922 [1:26:03<1:28:29,  1.75s/it] 49%|████▊     | 2881/5922 [1:26:05<1:25:21,  1.68s/it] 49%|████▊     | 2882/5922 [1:26:07<1:29:07,  1.76s/it] 49%|████▊     | 2883/5922 [1:26:09<1:31:09,  1.80s/it] 49%|████▊     | 2884/5922 [1:26:10<1:26:13,  1.70s/it] 49%|████▊     | 2885/5922 [1:26:12<1:32:43,  1.83s/it] 49%|████▊     | 2886/5922 [1:26:14<1:36:45,  1.91s/it] 49%|████▉     | 2887/5922 [1:26:17<1:45:18,  2.08s/it] 49%|████▉     | 2888/5922 [1:26:18<1:34:36,  1.87s/it] 49%|████▉     | 2889/5922 [1:26:20<1:34:38,  1.87s/it] 49%|████▉     | 2890/5922 [1:26:21<1:27:12,  1.73s/it] 49%|████▉     | 2891/5922 [1:26:23<1:30:09,  1.78s/it] 49%|████▉     | 2892/5922 [1:26:26<1:37:46,  1.94s/it] 49%|████▉     | 2893/5922 [1:26:27<1:35:21,  1.89s/it] 49%|████▉     | 2894/5922 [1:26:29<1:35:49,  1.90s/it] 49%|████▉     | 2895/5922 [1:26:31<1:29:46,  1.78s/it] 49%|████▉     | 2896/5922 [1:26:33<1:32:01,  1.82s/it] 49%|████▉     | 2897/5922 [1:26:34<1:25:41,  1.70s/it] 49%|████▉     | 2898/5922 [1:26:36<1:21:27,  1.62s/it] 49%|████▉     | 2899/5922 [1:26:37<1:18:43,  1.56s/it] 49%|████▉     | 2900/5922 [1:26:39<1:24:12,  1.67s/it]                                                       {'loss': 0.1436, 'grad_norm': 0.4017127291894064, 'learning_rate': 1.0968208739391903e-05, 'epoch': 1.47}
 49%|████▉     | 2900/5922 [1:26:39<1:24:12,  1.67s/it] 49%|████▉     | 2901/5922 [1:26:41<1:30:12,  1.79s/it] 49%|████▉     | 2902/5922 [1:26:42<1:24:07,  1.67s/it] 49%|████▉     | 2903/5922 [1:26:44<1:19:57,  1.59s/it] 49%|████▉     | 2904/5922 [1:26:45<1:17:17,  1.54s/it] 49%|████▉     | 2905/5922 [1:26:47<1:22:13,  1.64s/it] 49%|████▉     | 2906/5922 [1:26:49<1:25:43,  1.71s/it] 49%|████▉     | 2907/5922 [1:26:51<1:29:10,  1.77s/it] 49%|████▉     | 2908/5922 [1:26:52<1:23:23,  1.66s/it] 49%|████▉     | 2909/5922 [1:26:54<1:19:08,  1.58s/it] 49%|████▉     | 2910/5922 [1:26:56<1:24:45,  1.69s/it] 49%|████▉     | 2911/5922 [1:26:58<1:28:28,  1.76s/it] 49%|████▉     | 2912/5922 [1:26:59<1:30:22,  1.80s/it] 49%|████▉     | 2913/5922 [1:27:01<1:33:11,  1.86s/it] 49%|████▉     | 2914/5922 [1:27:03<1:26:34,  1.73s/it] 49%|████▉     | 2915/5922 [1:27:04<1:21:39,  1.63s/it] 49%|████▉     | 2916/5922 [1:27:06<1:27:07,  1.74s/it] 49%|████▉     | 2917/5922 [1:27:08<1:30:06,  1.80s/it] 49%|████▉     | 2918/5922 [1:27:10<1:23:19,  1.66s/it] 49%|████▉     | 2919/5922 [1:27:11<1:19:31,  1.59s/it] 49%|████▉     | 2920/5922 [1:27:13<1:28:13,  1.76s/it] 49%|████▉     | 2921/5922 [1:27:15<1:30:50,  1.82s/it] 49%|████▉     | 2922/5922 [1:27:17<1:24:37,  1.69s/it] 49%|████▉     | 2923/5922 [1:27:18<1:26:18,  1.73s/it] 49%|████▉     | 2924/5922 [1:27:20<1:29:06,  1.78s/it] 49%|████▉     | 2925/5922 [1:27:22<1:31:16,  1.83s/it]                                                       {'loss': 0.1372, 'grad_norm': 0.41999874609583565, 'learning_rate': 1.0841042999351374e-05, 'epoch': 1.48}
 49%|████▉     | 2925/5922 [1:27:22<1:31:16,  1.83s/it] 49%|████▉     | 2926/5922 [1:27:24<1:25:01,  1.70s/it] 49%|████▉     | 2927/5922 [1:27:26<1:31:01,  1.82s/it] 49%|████▉     | 2928/5922 [1:27:28<1:40:20,  2.01s/it] 49%|████▉     | 2929/5922 [1:27:30<1:30:51,  1.82s/it] 49%|████▉     | 2930/5922 [1:27:31<1:33:05,  1.87s/it] 49%|████▉     | 2931/5922 [1:27:33<1:30:54,  1.82s/it] 50%|████▉     | 2932/5922 [1:27:35<1:24:22,  1.69s/it] 50%|████▉     | 2933/5922 [1:27:37<1:27:51,  1.76s/it] 50%|████▉     | 2934/5922 [1:27:39<1:32:15,  1.85s/it] 50%|████▉     | 2935/5922 [1:27:41<1:33:09,  1.87s/it] 50%|████▉     | 2936/5922 [1:27:42<1:26:19,  1.73s/it] 50%|████▉     | 2937/5922 [1:27:43<1:21:04,  1.63s/it] 50%|████▉     | 2938/5922 [1:27:45<1:26:24,  1.74s/it] 50%|████▉     | 2939/5922 [1:27:47<1:28:08,  1.77s/it] 50%|████▉     | 2940/5922 [1:27:49<1:24:15,  1.70s/it] 50%|████▉     | 2941/5922 [1:27:50<1:21:51,  1.65s/it] 50%|████▉     | 2942/5922 [1:27:52<1:26:11,  1.74s/it] 50%|████▉     | 2943/5922 [1:27:54<1:27:28,  1.76s/it] 50%|████▉     | 2944/5922 [1:27:56<1:29:33,  1.80s/it] 50%|████▉     | 2945/5922 [1:27:57<1:23:50,  1.69s/it] 50%|████▉     | 2946/5922 [1:27:59<1:27:24,  1.76s/it] 50%|████▉     | 2947/5922 [1:28:01<1:30:03,  1.82s/it] 50%|████▉     | 2948/5922 [1:28:03<1:29:37,  1.81s/it] 50%|████▉     | 2949/5922 [1:28:05<1:30:04,  1.82s/it] 50%|████▉     | 2950/5922 [1:28:07<1:31:30,  1.85s/it]                                                       {'loss': 0.1322, 'grad_norm': 0.375770180552703, 'learning_rate': 1.0713816039670064e-05, 'epoch': 1.49}
 50%|████▉     | 2950/5922 [1:28:07<1:31:30,  1.85s/it] 50%|████▉     | 2951/5922 [1:28:09<1:40:19,  2.03s/it] 50%|████▉     | 2952/5922 [1:28:11<1:38:26,  1.99s/it] 50%|████▉     | 2953/5922 [1:28:12<1:29:45,  1.81s/it] 50%|████▉     | 2954/5922 [1:28:14<1:24:07,  1.70s/it] 50%|████▉     | 2955/5922 [1:28:15<1:19:19,  1.60s/it] 50%|████▉     | 2956/5922 [1:28:17<1:22:16,  1.66s/it] 50%|████▉     | 2957/5922 [1:28:18<1:17:40,  1.57s/it] 50%|████▉     | 2958/5922 [1:28:20<1:19:29,  1.61s/it] 50%|████▉     | 2959/5922 [1:28:23<1:30:46,  1.84s/it] 50%|████▉     | 2960/5922 [1:28:24<1:24:06,  1.70s/it] 50%|█████     | 2961/5922 [1:28:25<1:21:25,  1.65s/it] 50%|█████     | 2962/5922 [1:28:27<1:25:25,  1.73s/it] 50%|█████     | 2963/5922 [1:28:29<1:19:58,  1.62s/it] 50%|█████     | 2964/5922 [1:28:31<1:32:24,  1.87s/it] 50%|█████     | 2965/5922 [1:28:33<1:31:06,  1.85s/it] 50%|█████     | 2966/5922 [1:28:35<1:39:53,  2.03s/it] 50%|█████     | 2967/5922 [1:28:37<1:39:08,  2.01s/it] 50%|█████     | 2968/5922 [1:28:39<1:37:46,  1.99s/it] 50%|█████     | 2969/5922 [1:28:41<1:32:42,  1.88s/it] 50%|█████     | 2970/5922 [1:28:42<1:27:06,  1.77s/it] 50%|█████     | 2971/5922 [1:28:44<1:22:02,  1.67s/it] 50%|█████     | 2972/5922 [1:28:46<1:26:18,  1.76s/it] 50%|█████     | 2973/5922 [1:28:47<1:20:59,  1.65s/it] 50%|█████     | 2974/5922 [1:28:49<1:24:55,  1.73s/it] 50%|█████     | 2975/5922 [1:28:51<1:20:02,  1.63s/it]                                                       {'loss': 0.1374, 'grad_norm': 0.3800478977152418, 'learning_rate': 1.0586550698490912e-05, 'epoch': 1.51}
 50%|█████     | 2975/5922 [1:28:51<1:20:02,  1.63s/it] 50%|█████     | 2976/5922 [1:28:52<1:23:13,  1.70s/it] 50%|█████     | 2977/5922 [1:28:54<1:19:14,  1.61s/it] 50%|█████     | 2978/5922 [1:28:56<1:23:46,  1.71s/it] 50%|█████     | 2979/5922 [1:28:58<1:34:34,  1.93s/it] 50%|█████     | 2980/5922 [1:29:01<1:42:21,  2.09s/it] 50%|█████     | 2981/5922 [1:29:02<1:31:56,  1.88s/it] 50%|█████     | 2982/5922 [1:29:04<1:32:25,  1.89s/it] 50%|█████     | 2983/5922 [1:29:05<1:24:36,  1.73s/it] 50%|█████     | 2984/5922 [1:29:07<1:23:07,  1.70s/it] 50%|█████     | 2985/5922 [1:29:08<1:20:17,  1.64s/it] 50%|█████     | 2986/5922 [1:29:11<1:26:56,  1.78s/it] 50%|█████     | 2987/5922 [1:29:12<1:29:12,  1.82s/it] 50%|█████     | 2988/5922 [1:29:14<1:29:52,  1.84s/it] 50%|█████     | 2989/5922 [1:29:16<1:26:43,  1.77s/it] 50%|█████     | 2990/5922 [1:29:18<1:28:42,  1.82s/it] 51%|█████     | 2991/5922 [1:29:20<1:29:33,  1.83s/it] 51%|█████     | 2992/5922 [1:29:22<1:30:32,  1.85s/it] 51%|█████     | 2993/5922 [1:29:24<1:31:23,  1.87s/it] 51%|█████     | 2994/5922 [1:29:26<1:38:58,  2.03s/it] 51%|█████     | 2995/5922 [1:29:28<1:37:28,  2.00s/it] 51%|█████     | 2996/5922 [1:29:30<1:36:39,  1.98s/it] 51%|█████     | 2997/5922 [1:29:32<1:43:22,  2.12s/it] 51%|█████     | 2998/5922 [1:29:34<1:38:24,  2.02s/it] 51%|█████     | 2999/5922 [1:29:36<1:35:32,  1.96s/it] 51%|█████     | 3000/5922 [1:29:38<1:37:36,  2.00s/it]                                                       {'loss': 0.1434, 'grad_norm': 0.4320669820136403, 'learning_rate': 1.045926982084662e-05, 'epoch': 1.52}
 51%|█████     | 3000/5922 [1:29:38<1:37:36,  2.00s/it][INFO|trainer.py:3993] 2025-08-30 15:18:29,731 >> Saving model checkpoint to saves/qwen3-1.7B/lora/sft/checkpoint-3000
[INFO|configuration_utils.py:696] 2025-08-30 15:18:29,743 >> loading configuration file /home/qianwenhao/LLM/Qwen3-1.7B/config.json
[INFO|configuration_utils.py:770] 2025-08-30 15:18:29,743 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "max_position_embeddings": 40960,
  "max_window_layers": 28,
  "model_type": "qwen3",
  "num_attention_heads": 16,
  "num_hidden_layers": 28,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|tokenization_utils_base.py:2356] 2025-08-30 15:18:29,760 >> chat template saved in saves/qwen3-1.7B/lora/sft/checkpoint-3000/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-08-30 15:18:29,760 >> tokenizer config file saved in saves/qwen3-1.7B/lora/sft/checkpoint-3000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-08-30 15:18:29,760 >> Special tokens file saved in saves/qwen3-1.7B/lora/sft/checkpoint-3000/special_tokens_map.json
[2025-08-30 15:18:29,964] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step2999 is about to be saved!
[2025-08-30 15:18:29,974] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: saves/qwen3-1.7B/lora/sft/checkpoint-3000/global_step2999/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-08-30 15:18:29,974] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-3000/global_step2999/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-08-30 15:18:29,979] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-3000/global_step2999/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-08-30 15:18:29,980] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-3000/global_step2999/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-08-30 15:18:29,991] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-3000/global_step2999/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-08-30 15:18:29,991] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved saves/qwen3-1.7B/lora/sft/checkpoint-3000/global_step2999/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-08-30 15:18:30,000] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2999 is ready now!
 51%|█████     | 3001/5922 [1:29:42<2:00:39,  2.48s/it] 51%|█████     | 3002/5922 [1:29:44<1:53:51,  2.34s/it] 51%|█████     | 3003/5922 [1:29:45<1:45:02,  2.16s/it] 51%|█████     | 3004/5922 [1:29:47<1:34:24,  1.94s/it] 51%|█████     | 3005/5922 [1:29:49<1:34:00,  1.93s/it] 51%|█████     | 3006/5922 [1:29:50<1:25:38,  1.76s/it] 51%|█████     | 3007/5922 [1:29:51<1:20:44,  1.66s/it] 51%|█████     | 3008/5922 [1:29:53<1:17:23,  1.59s/it] 51%|█████     | 3009/5922 [1:29:54<1:14:28,  1.53s/it] 51%|█████     | 3010/5922 [1:29:56<1:20:12,  1.65s/it] 51%|█████     | 3011/5922 [1:29:58<1:24:40,  1.75s/it] 51%|█████     | 3012/5922 [1:30:00<1:28:11,  1.82s/it] 51%|█████     | 3013/5922 [1:30:02<1:22:12,  1.70s/it] 51%|█████     | 3014/5922 [1:30:03<1:17:53,  1.61s/it] 51%|█████     | 3015/5922 [1:30:05<1:21:17,  1.68s/it] 51%|█████     | 3016/5922 [1:30:07<1:21:49,  1.69s/it] 51%|█████     | 3017/5922 [1:30:08<1:25:04,  1.76s/it] 51%|█████     | 3018/5922 [1:30:10<1:27:17,  1.80s/it] 51%|█████     | 3019/5922 [1:30:12<1:29:02,  1.84s/it] 51%|█████     | 3020/5922 [1:30:14<1:31:43,  1.90s/it] 51%|█████     | 3021/5922 [1:30:16<1:24:12,  1.74s/it] 51%|█████     | 3022/5922 [1:30:18<1:26:51,  1.80s/it] 51%|█████     | 3023/5922 [1:30:20<1:31:39,  1.90s/it] 51%|█████     | 3024/5922 [1:30:22<1:32:06,  1.91s/it] 51%|█████     | 3025/5922 [1:30:23<1:26:33,  1.79s/it]                                                       {'loss': 0.1358, 'grad_norm': 0.42381410717268836, 'learning_rate': 1.033199625455879e-05, 'epoch': 1.53}
 51%|█████     | 3025/5922 [1:30:23<1:26:33,  1.79s/it] 51%|█████     | 3026/5922 [1:30:26<1:36:16,  1.99s/it] 51%|█████     | 3027/5922 [1:30:27<1:29:46,  1.86s/it] 51%|█████     | 3028/5922 [1:30:29<1:30:32,  1.88s/it] 51%|█████     | 3029/5922 [1:30:31<1:23:23,  1.73s/it] 51%|█████     | 3030/5922 [1:30:33<1:34:37,  1.96s/it] 51%|█████     | 3031/5922 [1:30:35<1:33:58,  1.95s/it] 51%|█████     | 3032/5922 [1:30:37<1:33:53,  1.95s/it] 51%|█████     | 3033/5922 [1:30:39<1:30:31,  1.88s/it] 51%|█████     | 3034/5922 [1:30:40<1:24:55,  1.76s/it] 51%|█████     | 3035/5922 [1:30:42<1:20:11,  1.67s/it] 51%|█████▏    | 3036/5922 [1:30:43<1:16:10,  1.58s/it] 51%|█████▏    | 3037/5922 [1:30:44<1:13:13,  1.52s/it] 51%|█████▏    | 3038/5922 [1:30:47<1:26:02,  1.79s/it] 51%|█████▏    | 3039/5922 [1:30:48<1:23:25,  1.74s/it] 51%|█████▏    | 3040/5922 [1:30:50<1:26:05,  1.79s/it] 51%|█████▏    | 3041/5922 [1:30:53<1:33:45,  1.95s/it] 51%|█████▏    | 3042/5922 [1:30:54<1:27:53,  1.83s/it] 51%|█████▏    | 3043/5922 [1:30:56<1:27:44,  1.83s/it] 51%|█████▏    | 3044/5922 [1:30:58<1:28:20,  1.84s/it] 51%|█████▏    | 3045/5922 [1:30:59<1:24:53,  1.77s/it] 51%|█████▏    | 3046/5922 [1:31:01<1:27:39,  1.83s/it] 51%|█████▏    | 3047/5922 [1:31:03<1:21:47,  1.71s/it] 51%|█████▏    | 3048/5922 [1:31:04<1:17:20,  1.61s/it] 51%|█████▏    | 3049/5922 [1:31:06<1:13:38,  1.54s/it] 52%|█████▏    | 3050/5922 [1:31:08<1:18:53,  1.65s/it]                                                       {'loss': 0.1358, 'grad_norm': 0.39164858160436894, 'learning_rate': 1.0204752846136581e-05, 'epoch': 1.55}
 52%|█████▏    | 3050/5922 [1:31:08<1:18:53,  1.65s/it] 52%|█████▏    | 3051/5922 [1:31:09<1:14:38,  1.56s/it] 52%|█████▏    | 3052/5922 [1:31:10<1:12:07,  1.51s/it] 52%|█████▏    | 3053/5922 [1:31:12<1:18:16,  1.64s/it] 52%|█████▏    | 3054/5922 [1:31:14<1:15:00,  1.57s/it] 52%|█████▏    | 3055/5922 [1:31:16<1:19:44,  1.67s/it] 52%|█████▏    | 3056/5922 [1:31:17<1:16:11,  1.60s/it] 52%|█████▏    | 3057/5922 [1:31:19<1:20:33,  1.69s/it] 52%|█████▏    | 3058/5922 [1:31:21<1:24:16,  1.77s/it] 52%|█████▏    | 3059/5922 [1:31:22<1:19:43,  1.67s/it] 52%|█████▏    | 3060/5922 [1:31:24<1:18:58,  1.66s/it] 52%|█████▏    | 3061/5922 [1:31:26<1:25:15,  1.79s/it] 52%|█████▏    | 3062/5922 [1:31:28<1:33:55,  1.97s/it] 52%|█████▏    | 3063/5922 [1:31:30<1:35:19,  2.00s/it] 52%|█████▏    | 3064/5922 [1:31:32<1:31:09,  1.91s/it] 52%|█████▏    | 3065/5922 [1:31:34<1:31:02,  1.91s/it] 52%|█████▏    | 3066/5922 [1:31:35<1:24:02,  1.77s/it] 52%|█████▏    | 3067/5922 [1:31:38<1:34:02,  1.98s/it] 52%|█████▏    | 3068/5922 [1:31:39<1:25:20,  1.79s/it] 52%|█████▏    | 3069/5922 [1:31:41<1:19:20,  1.67s/it] 52%|█████▏    | 3070/5922 [1:31:42<1:15:40,  1.59s/it] 52%|█████▏    | 3071/5922 [1:31:44<1:25:04,  1.79s/it] 52%|█████▏    | 3072/5922 [1:31:46<1:19:12,  1.67s/it] 52%|█████▏    | 3073/5922 [1:31:47<1:15:07,  1.58s/it] 52%|█████▏    | 3074/5922 [1:31:49<1:12:37,  1.53s/it] 52%|█████▏    | 3075/5922 [1:31:51<1:20:03,  1.69s/it]                                                       {'loss': 0.1335, 'grad_norm': 0.4377123328931471, 'learning_rate': 1.0077562436675607e-05, 'epoch': 1.56}
 52%|█████▏    | 3075/5922 [1:31:51<1:20:03,  1.69s/it] 52%|█████▏    | 3076/5922 [1:31:52<1:17:27,  1.63s/it] 52%|█████▏    | 3077/5922 [1:31:54<1:15:59,  1.60s/it] 52%|█████▏    | 3078/5922 [1:31:55<1:12:44,  1.53s/it] 52%|█████▏    | 3079/5922 [1:31:56<1:10:36,  1.49s/it] 52%|█████▏    | 3080/5922 [1:31:59<1:23:13,  1.76s/it] 52%|█████▏    | 3081/5922 [1:32:00<1:22:00,  1.73s/it] 52%|█████▏    | 3082/5922 [1:32:02<1:16:55,  1.63s/it] 52%|█████▏    | 3083/5922 [1:32:04<1:20:57,  1.71s/it] 52%|█████▏    | 3084/5922 [1:32:06<1:24:49,  1.79s/it] 52%|█████▏    | 3085/5922 [1:32:07<1:19:04,  1.67s/it] 52%|█████▏    | 3086/5922 [1:32:09<1:23:59,  1.78s/it] 52%|█████▏    | 3087/5922 [1:32:10<1:18:04,  1.65s/it] 52%|█████▏    | 3088/5922 [1:32:12<1:14:01,  1.57s/it] 52%|█████▏    | 3089/5922 [1:32:14<1:19:11,  1.68s/it] 52%|█████▏    | 3090/5922 [1:32:16<1:21:05,  1.72s/it] 52%|█████▏    | 3091/5922 [1:32:17<1:17:35,  1.64s/it] 52%|█████▏    | 3092/5922 [1:32:18<1:13:57,  1.57s/it] 52%|█████▏    | 3093/5922 [1:32:20<1:18:37,  1.67s/it] 52%|█████▏    | 3094/5922 [1:32:22<1:16:06,  1.61s/it] 52%|█████▏    | 3095/5922 [1:32:23<1:16:39,  1.63s/it] 52%|█████▏    | 3096/5922 [1:32:25<1:21:47,  1.74s/it] 52%|█████▏    | 3097/5922 [1:32:27<1:16:58,  1.63s/it] 52%|█████▏    | 3098/5922 [1:32:28<1:16:14,  1.62s/it] 52%|█████▏    | 3099/5922 [1:32:30<1:12:30,  1.54s/it] 52%|█████▏    | 3100/5922 [1:32:31<1:11:58,  1.53s/it]                                                       {'loss': 0.1312, 'grad_norm': 0.33921520149241785, 'learning_rate': 9.950447857757783e-06, 'epoch': 1.57}
 52%|█████▏    | 3100/5922 [1:32:31<1:11:58,  1.53s/it] 52%|█████▏    | 3101/5922 [1:32:33<1:09:54,  1.49s/it] 52%|█████▏    | 3102/5922 [1:32:35<1:16:17,  1.62s/it] 52%|█████▏    | 3103/5922 [1:32:36<1:15:05,  1.60s/it] 52%|█████▏    | 3104/5922 [1:32:38<1:22:51,  1.76s/it] 52%|█████▏    | 3105/5922 [1:32:40<1:24:38,  1.80s/it] 52%|█████▏    | 3106/5922 [1:32:42<1:24:58,  1.81s/it] 52%|█████▏    | 3107/5922 [1:32:43<1:18:40,  1.68s/it] 52%|█████▏    | 3108/5922 [1:32:45<1:23:33,  1.78s/it] 52%|█████▏    | 3109/5922 [1:32:47<1:26:59,  1.86s/it] 53%|█████▎    | 3110/5922 [1:32:49<1:28:08,  1.88s/it] 53%|█████▎    | 3111/5922 [1:32:52<1:35:53,  2.05s/it] 53%|█████▎    | 3112/5922 [1:32:54<1:33:13,  1.99s/it] 53%|█████▎    | 3113/5922 [1:32:56<1:32:10,  1.97s/it] 53%|█████▎    | 3114/5922 [1:32:57<1:24:07,  1.80s/it] 53%|█████▎    | 3115/5922 [1:32:59<1:27:03,  1.86s/it] 53%|█████▎    | 3116/5922 [1:33:01<1:22:22,  1.76s/it] 53%|█████▎    | 3117/5922 [1:33:02<1:21:05,  1.73s/it] 53%|█████▎    | 3118/5922 [1:33:04<1:21:57,  1.75s/it] 53%|█████▎    | 3119/5922 [1:33:05<1:17:08,  1.65s/it] 53%|█████▎    | 3120/5922 [1:33:07<1:13:27,  1.57s/it] 53%|█████▎    | 3121/5922 [1:33:08<1:10:21,  1.51s/it] 53%|█████▎    | 3122/5922 [1:33:10<1:10:14,  1.51s/it] 53%|█████▎    | 3123/5922 [1:33:12<1:23:49,  1.80s/it] 53%|█████▎    | 3124/5922 [1:33:14<1:17:54,  1.67s/it] 53%|█████▎    | 3125/5922 [1:33:16<1:23:57,  1.80s/it]                                                       {'loss': 0.1417, 'grad_norm': 0.4490978034131399, 'learning_rate': 9.823431927352917e-06, 'epoch': 1.58}
 53%|█████▎    | 3125/5922 [1:33:16<1:23:57,  1.80s/it] 53%|█████▎    | 3126/5922 [1:33:17<1:18:08,  1.68s/it] 53%|█████▎    | 3127/5922 [1:33:19<1:19:29,  1.71s/it] 53%|█████▎    | 3128/5922 [1:33:21<1:20:58,  1.74s/it] 53%|█████▎    | 3129/5922 [1:33:23<1:23:39,  1.80s/it] 53%|█████▎    | 3130/5922 [1:33:25<1:25:55,  1.85s/it] 53%|█████▎    | 3131/5922 [1:33:26<1:27:03,  1.87s/it] 53%|█████▎    | 3132/5922 [1:33:28<1:21:02,  1.74s/it] 53%|█████▎    | 3133/5922 [1:33:30<1:23:14,  1.79s/it] 53%|█████▎    | 3134/5922 [1:33:32<1:25:06,  1.83s/it] 53%|█████▎    | 3135/5922 [1:33:34<1:26:24,  1.86s/it] 53%|█████▎    | 3136/5922 [1:33:35<1:20:18,  1.73s/it] 53%|█████▎    | 3137/5922 [1:33:36<1:15:57,  1.64s/it] 53%|█████▎    | 3138/5922 [1:33:38<1:19:01,  1.70s/it] 53%|█████▎    | 3139/5922 [1:33:40<1:17:27,  1.67s/it] 53%|█████▎    | 3140/5922 [1:33:41<1:13:32,  1.59s/it] 53%|█████▎    | 3141/5922 [1:33:43<1:18:12,  1.69s/it] 53%|█████▎    | 3142/5922 [1:33:45<1:21:06,  1.75s/it] 53%|█████▎    | 3143/5922 [1:33:47<1:17:46,  1.68s/it] 53%|█████▎    | 3144/5922 [1:33:49<1:21:10,  1.75s/it] 53%|█████▎    | 3145/5922 [1:33:51<1:23:27,  1.80s/it] 53%|█████▎    | 3146/5922 [1:33:53<1:27:01,  1.88s/it] 53%|█████▎    | 3147/5922 [1:33:55<1:30:42,  1.96s/it] 53%|█████▎    | 3148/5922 [1:33:56<1:26:43,  1.88s/it] 53%|█████▎    | 3149/5922 [1:33:58<1:27:11,  1.89s/it] 53%|█████▎    | 3150/5922 [1:34:00<1:20:10,  1.74s/it]                                                       {'loss': 0.1352, 'grad_norm': 0.3661028712136314, 'learning_rate': 9.696537445722695e-06, 'epoch': 1.6}
 53%|█████▎    | 3150/5922 [1:34:00<1:20:10,  1.74s/it] 53%|█████▎    | 3151/5922 [1:34:01<1:18:18,  1.70s/it] 53%|█████▎    | 3152/5922 [1:34:03<1:14:02,  1.60s/it] 53%|█████▎    | 3153/5922 [1:34:05<1:26:07,  1.87s/it] 53%|█████▎    | 3154/5922 [1:34:08<1:34:18,  2.04s/it] 53%|█████▎    | 3155/5922 [1:34:10<1:32:57,  2.02s/it] 53%|█████▎    | 3156/5922 [1:34:11<1:24:00,  1.82s/it] 53%|█████▎    | 3157/5922 [1:34:13<1:26:22,  1.87s/it] 53%|█████▎    | 3158/5922 [1:34:14<1:19:32,  1.73s/it] 53%|█████▎    | 3159/5922 [1:34:16<1:16:35,  1.66s/it] 53%|█████▎    | 3160/5922 [1:34:18<1:27:25,  1.90s/it] 53%|█████▎    | 3161/5922 [1:34:20<1:27:35,  1.90s/it] 53%|█████▎    | 3162/5922 [1:34:22<1:26:56,  1.89s/it] 53%|█████▎    | 3163/5922 [1:34:23<1:19:41,  1.73s/it] 53%|█████▎    | 3164/5922 [1:34:25<1:16:11,  1.66s/it] 53%|█████▎    | 3165/5922 [1:34:26<1:12:25,  1.58s/it] 53%|█████▎    | 3166/5922 [1:34:28<1:16:57,  1.68s/it] 53%|█████▎    | 3167/5922 [1:34:30<1:12:54,  1.59s/it] 53%|█████▎    | 3168/5922 [1:34:31<1:16:25,  1.66s/it] 54%|█████▎    | 3169/5922 [1:34:33<1:18:30,  1.71s/it] 54%|█████▎    | 3170/5922 [1:34:35<1:14:04,  1.61s/it] 54%|█████▎    | 3171/5922 [1:34:36<1:14:53,  1.63s/it] 54%|█████▎    | 3172/5922 [1:34:38<1:11:35,  1.56s/it] 54%|█████▎    | 3173/5922 [1:34:40<1:16:37,  1.67s/it] 54%|█████▎    | 3174/5922 [1:34:42<1:20:14,  1.75s/it] 54%|█████▎    | 3175/5922 [1:34:43<1:17:52,  1.70s/it]                                                       {'loss': 0.1345, 'grad_norm': 0.39326979095535475, 'learning_rate': 9.569787191327886e-06, 'epoch': 1.61}
 54%|█████▎    | 3175/5922 [1:34:43<1:17:52,  1.70s/it] 54%|█████▎    | 3176/5922 [1:34:45<1:13:31,  1.61s/it] 54%|█████▎    | 3177/5922 [1:34:47<1:20:32,  1.76s/it] 54%|█████▎    | 3178/5922 [1:34:48<1:15:16,  1.65s/it] 54%|█████▎    | 3179/5922 [1:34:50<1:12:57,  1.60s/it] 54%|█████▎    | 3180/5922 [1:34:51<1:09:56,  1.53s/it] 54%|█████▎    | 3181/5922 [1:34:53<1:15:15,  1.65s/it] 54%|█████▎    | 3182/5922 [1:34:55<1:22:04,  1.80s/it] 54%|█████▎    | 3183/5922 [1:34:57<1:23:32,  1.83s/it] 54%|█████▍    | 3184/5922 [1:34:59<1:21:30,  1.79s/it] 54%|█████▍    | 3185/5922 [1:35:00<1:23:01,  1.82s/it] 54%|█████▍    | 3186/5922 [1:35:02<1:17:14,  1.69s/it] 54%|█████▍    | 3187/5922 [1:35:03<1:13:35,  1.61s/it] 54%|█████▍    | 3188/5922 [1:35:05<1:13:54,  1.62s/it] 54%|█████▍    | 3189/5922 [1:35:06<1:10:41,  1.55s/it] 54%|█████▍    | 3190/5922 [1:35:08<1:15:29,  1.66s/it] 54%|█████▍    | 3191/5922 [1:35:10<1:16:51,  1.69s/it] 54%|█████▍    | 3192/5922 [1:35:12<1:20:11,  1.76s/it] 54%|█████▍    | 3193/5922 [1:35:13<1:14:25,  1.64s/it] 54%|█████▍    | 3194/5922 [1:35:15<1:17:57,  1.71s/it] 54%|█████▍    | 3195/5922 [1:35:17<1:20:14,  1.77s/it] 54%|█████▍    | 3196/5922 [1:35:19<1:16:25,  1.68s/it] 54%|█████▍    | 3197/5922 [1:35:20<1:12:37,  1.60s/it] 54%|█████▍    | 3198/5922 [1:35:22<1:17:14,  1.70s/it] 54%|█████▍    | 3199/5922 [1:35:24<1:26:40,  1.91s/it] 54%|█████▍    | 3200/5922 [1:35:26<1:24:36,  1.86s/it]                                                       {'loss': 0.1382, 'grad_norm': 0.4669101572235025, 'learning_rate': 9.443203916739455e-06, 'epoch': 1.62}
 54%|█████▍    | 3200/5922 [1:35:26<1:24:36,  1.86s/it] 54%|█████▍    | 3201/5922 [1:35:28<1:23:43,  1.85s/it] 54%|█████▍    | 3202/5922 [1:35:29<1:17:09,  1.70s/it] 54%|█████▍    | 3203/5922 [1:35:31<1:18:25,  1.73s/it] 54%|█████▍    | 3204/5922 [1:35:33<1:24:53,  1.87s/it] 54%|█████▍    | 3205/5922 [1:35:35<1:18:04,  1.72s/it] 54%|█████▍    | 3206/5922 [1:35:37<1:22:40,  1.83s/it] 54%|█████▍    | 3207/5922 [1:35:38<1:16:13,  1.68s/it] 54%|█████▍    | 3208/5922 [1:35:40<1:19:17,  1.75s/it] 54%|█████▍    | 3209/5922 [1:35:42<1:27:54,  1.94s/it] 54%|█████▍    | 3210/5922 [1:35:45<1:35:07,  2.10s/it] 54%|█████▍    | 3211/5922 [1:35:46<1:25:29,  1.89s/it] 54%|█████▍    | 3212/5922 [1:35:48<1:20:53,  1.79s/it] 54%|█████▍    | 3213/5922 [1:35:50<1:22:47,  1.83s/it] 54%|█████▍    | 3214/5922 [1:35:51<1:21:25,  1.80s/it] 54%|█████▍    | 3215/5922 [1:35:53<1:19:46,  1.77s/it] 54%|█████▍    | 3216/5922 [1:35:55<1:21:51,  1.81s/it] 54%|█████▍    | 3217/5922 [1:35:57<1:18:15,  1.74s/it] 54%|█████▍    | 3218/5922 [1:35:58<1:16:07,  1.69s/it] 54%|█████▍    | 3219/5922 [1:36:00<1:17:56,  1.73s/it] 54%|█████▍    | 3220/5922 [1:36:02<1:18:22,  1.74s/it] 54%|█████▍    | 3221/5922 [1:36:04<1:19:16,  1.76s/it] 54%|█████▍    | 3222/5922 [1:36:05<1:21:04,  1.80s/it] 54%|█████▍    | 3223/5922 [1:36:07<1:24:04,  1.87s/it] 54%|█████▍    | 3224/5922 [1:36:09<1:24:01,  1.87s/it] 54%|█████▍    | 3225/5922 [1:36:11<1:21:16,  1.81s/it]                                                       {'loss': 0.1267, 'grad_norm': 0.505217227486649, 'learning_rate': 9.3168103445543e-06, 'epoch': 1.63}
 54%|█████▍    | 3225/5922 [1:36:11<1:21:16,  1.81s/it] 54%|█████▍    | 3226/5922 [1:36:13<1:30:03,  2.00s/it] 54%|█████▍    | 3227/5922 [1:36:15<1:28:51,  1.98s/it] 55%|█████▍    | 3228/5922 [1:36:17<1:28:15,  1.97s/it] 55%|█████▍    | 3229/5922 [1:36:19<1:20:16,  1.79s/it] 55%|█████▍    | 3230/5922 [1:36:20<1:14:44,  1.67s/it] 55%|█████▍    | 3231/5922 [1:36:21<1:11:09,  1.59s/it] 55%|█████▍    | 3232/5922 [1:36:23<1:12:10,  1.61s/it] 55%|█████▍    | 3233/5922 [1:36:25<1:13:25,  1.64s/it] 55%|█████▍    | 3234/5922 [1:36:26<1:11:57,  1.61s/it] 55%|█████▍    | 3235/5922 [1:36:28<1:16:10,  1.70s/it] 55%|█████▍    | 3236/5922 [1:36:30<1:12:38,  1.62s/it] 55%|█████▍    | 3237/5922 [1:36:32<1:16:20,  1.71s/it] 55%|█████▍    | 3238/5922 [1:36:33<1:11:43,  1.60s/it] 55%|█████▍    | 3239/5922 [1:36:35<1:16:25,  1.71s/it] 55%|█████▍    | 3240/5922 [1:36:36<1:13:22,  1.64s/it] 55%|█████▍    | 3241/5922 [1:36:38<1:15:37,  1.69s/it] 55%|█████▍    | 3242/5922 [1:36:40<1:20:48,  1.81s/it] 55%|█████▍    | 3243/5922 [1:36:42<1:20:41,  1.81s/it] 55%|█████▍    | 3244/5922 [1:36:44<1:22:14,  1.84s/it] 55%|█████▍    | 3245/5922 [1:36:46<1:23:35,  1.87s/it] 55%|█████▍    | 3246/5922 [1:36:48<1:24:24,  1.89s/it] 55%|█████▍    | 3247/5922 [1:36:50<1:24:41,  1.90s/it] 55%|█████▍    | 3248/5922 [1:36:52<1:25:15,  1.91s/it] 55%|█████▍    | 3249/5922 [1:36:53<1:18:20,  1.76s/it] 55%|█████▍    | 3250/5922 [1:36:55<1:14:39,  1.68s/it]                                                       {'loss': 0.1388, 'grad_norm': 0.4133293420243468, 'learning_rate': 9.190629163316386e-06, 'epoch': 1.65}
 55%|█████▍    | 3250/5922 [1:36:55<1:14:39,  1.68s/it] 55%|█████▍    | 3251/5922 [1:36:57<1:17:54,  1.75s/it] 55%|█████▍    | 3252/5922 [1:36:58<1:13:27,  1.65s/it] 55%|█████▍    | 3253/5922 [1:37:00<1:20:58,  1.82s/it] 55%|█████▍    | 3254/5922 [1:37:02<1:21:00,  1.82s/it] 55%|█████▍    | 3255/5922 [1:37:04<1:20:25,  1.81s/it] 55%|█████▍    | 3256/5922 [1:37:06<1:28:05,  1.98s/it] 55%|█████▍    | 3257/5922 [1:37:08<1:20:23,  1.81s/it] 55%|█████▌    | 3258/5922 [1:37:09<1:18:46,  1.77s/it] 55%|█████▌    | 3259/5922 [1:37:11<1:21:57,  1.85s/it] 55%|█████▌    | 3260/5922 [1:37:13<1:16:52,  1.73s/it] 55%|█████▌    | 3261/5922 [1:37:14<1:11:54,  1.62s/it] 55%|█████▌    | 3262/5922 [1:37:16<1:08:39,  1.55s/it] 55%|█████▌    | 3263/5922 [1:37:17<1:11:53,  1.62s/it] 55%|█████▌    | 3264/5922 [1:37:19<1:11:00,  1.60s/it] 55%|█████▌    | 3265/5922 [1:37:21<1:18:15,  1.77s/it] 55%|█████▌    | 3266/5922 [1:37:24<1:27:30,  1.98s/it] 55%|█████▌    | 3267/5922 [1:37:25<1:19:44,  1.80s/it] 55%|█████▌    | 3268/5922 [1:37:27<1:21:14,  1.84s/it] 55%|█████▌    | 3269/5922 [1:37:29<1:29:00,  2.01s/it] 55%|█████▌    | 3270/5922 [1:37:31<1:20:38,  1.82s/it] 55%|█████▌    | 3271/5922 [1:37:32<1:20:58,  1.83s/it] 55%|█████▌    | 3272/5922 [1:37:34<1:21:57,  1.86s/it] 55%|█████▌    | 3273/5922 [1:37:36<1:15:15,  1.70s/it] 55%|█████▌    | 3274/5922 [1:37:37<1:10:53,  1.61s/it] 55%|█████▌    | 3275/5922 [1:37:39<1:13:51,  1.67s/it]                                                       {'loss': 0.1436, 'grad_norm': 0.44651183828289354, 'learning_rate': 9.064683023444007e-06, 'epoch': 1.66}
 55%|█████▌    | 3275/5922 [1:37:39<1:13:51,  1.67s/it] 55%|█████▌    | 3276/5922 [1:37:41<1:17:56,  1.77s/it] 55%|█████▌    | 3277/5922 [1:37:43<1:17:54,  1.77s/it] 55%|█████▌    | 3278/5922 [1:37:44<1:17:45,  1.76s/it] 55%|█████▌    | 3279/5922 [1:37:46<1:12:38,  1.65s/it] 55%|█████▌    | 3280/5922 [1:37:47<1:09:17,  1.57s/it] 55%|█████▌    | 3281/5922 [1:37:49<1:06:44,  1.52s/it] 55%|█████▌    | 3282/5922 [1:37:50<1:04:40,  1.47s/it] 55%|█████▌    | 3283/5922 [1:37:52<1:13:03,  1.66s/it] 55%|█████▌    | 3284/5922 [1:37:54<1:09:46,  1.59s/it] 55%|█████▌    | 3285/5922 [1:37:55<1:06:45,  1.52s/it] 55%|█████▌    | 3286/5922 [1:37:56<1:05:07,  1.48s/it] 56%|█████▌    | 3287/5922 [1:37:58<1:11:10,  1.62s/it] 56%|█████▌    | 3288/5922 [1:38:00<1:11:09,  1.62s/it] 56%|█████▌    | 3289/5922 [1:38:01<1:07:54,  1.55s/it] 56%|█████▌    | 3290/5922 [1:38:03<1:05:09,  1.49s/it] 56%|█████▌    | 3291/5922 [1:38:04<1:03:52,  1.46s/it] 56%|█████▌    | 3292/5922 [1:38:05<1:02:36,  1.43s/it] 56%|█████▌    | 3293/5922 [1:38:07<1:10:44,  1.61s/it] 56%|█████▌    | 3294/5922 [1:38:09<1:13:12,  1.67s/it] 56%|█████▌    | 3295/5922 [1:38:11<1:09:27,  1.59s/it] 56%|█████▌    | 3296/5922 [1:38:12<1:09:39,  1.59s/it] 56%|█████▌    | 3297/5922 [1:38:14<1:14:03,  1.69s/it] 56%|█████▌    | 3298/5922 [1:38:16<1:14:04,  1.69s/it] 56%|█████▌    | 3299/5922 [1:38:17<1:10:02,  1.60s/it] 56%|█████▌    | 3300/5922 [1:38:19<1:06:42,  1.53s/it]                                                       {'loss': 0.1255, 'grad_norm': 0.4169115048370827, 'learning_rate': 8.938994533163847e-06, 'epoch': 1.67}
 56%|█████▌    | 3300/5922 [1:38:19<1:06:42,  1.53s/it] 56%|█████▌    | 3301/5922 [1:38:20<1:04:28,  1.48s/it] 56%|█████▌    | 3302/5922 [1:38:21<1:03:17,  1.45s/it] 56%|█████▌    | 3303/5922 [1:38:24<1:16:41,  1.76s/it] 56%|█████▌    | 3304/5922 [1:38:25<1:14:49,  1.71s/it] 56%|█████▌    | 3305/5922 [1:38:27<1:18:10,  1.79s/it] 56%|█████▌    | 3306/5922 [1:38:29<1:12:45,  1.67s/it] 56%|█████▌    | 3307/5922 [1:38:30<1:08:51,  1.58s/it] 56%|█████▌    | 3308/5922 [1:38:32<1:09:03,  1.59s/it] 56%|█████▌    | 3309/5922 [1:38:34<1:20:18,  1.84s/it] 56%|█████▌    | 3310/5922 [1:38:36<1:14:13,  1.71s/it] 56%|█████▌    | 3311/5922 [1:38:37<1:10:18,  1.62s/it] 56%|█████▌    | 3312/5922 [1:38:38<1:07:13,  1.55s/it] 56%|█████▌    | 3313/5922 [1:38:40<1:10:03,  1.61s/it] 56%|█████▌    | 3314/5922 [1:38:41<1:07:21,  1.55s/it] 56%|█████▌    | 3315/5922 [1:38:43<1:06:28,  1.53s/it] 56%|█████▌    | 3316/5922 [1:38:45<1:11:02,  1.64s/it] 56%|█████▌    | 3317/5922 [1:38:47<1:13:06,  1.68s/it] 56%|█████▌    | 3318/5922 [1:38:48<1:09:06,  1.59s/it] 56%|█████▌    | 3319/5922 [1:38:50<1:13:31,  1.69s/it] 56%|█████▌    | 3320/5922 [1:38:51<1:09:54,  1.61s/it] 56%|█████▌    | 3321/5922 [1:38:53<1:12:05,  1.66s/it] 56%|█████▌    | 3322/5922 [1:38:55<1:15:34,  1.74s/it] 56%|█████▌    | 3323/5922 [1:38:57<1:18:07,  1.80s/it] 56%|█████▌    | 3324/5922 [1:38:58<1:11:54,  1.66s/it] 56%|█████▌    | 3325/5922 [1:39:00<1:07:38,  1.56s/it]                                                       {'loss': 0.1273, 'grad_norm': 0.43790041497761045, 'learning_rate': 8.813586254452671e-06, 'epoch': 1.68}
 56%|█████▌    | 3325/5922 [1:39:00<1:07:38,  1.56s/it] 56%|█████▌    | 3326/5922 [1:39:01<1:04:54,  1.50s/it] 56%|█████▌    | 3327/5922 [1:39:03<1:10:24,  1.63s/it] 56%|█████▌    | 3328/5922 [1:39:04<1:07:41,  1.57s/it] 56%|█████▌    | 3329/5922 [1:39:06<1:05:22,  1.51s/it] 56%|█████▌    | 3330/5922 [1:39:08<1:10:40,  1.64s/it] 56%|█████▌    | 3331/5922 [1:39:09<1:07:18,  1.56s/it] 56%|█████▋    | 3332/5922 [1:39:11<1:11:59,  1.67s/it] 56%|█████▋    | 3333/5922 [1:39:13<1:16:31,  1.77s/it] 56%|█████▋    | 3334/5922 [1:39:15<1:25:24,  1.98s/it] 56%|█████▋    | 3335/5922 [1:39:17<1:17:52,  1.81s/it] 56%|█████▋    | 3336/5922 [1:39:18<1:12:11,  1.67s/it] 56%|█████▋    | 3337/5922 [1:39:20<1:09:58,  1.62s/it] 56%|█████▋    | 3338/5922 [1:39:22<1:19:47,  1.85s/it] 56%|█████▋    | 3339/5922 [1:39:24<1:22:58,  1.93s/it] 56%|█████▋    | 3340/5922 [1:39:26<1:18:49,  1.83s/it] 56%|█████▋    | 3341/5922 [1:39:28<1:25:38,  1.99s/it] 56%|█████▋    | 3342/5922 [1:39:30<1:17:47,  1.81s/it] 56%|█████▋    | 3343/5922 [1:39:31<1:12:24,  1.68s/it] 56%|█████▋    | 3344/5922 [1:39:32<1:09:04,  1.61s/it] 56%|█████▋    | 3345/5922 [1:39:34<1:06:12,  1.54s/it] 57%|█████▋    | 3346/5922 [1:39:35<1:04:14,  1.50s/it] 57%|█████▋    | 3347/5922 [1:39:37<1:02:50,  1.46s/it] 57%|█████▋    | 3348/5922 [1:39:38<1:03:10,  1.47s/it] 57%|█████▋    | 3349/5922 [1:39:39<1:02:05,  1.45s/it] 57%|█████▋    | 3350/5922 [1:39:41<1:07:41,  1.58s/it]                                                       {'loss': 0.1328, 'grad_norm': 0.5078918824323039, 'learning_rate': 8.688480698987269e-06, 'epoch': 1.7}
 57%|█████▋    | 3350/5922 [1:39:41<1:07:41,  1.58s/it] 57%|█████▋    | 3351/5922 [1:39:43<1:05:23,  1.53s/it] 57%|█████▋    | 3352/5922 [1:39:44<1:04:36,  1.51s/it] 57%|█████▋    | 3353/5922 [1:39:46<1:03:33,  1.48s/it] 57%|█████▋    | 3354/5922 [1:39:48<1:09:29,  1.62s/it] 57%|█████▋    | 3355/5922 [1:39:50<1:13:30,  1.72s/it] 57%|█████▋    | 3356/5922 [1:39:51<1:14:09,  1.73s/it] 57%|█████▋    | 3357/5922 [1:39:53<1:10:44,  1.65s/it] 57%|█████▋    | 3358/5922 [1:39:55<1:11:59,  1.68s/it] 57%|█████▋    | 3359/5922 [1:39:56<1:08:05,  1.59s/it] 57%|█████▋    | 3360/5922 [1:39:58<1:12:27,  1.70s/it] 57%|█████▋    | 3361/5922 [1:39:59<1:08:30,  1.61s/it] 57%|█████▋    | 3362/5922 [1:40:01<1:05:52,  1.54s/it] 57%|█████▋    | 3363/5922 [1:40:03<1:10:15,  1.65s/it] 57%|█████▋    | 3364/5922 [1:40:04<1:14:06,  1.74s/it] 57%|█████▋    | 3365/5922 [1:40:07<1:21:04,  1.90s/it] 57%|█████▋    | 3366/5922 [1:40:09<1:23:44,  1.97s/it] 57%|█████▋    | 3367/5922 [1:40:11<1:27:02,  2.04s/it] 57%|█████▋    | 3368/5922 [1:40:13<1:25:36,  2.01s/it] 57%|█████▋    | 3369/5922 [1:40:15<1:30:17,  2.12s/it] 57%|█████▋    | 3370/5922 [1:40:17<1:21:01,  1.91s/it] 57%|█████▋    | 3371/5922 [1:40:18<1:14:01,  1.74s/it] 57%|█████▋    | 3372/5922 [1:40:20<1:08:53,  1.62s/it] 57%|█████▋    | 3373/5922 [1:40:21<1:07:56,  1.60s/it] 57%|█████▋    | 3374/5922 [1:40:23<1:16:37,  1.80s/it] 57%|█████▋    | 3375/5922 [1:40:25<1:17:18,  1.82s/it]                                                       {'loss': 0.1384, 'grad_norm': 0.35689185511850285, 'learning_rate': 8.56370032410346e-06, 'epoch': 1.71}
 57%|█████▋    | 3375/5922 [1:40:25<1:17:18,  1.82s/it] 57%|█████▋    | 3376/5922 [1:40:27<1:11:51,  1.69s/it] 57%|█████▋    | 3377/5922 [1:40:28<1:13:44,  1.74s/it] 57%|█████▋    | 3378/5922 [1:40:31<1:22:55,  1.96s/it] 57%|█████▋    | 3379/5922 [1:40:32<1:18:09,  1.84s/it] 57%|█████▋    | 3380/5922 [1:40:35<1:21:33,  1.93s/it] 57%|█████▋    | 3381/5922 [1:40:37<1:21:04,  1.91s/it] 57%|█████▋    | 3382/5922 [1:40:38<1:20:54,  1.91s/it] 57%|█████▋    | 3383/5922 [1:40:41<1:23:31,  1.97s/it] 57%|█████▋    | 3384/5922 [1:40:42<1:18:08,  1.85s/it] 57%|█████▋    | 3385/5922 [1:40:44<1:21:38,  1.93s/it] 57%|█████▋    | 3386/5922 [1:40:46<1:16:23,  1.81s/it] 57%|█████▋    | 3387/5922 [1:40:48<1:17:36,  1.84s/it] 57%|█████▋    | 3388/5922 [1:40:50<1:18:31,  1.86s/it] 57%|█████▋    | 3389/5922 [1:40:51<1:19:34,  1.88s/it] 57%|█████▋    | 3390/5922 [1:40:53<1:20:24,  1.91s/it] 57%|█████▋    | 3391/5922 [1:40:55<1:20:06,  1.90s/it] 57%|█████▋    | 3392/5922 [1:40:57<1:13:51,  1.75s/it] 57%|█████▋    | 3393/5922 [1:40:58<1:09:11,  1.64s/it] 57%|█████▋    | 3394/5922 [1:40:59<1:05:48,  1.56s/it] 57%|█████▋    | 3395/5922 [1:41:01<1:09:06,  1.64s/it] 57%|█████▋    | 3396/5922 [1:41:03<1:10:24,  1.67s/it] 57%|█████▋    | 3397/5922 [1:41:04<1:06:18,  1.58s/it] 57%|█████▋    | 3398/5922 [1:41:06<1:05:53,  1.57s/it] 57%|█████▋    | 3399/5922 [1:41:07<1:04:01,  1.52s/it] 57%|█████▋    | 3400/5922 [1:41:10<1:14:35,  1.77s/it]                                                       {'loss': 0.1388, 'grad_norm': 0.5633829993633446, 'learning_rate': 8.439267528764843e-06, 'epoch': 1.72}
 57%|█████▋    | 3400/5922 [1:41:10<1:14:35,  1.77s/it] 57%|█████▋    | 3401/5922 [1:41:11<1:09:40,  1.66s/it] 57%|█████▋    | 3402/5922 [1:41:13<1:12:41,  1.73s/it] 57%|█████▋    | 3403/5922 [1:41:15<1:12:05,  1.72s/it] 57%|█████▋    | 3404/5922 [1:41:17<1:19:33,  1.90s/it] 57%|█████▋    | 3405/5922 [1:41:19<1:26:28,  2.06s/it] 58%|█████▊    | 3406/5922 [1:41:21<1:19:50,  1.90s/it] 58%|█████▊    | 3407/5922 [1:41:23<1:20:00,  1.91s/it] 58%|█████▊    | 3408/5922 [1:41:25<1:19:27,  1.90s/it] 58%|█████▊    | 3409/5922 [1:41:27<1:19:31,  1.90s/it] 58%|█████▊    | 3410/5922 [1:41:29<1:19:58,  1.91s/it] 58%|█████▊    | 3411/5922 [1:41:30<1:15:16,  1.80s/it] 58%|█████▊    | 3412/5922 [1:41:32<1:16:49,  1.84s/it] 58%|█████▊    | 3413/5922 [1:41:34<1:11:35,  1.71s/it] 58%|█████▊    | 3414/5922 [1:41:35<1:09:36,  1.67s/it] 58%|█████▊    | 3415/5922 [1:41:37<1:10:25,  1.69s/it] 58%|█████▊    | 3416/5922 [1:41:38<1:08:20,  1.64s/it] 58%|█████▊    | 3417/5922 [1:41:40<1:05:38,  1.57s/it] 58%|█████▊    | 3418/5922 [1:41:41<1:05:59,  1.58s/it] 58%|█████▊    | 3419/5922 [1:41:43<1:05:30,  1.57s/it] 58%|█████▊    | 3420/5922 [1:41:45<1:09:41,  1.67s/it] 58%|█████▊    | 3421/5922 [1:41:46<1:06:03,  1.58s/it] 58%|█████▊    | 3422/5922 [1:41:48<1:03:23,  1.52s/it] 58%|█████▊    | 3423/5922 [1:41:49<1:02:14,  1.49s/it] 58%|█████▊    | 3424/5922 [1:41:50<1:00:45,  1.46s/it] 58%|█████▊    | 3425/5922 [1:41:52<59:54,  1.44s/it]                                                       {'loss': 0.1243, 'grad_norm': 0.40012000787236196, 'learning_rate': 8.31520464954201e-06, 'epoch': 1.74}
 58%|█████▊    | 3425/5922 [1:41:52<59:54,  1.44s/it] 58%|█████▊    | 3426/5922 [1:41:53<59:10,  1.42s/it] 58%|█████▊    | 3427/5922 [1:41:55<58:23,  1.40s/it] 58%|█████▊    | 3428/5922 [1:41:56<1:04:58,  1.56s/it] 58%|█████▊    | 3429/5922 [1:41:58<1:08:58,  1.66s/it] 58%|█████▊    | 3430/5922 [1:42:00<1:12:12,  1.74s/it] 58%|█████▊    | 3431/5922 [1:42:02<1:07:53,  1.64s/it] 58%|█████▊    | 3432/5922 [1:42:04<1:18:21,  1.89s/it] 58%|█████▊    | 3433/5922 [1:42:06<1:14:01,  1.78s/it] 58%|█████▊    | 3434/5922 [1:42:07<1:09:06,  1.67s/it] 58%|█████▊    | 3435/5922 [1:42:08<1:05:31,  1.58s/it] 58%|█████▊    | 3436/5922 [1:42:10<1:09:41,  1.68s/it] 58%|█████▊    | 3437/5922 [1:42:12<1:06:15,  1.60s/it] 58%|█████▊    | 3438/5922 [1:42:13<1:03:25,  1.53s/it] 58%|█████▊    | 3439/5922 [1:42:15<1:07:56,  1.64s/it] 58%|█████▊    | 3440/5922 [1:42:17<1:11:22,  1.73s/it] 58%|█████▊    | 3441/5922 [1:42:19<1:16:04,  1.84s/it] 58%|█████▊    | 3442/5922 [1:42:20<1:10:52,  1.71s/it] 58%|█████▊    | 3443/5922 [1:42:22<1:06:38,  1.61s/it] 58%|█████▊    | 3444/5922 [1:42:25<1:20:41,  1.95s/it] 58%|█████▊    | 3445/5922 [1:42:27<1:20:17,  1.95s/it] 58%|█████▊    | 3446/5922 [1:42:28<1:18:41,  1.91s/it] 58%|█████▊    | 3447/5922 [1:42:30<1:18:09,  1.89s/it] 58%|█████▊    | 3448/5922 [1:42:32<1:11:50,  1.74s/it] 58%|█████▊    | 3449/5922 [1:42:33<1:07:09,  1.63s/it] 58%|█████▊    | 3450/5922 [1:42:35<1:12:42,  1.76s/it]                                                       {'loss': 0.1396, 'grad_norm': 0.3848248962737969, 'learning_rate': 8.191533956602998e-06, 'epoch': 1.75}
 58%|█████▊    | 3450/5922 [1:42:35<1:12:42,  1.76s/it] 58%|█████▊    | 3451/5922 [1:42:37<1:20:25,  1.95s/it] 58%|█████▊    | 3452/5922 [1:42:39<1:14:01,  1.80s/it] 58%|█████▊    | 3453/5922 [1:42:41<1:22:19,  2.00s/it] 58%|█████▊    | 3454/5922 [1:42:43<1:17:22,  1.88s/it] 58%|█████▊    | 3455/5922 [1:42:45<1:24:39,  2.06s/it] 58%|█████▊    | 3456/5922 [1:42:47<1:23:10,  2.02s/it] 58%|█████▊    | 3457/5922 [1:42:49<1:20:06,  1.95s/it] 58%|█████▊    | 3458/5922 [1:42:51<1:13:02,  1.78s/it] 58%|█████▊    | 3459/5922 [1:42:52<1:08:14,  1.66s/it] 58%|█████▊    | 3460/5922 [1:42:53<1:05:23,  1.59s/it] 58%|█████▊    | 3461/5922 [1:42:55<1:09:41,  1.70s/it] 58%|█████▊    | 3462/5922 [1:42:57<1:11:35,  1.75s/it] 58%|█████▊    | 3463/5922 [1:42:59<1:06:56,  1.63s/it] 58%|█████▊    | 3464/5922 [1:43:00<1:10:47,  1.73s/it] 59%|█████▊    | 3465/5922 [1:43:02<1:12:01,  1.76s/it] 59%|█████▊    | 3466/5922 [1:43:04<1:13:45,  1.80s/it] 59%|█████▊    | 3467/5922 [1:43:06<1:15:18,  1.84s/it] 59%|█████▊    | 3468/5922 [1:43:08<1:17:20,  1.89s/it] 59%|█████▊    | 3469/5922 [1:43:10<1:18:13,  1.91s/it] 59%|█████▊    | 3470/5922 [1:43:12<1:13:21,  1.79s/it] 59%|█████▊    | 3471/5922 [1:43:13<1:07:49,  1.66s/it] 59%|█████▊    | 3472/5922 [1:43:15<1:10:50,  1.73s/it] 59%|█████▊    | 3473/5922 [1:43:16<1:06:39,  1.63s/it] 59%|█████▊    | 3474/5922 [1:43:18<1:10:02,  1.72s/it] 59%|█████▊    | 3475/5922 [1:43:20<1:10:37,  1.73s/it]                                                       {'loss': 0.1388, 'grad_norm': 0.31295038879797077, 'learning_rate': 8.068277649715606e-06, 'epoch': 1.76}
 59%|█████▊    | 3475/5922 [1:43:20<1:10:37,  1.73s/it] 59%|█████▊    | 3476/5922 [1:43:21<1:06:31,  1.63s/it] 59%|█████▊    | 3477/5922 [1:43:23<1:09:46,  1.71s/it] 59%|█████▊    | 3478/5922 [1:43:25<1:07:53,  1.67s/it] 59%|█████▊    | 3479/5922 [1:43:27<1:11:07,  1.75s/it] 59%|█████▉    | 3480/5922 [1:43:28<1:08:38,  1.69s/it] 59%|█████▉    | 3481/5922 [1:43:30<1:04:50,  1.59s/it] 59%|█████▉    | 3482/5922 [1:43:31<1:02:29,  1.54s/it] 59%|█████▉    | 3483/5922 [1:43:32<1:00:34,  1.49s/it] 59%|█████▉    | 3484/5922 [1:43:35<1:12:08,  1.78s/it] 59%|█████▉    | 3485/5922 [1:43:37<1:20:20,  1.98s/it] 59%|█████▉    | 3486/5922 [1:43:39<1:17:29,  1.91s/it] 59%|█████▉    | 3487/5922 [1:43:41<1:15:48,  1.87s/it] 59%|█████▉    | 3488/5922 [1:43:42<1:09:42,  1.72s/it] 59%|█████▉    | 3489/5922 [1:43:44<1:13:09,  1.80s/it] 59%|█████▉    | 3490/5922 [1:43:47<1:19:29,  1.96s/it] 59%|█████▉    | 3491/5922 [1:43:48<1:18:50,  1.95s/it] 59%|█████▉    | 3492/5922 [1:43:50<1:18:33,  1.94s/it] 59%|█████▉    | 3493/5922 [1:43:52<1:13:42,  1.82s/it] 59%|█████▉    | 3494/5922 [1:43:54<1:13:15,  1.81s/it] 59%|█████▉    | 3495/5922 [1:43:55<1:09:20,  1.71s/it] 59%|█████▉    | 3496/5922 [1:43:57<1:12:24,  1.79s/it] 59%|█████▉    | 3497/5922 [1:43:59<1:14:07,  1.83s/it] 59%|█████▉    | 3498/5922 [1:44:01<1:12:13,  1.79s/it] 59%|█████▉    | 3499/5922 [1:44:03<1:19:30,  1.97s/it] 59%|█████▉    | 3500/5922 [1:44:05<1:12:21,  1.79s/it]                                                       {'loss': 0.1342, 'grad_norm': 0.38244720308461566, 'learning_rate': 7.945457854262397e-06, 'epoch': 1.77}
 59%|█████▉    | 3500/5922 [1:44:05<1:12:21,  1.79s/it][INFO|trainer.py:3993] 2025-08-30 15:32:56,324 >> Saving model checkpoint to saves/qwen3-1.7B/lora/sft/checkpoint-3500
[INFO|configuration_utils.py:696] 2025-08-30 15:32:56,336 >> loading configuration file /home/qianwenhao/LLM/Qwen3-1.7B/config.json
[INFO|configuration_utils.py:770] 2025-08-30 15:32:56,337 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "max_position_embeddings": 40960,
  "max_window_layers": 28,
  "model_type": "qwen3",
  "num_attention_heads": 16,
  "num_hidden_layers": 28,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|tokenization_utils_base.py:2356] 2025-08-30 15:32:56,353 >> chat template saved in saves/qwen3-1.7B/lora/sft/checkpoint-3500/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-08-30 15:32:56,353 >> tokenizer config file saved in saves/qwen3-1.7B/lora/sft/checkpoint-3500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-08-30 15:32:56,353 >> Special tokens file saved in saves/qwen3-1.7B/lora/sft/checkpoint-3500/special_tokens_map.json
[2025-08-30 15:32:56,515] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step3499 is about to be saved!
[2025-08-30 15:32:56,524] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: saves/qwen3-1.7B/lora/sft/checkpoint-3500/global_step3499/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-08-30 15:32:56,524] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-3500/global_step3499/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-08-30 15:32:56,529] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-3500/global_step3499/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-08-30 15:32:56,530] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-3500/global_step3499/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-08-30 15:32:56,542] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-3500/global_step3499/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-08-30 15:32:56,542] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved saves/qwen3-1.7B/lora/sft/checkpoint-3500/global_step3499/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-08-30 15:32:56,550] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3499 is ready now!
 59%|█████▉    | 3501/5922 [1:44:08<1:36:07,  2.38s/it] 59%|█████▉    | 3502/5922 [1:44:10<1:26:01,  2.13s/it] 59%|█████▉    | 3503/5922 [1:44:11<1:17:50,  1.93s/it] 59%|█████▉    | 3504/5922 [1:44:13<1:19:06,  1.96s/it] 59%|█████▉    | 3505/5922 [1:44:15<1:18:01,  1.94s/it] 59%|█████▉    | 3506/5922 [1:44:17<1:11:58,  1.79s/it] 59%|█████▉    | 3507/5922 [1:44:18<1:09:08,  1.72s/it] 59%|█████▉    | 3508/5922 [1:44:20<1:04:59,  1.62s/it] 59%|█████▉    | 3509/5922 [1:44:21<1:03:17,  1.57s/it] 59%|█████▉    | 3510/5922 [1:44:23<1:07:43,  1.68s/it] 59%|█████▉    | 3511/5922 [1:44:26<1:17:02,  1.92s/it] 59%|█████▉    | 3512/5922 [1:44:28<1:23:47,  2.09s/it] 59%|█████▉    | 3513/5922 [1:44:30<1:21:56,  2.04s/it] 59%|█████▉    | 3514/5922 [1:44:32<1:17:42,  1.94s/it] 59%|█████▉    | 3515/5922 [1:44:33<1:11:10,  1.77s/it] 59%|█████▉    | 3516/5922 [1:44:35<1:12:59,  1.82s/it] 59%|█████▉    | 3517/5922 [1:44:37<1:14:28,  1.86s/it] 59%|█████▉    | 3518/5922 [1:44:39<1:13:36,  1.84s/it] 59%|█████▉    | 3519/5922 [1:44:40<1:08:09,  1.70s/it] 59%|█████▉    | 3520/5922 [1:44:42<1:10:14,  1.75s/it] 59%|█████▉    | 3521/5922 [1:44:43<1:06:21,  1.66s/it] 59%|█████▉    | 3522/5922 [1:44:46<1:15:56,  1.90s/it] 59%|█████▉    | 3523/5922 [1:44:47<1:09:45,  1.74s/it] 60%|█████▉    | 3524/5922 [1:44:49<1:12:04,  1.80s/it] 60%|█████▉    | 3525/5922 [1:44:51<1:09:46,  1.75s/it]                                                       {'loss': 0.1412, 'grad_norm': 0.46202057723065904, 'learning_rate': 7.82309661726904e-06, 'epoch': 1.79}
 60%|█████▉    | 3525/5922 [1:44:51<1:09:46,  1.75s/it] 60%|█████▉    | 3526/5922 [1:44:53<1:11:55,  1.80s/it] 60%|█████▉    | 3527/5922 [1:44:54<1:08:29,  1.72s/it] 60%|█████▉    | 3528/5922 [1:44:56<1:09:04,  1.73s/it] 60%|█████▉    | 3529/5922 [1:44:58<1:11:12,  1.79s/it] 60%|█████▉    | 3530/5922 [1:44:59<1:06:18,  1.66s/it] 60%|█████▉    | 3531/5922 [1:45:01<1:03:32,  1.59s/it] 60%|█████▉    | 3532/5922 [1:45:02<1:01:08,  1.54s/it] 60%|█████▉    | 3533/5922 [1:45:03<59:07,  1.48s/it]   60%|█████▉    | 3534/5922 [1:45:05<1:04:25,  1.62s/it] 60%|█████▉    | 3535/5922 [1:45:07<1:08:00,  1.71s/it] 60%|█████▉    | 3536/5922 [1:45:09<1:06:24,  1.67s/it] 60%|█████▉    | 3537/5922 [1:45:10<1:02:44,  1.58s/it] 60%|█████▉    | 3538/5922 [1:45:12<1:00:38,  1.53s/it] 60%|█████▉    | 3539/5922 [1:45:14<1:04:33,  1.63s/it] 60%|█████▉    | 3540/5922 [1:45:15<1:01:48,  1.56s/it] 60%|█████▉    | 3541/5922 [1:45:16<1:00:38,  1.53s/it] 60%|█████▉    | 3542/5922 [1:45:18<1:00:14,  1.52s/it] 60%|█████▉    | 3543/5922 [1:45:20<1:11:25,  1.80s/it] 60%|█████▉    | 3544/5922 [1:45:22<1:13:06,  1.84s/it] 60%|█████▉    | 3545/5922 [1:45:24<1:07:55,  1.71s/it] 60%|█████▉    | 3546/5922 [1:45:25<1:04:03,  1.62s/it] 60%|█████▉    | 3547/5922 [1:45:27<1:07:39,  1.71s/it] 60%|█████▉    | 3548/5922 [1:45:29<1:06:39,  1.68s/it] 60%|█████▉    | 3549/5922 [1:45:31<1:14:14,  1.88s/it] 60%|█████▉    | 3550/5922 [1:45:32<1:09:48,  1.77s/it]                                                       {'loss': 0.1346, 'grad_norm': 0.3889491157771602, 'learning_rate': 7.70121590344669e-06, 'epoch': 1.8}
 60%|█████▉    | 3550/5922 [1:45:32<1:09:48,  1.77s/it] 60%|█████▉    | 3551/5922 [1:45:34<1:05:18,  1.65s/it] 60%|█████▉    | 3552/5922 [1:45:35<1:04:35,  1.64s/it] 60%|█████▉    | 3553/5922 [1:45:37<1:08:13,  1.73s/it] 60%|██████    | 3554/5922 [1:45:40<1:16:08,  1.93s/it] 60%|██████    | 3555/5922 [1:45:42<1:18:10,  1.98s/it] 60%|██████    | 3556/5922 [1:45:44<1:24:04,  2.13s/it] 60%|██████    | 3557/5922 [1:45:47<1:28:21,  2.24s/it] 60%|██████    | 3558/5922 [1:45:48<1:20:00,  2.03s/it] 60%|██████    | 3559/5922 [1:45:50<1:18:39,  2.00s/it] 60%|██████    | 3560/5922 [1:45:52<1:11:33,  1.82s/it] 60%|██████    | 3561/5922 [1:45:53<1:06:35,  1.69s/it] 60%|██████    | 3562/5922 [1:45:55<1:03:42,  1.62s/it] 60%|██████    | 3563/5922 [1:45:56<1:00:43,  1.54s/it] 60%|██████    | 3564/5922 [1:45:58<1:05:13,  1.66s/it] 60%|██████    | 3565/5922 [1:46:00<1:08:36,  1.75s/it] 60%|██████    | 3566/5922 [1:46:01<1:04:07,  1.63s/it] 60%|██████    | 3567/5922 [1:46:03<1:05:40,  1.67s/it] 60%|██████    | 3568/5922 [1:46:05<1:07:31,  1.72s/it] 60%|██████    | 3569/5922 [1:46:07<1:12:00,  1.84s/it] 60%|██████    | 3570/5922 [1:46:08<1:08:22,  1.74s/it] 60%|██████    | 3571/5922 [1:46:10<1:10:14,  1.79s/it] 60%|██████    | 3572/5922 [1:46:12<1:10:13,  1.79s/it] 60%|██████    | 3573/5922 [1:46:14<1:10:41,  1.81s/it] 60%|██████    | 3574/5922 [1:46:15<1:05:23,  1.67s/it] 60%|██████    | 3575/5922 [1:46:17<1:08:22,  1.75s/it]                                                       {'loss': 0.1428, 'grad_norm': 0.44375109677044156, 'learning_rate': 7.579837591249191e-06, 'epoch': 1.81}
 60%|██████    | 3575/5922 [1:46:17<1:08:22,  1.75s/it] 60%|██████    | 3576/5922 [1:46:19<1:10:09,  1.79s/it] 60%|██████    | 3577/5922 [1:46:21<1:11:34,  1.83s/it] 60%|██████    | 3578/5922 [1:46:23<1:08:44,  1.76s/it] 60%|██████    | 3579/5922 [1:46:25<1:11:05,  1.82s/it] 60%|██████    | 3580/5922 [1:46:26<1:05:47,  1.69s/it] 60%|██████    | 3581/5922 [1:46:28<1:12:54,  1.87s/it] 60%|██████    | 3582/5922 [1:46:30<1:15:15,  1.93s/it] 61%|██████    | 3583/5922 [1:46:32<1:14:14,  1.90s/it] 61%|██████    | 3584/5922 [1:46:34<1:08:06,  1.75s/it] 61%|██████    | 3585/5922 [1:46:35<1:09:33,  1.79s/it] 61%|██████    | 3586/5922 [1:46:38<1:17:26,  1.99s/it] 61%|██████    | 3587/5922 [1:46:40<1:22:22,  2.12s/it] 61%|██████    | 3588/5922 [1:46:42<1:14:18,  1.91s/it] 61%|██████    | 3589/5922 [1:46:43<1:08:15,  1.76s/it] 61%|██████    | 3590/5922 [1:46:45<1:05:13,  1.68s/it] 61%|██████    | 3591/5922 [1:46:46<1:06:16,  1.71s/it] 61%|██████    | 3592/5922 [1:46:48<1:02:48,  1.62s/it] 61%|██████    | 3593/5922 [1:46:49<1:01:22,  1.58s/it] 61%|██████    | 3594/5922 [1:46:51<1:05:30,  1.69s/it] 61%|██████    | 3595/5922 [1:46:53<1:09:30,  1.79s/it] 61%|██████    | 3596/5922 [1:46:55<1:04:57,  1.68s/it] 61%|██████    | 3597/5922 [1:46:56<1:01:54,  1.60s/it] 61%|██████    | 3598/5922 [1:46:58<1:06:55,  1.73s/it] 61%|██████    | 3599/5922 [1:47:00<1:07:23,  1.74s/it] 61%|██████    | 3600/5922 [1:47:01<1:04:30,  1.67s/it]                                                       {'loss': 0.1284, 'grad_norm': 0.3426192702282173, 'learning_rate': 7.4589834689457206e-06, 'epoch': 1.82}
 61%|██████    | 3600/5922 [1:47:01<1:04:30,  1.67s/it] 61%|██████    | 3601/5922 [1:47:03<1:02:21,  1.61s/it] 61%|██████    | 3602/5922 [1:47:04<59:46,  1.55s/it]   61%|██████    | 3603/5922 [1:47:06<59:38,  1.54s/it] 61%|██████    | 3604/5922 [1:47:07<58:15,  1.51s/it] 61%|██████    | 3605/5922 [1:47:09<1:03:20,  1.64s/it] 61%|██████    | 3606/5922 [1:47:11<1:06:15,  1.72s/it] 61%|██████    | 3607/5922 [1:47:14<1:15:01,  1.94s/it] 61%|██████    | 3608/5922 [1:47:15<1:08:15,  1.77s/it] 61%|██████    | 3609/5922 [1:47:17<1:05:37,  1.70s/it] 61%|██████    | 3610/5922 [1:47:18<1:01:59,  1.61s/it] 61%|██████    | 3611/5922 [1:47:20<1:02:29,  1.62s/it] 61%|██████    | 3612/5922 [1:47:21<1:02:15,  1.62s/it] 61%|██████    | 3613/5922 [1:47:23<1:05:40,  1.71s/it] 61%|██████    | 3614/5922 [1:47:24<1:02:09,  1.62s/it] 61%|██████    | 3615/5922 [1:47:26<1:05:46,  1.71s/it] 61%|██████    | 3616/5922 [1:47:28<1:01:43,  1.61s/it] 61%|██████    | 3617/5922 [1:47:29<58:59,  1.54s/it]   61%|██████    | 3618/5922 [1:47:31<1:03:33,  1.66s/it] 61%|██████    | 3619/5922 [1:47:33<1:01:06,  1.59s/it] 61%|██████    | 3620/5922 [1:47:34<58:48,  1.53s/it]   61%|██████    | 3621/5922 [1:47:35<57:29,  1.50s/it] 61%|██████    | 3622/5922 [1:47:38<1:08:33,  1.79s/it] 61%|██████    | 3623/5922 [1:47:40<1:08:49,  1.80s/it] 61%|██████    | 3624/5922 [1:47:41<1:06:04,  1.73s/it] 61%|██████    | 3625/5922 [1:47:44<1:13:11,  1.91s/it]                                                       {'loss': 0.1288, 'grad_norm': 0.4344490210237586, 'learning_rate': 7.338675230709643e-06, 'epoch': 1.84}
 61%|██████    | 3625/5922 [1:47:44<1:13:11,  1.91s/it] 61%|██████    | 3626/5922 [1:47:45<1:13:22,  1.92s/it] 61%|██████    | 3627/5922 [1:47:47<1:12:39,  1.90s/it] 61%|██████▏   | 3628/5922 [1:47:49<1:11:25,  1.87s/it] 61%|██████▏   | 3629/5922 [1:47:52<1:17:58,  2.04s/it] 61%|██████▏   | 3630/5922 [1:47:54<1:19:58,  2.09s/it] 61%|██████▏   | 3631/5922 [1:47:55<1:11:21,  1.87s/it] 61%|██████▏   | 3632/5922 [1:47:56<1:05:40,  1.72s/it] 61%|██████▏   | 3633/5922 [1:47:59<1:13:05,  1.92s/it] 61%|██████▏   | 3634/5922 [1:48:01<1:17:43,  2.04s/it] 61%|██████▏   | 3635/5922 [1:48:03<1:16:23,  2.00s/it] 61%|██████▏   | 3636/5922 [1:48:06<1:21:34,  2.14s/it] 61%|██████▏   | 3637/5922 [1:48:07<1:13:49,  1.94s/it] 61%|██████▏   | 3638/5922 [1:48:09<1:13:53,  1.94s/it] 61%|██████▏   | 3639/5922 [1:48:11<1:13:00,  1.92s/it] 61%|██████▏   | 3640/5922 [1:48:13<1:12:54,  1.92s/it] 61%|██████▏   | 3641/5922 [1:48:15<1:12:51,  1.92s/it] 61%|██████▏   | 3642/5922 [1:48:17<1:12:56,  1.92s/it] 62%|██████▏   | 3643/5922 [1:48:18<1:06:55,  1.76s/it] 62%|██████▏   | 3644/5922 [1:48:19<1:02:31,  1.65s/it] 62%|██████▏   | 3645/5922 [1:48:21<1:04:37,  1.70s/it] 62%|██████▏   | 3646/5922 [1:48:23<1:09:10,  1.82s/it] 62%|██████▏   | 3647/5922 [1:48:25<1:10:15,  1.85s/it] 62%|██████▏   | 3648/5922 [1:48:28<1:16:55,  2.03s/it] 62%|██████▏   | 3649/5922 [1:48:30<1:15:20,  1.99s/it] 62%|██████▏   | 3650/5922 [1:48:31<1:08:37,  1.81s/it]                                                       {'loss': 0.1393, 'grad_norm': 0.5785677492749968, 'learning_rate': 7.218934472724268e-06, 'epoch': 1.85}
 62%|██████▏   | 3650/5922 [1:48:31<1:08:37,  1.81s/it] 62%|██████▏   | 3651/5922 [1:48:32<1:03:41,  1.68s/it] 62%|██████▏   | 3652/5922 [1:48:34<1:06:34,  1.76s/it] 62%|██████▏   | 3653/5922 [1:48:36<1:09:47,  1.85s/it] 62%|██████▏   | 3654/5922 [1:48:38<1:04:35,  1.71s/it] 62%|██████▏   | 3655/5922 [1:48:40<1:05:49,  1.74s/it] 62%|██████▏   | 3656/5922 [1:48:42<1:09:27,  1.84s/it] 62%|██████▏   | 3657/5922 [1:48:44<1:10:25,  1.87s/it] 62%|██████▏   | 3658/5922 [1:48:46<1:14:56,  1.99s/it] 62%|██████▏   | 3659/5922 [1:48:47<1:07:57,  1.80s/it] 62%|██████▏   | 3660/5922 [1:48:49<1:03:12,  1.68s/it] 62%|██████▏   | 3661/5922 [1:48:51<1:06:41,  1.77s/it] 62%|██████▏   | 3662/5922 [1:48:53<1:12:19,  1.92s/it] 62%|██████▏   | 3663/5922 [1:48:55<1:12:25,  1.92s/it] 62%|██████▏   | 3664/5922 [1:48:56<1:06:34,  1.77s/it] 62%|██████▏   | 3665/5922 [1:48:58<1:08:02,  1.81s/it] 62%|██████▏   | 3666/5922 [1:48:59<1:02:47,  1.67s/it] 62%|██████▏   | 3667/5922 [1:49:01<1:05:15,  1.74s/it] 62%|██████▏   | 3668/5922 [1:49:03<1:05:37,  1.75s/it] 62%|██████▏   | 3669/5922 [1:49:04<1:01:24,  1.64s/it] 62%|██████▏   | 3670/5922 [1:49:06<1:02:16,  1.66s/it] 62%|██████▏   | 3671/5922 [1:49:08<1:07:38,  1.80s/it] 62%|██████▏   | 3672/5922 [1:49:10<1:09:01,  1.84s/it] 62%|██████▏   | 3673/5922 [1:49:12<1:10:54,  1.89s/it] 62%|██████▏   | 3674/5922 [1:49:15<1:17:15,  2.06s/it] 62%|██████▏   | 3675/5922 [1:49:17<1:15:55,  2.03s/it]                                                       {'loss': 0.1382, 'grad_norm': 0.424092097530812, 'learning_rate': 7.099782689306156e-06, 'epoch': 1.86}
 62%|██████▏   | 3675/5922 [1:49:17<1:15:55,  2.03s/it] 62%|██████▏   | 3676/5922 [1:49:19<1:14:57,  2.00s/it] 62%|██████▏   | 3677/5922 [1:49:20<1:07:56,  1.82s/it] 62%|██████▏   | 3678/5922 [1:49:22<1:10:34,  1.89s/it] 62%|██████▏   | 3679/5922 [1:49:23<1:04:58,  1.74s/it] 62%|██████▏   | 3680/5922 [1:49:25<1:01:09,  1.64s/it] 62%|██████▏   | 3681/5922 [1:49:27<1:06:22,  1.78s/it] 62%|██████▏   | 3682/5922 [1:49:29<1:09:02,  1.85s/it] 62%|██████▏   | 3683/5922 [1:49:30<1:03:47,  1.71s/it] 62%|██████▏   | 3684/5922 [1:49:32<1:00:29,  1.62s/it] 62%|██████▏   | 3685/5922 [1:49:34<1:04:07,  1.72s/it] 62%|██████▏   | 3686/5922 [1:49:35<1:01:44,  1.66s/it] 62%|██████▏   | 3687/5922 [1:49:37<58:35,  1.57s/it]   62%|██████▏   | 3688/5922 [1:49:39<1:08:19,  1.83s/it] 62%|██████▏   | 3689/5922 [1:49:40<1:03:38,  1.71s/it] 62%|██████▏   | 3690/5922 [1:49:42<1:00:23,  1.62s/it] 62%|██████▏   | 3691/5922 [1:49:44<1:03:40,  1.71s/it] 62%|██████▏   | 3692/5922 [1:49:46<1:08:06,  1.83s/it] 62%|██████▏   | 3693/5922 [1:49:48<1:09:13,  1.86s/it] 62%|██████▏   | 3694/5922 [1:49:50<1:16:24,  2.06s/it] 62%|██████▏   | 3695/5922 [1:49:52<1:14:12,  2.00s/it] 62%|██████▏   | 3696/5922 [1:49:54<1:14:15,  2.00s/it] 62%|██████▏   | 3697/5922 [1:49:56<1:11:25,  1.93s/it] 62%|██████▏   | 3698/5922 [1:49:58<1:11:16,  1.92s/it] 62%|██████▏   | 3699/5922 [1:50:00<1:11:10,  1.92s/it] 62%|██████▏   | 3700/5922 [1:50:02<1:15:36,  2.04s/it]                                                       {'loss': 0.1422, 'grad_norm': 0.42918385512551194, 'learning_rate': 6.981241269046764e-06, 'epoch': 1.87}
 62%|██████▏   | 3700/5922 [1:50:02<1:15:36,  2.04s/it] 62%|██████▏   | 3701/5922 [1:50:03<1:08:05,  1.84s/it] 63%|██████▎   | 3702/5922 [1:50:05<1:03:00,  1.70s/it] 63%|██████▎   | 3703/5922 [1:50:06<59:39,  1.61s/it]   63%|██████▎   | 3704/5922 [1:50:09<1:09:10,  1.87s/it] 63%|██████▎   | 3705/5922 [1:50:10<1:04:59,  1.76s/it] 63%|██████▎   | 3706/5922 [1:50:12<1:07:19,  1.82s/it] 63%|██████▎   | 3707/5922 [1:50:14<1:06:56,  1.81s/it] 63%|██████▎   | 3708/5922 [1:50:15<1:02:34,  1.70s/it] 63%|██████▎   | 3709/5922 [1:50:18<1:07:10,  1.82s/it] 63%|██████▎   | 3710/5922 [1:50:19<1:08:15,  1.85s/it] 63%|██████▎   | 3711/5922 [1:50:21<1:08:51,  1.87s/it] 63%|██████▎   | 3712/5922 [1:50:23<1:08:47,  1.87s/it] 63%|██████▎   | 3713/5922 [1:50:25<1:08:14,  1.85s/it] 63%|██████▎   | 3714/5922 [1:50:26<1:03:13,  1.72s/it] 63%|██████▎   | 3715/5922 [1:50:28<1:04:26,  1.75s/it] 63%|██████▎   | 3716/5922 [1:50:30<1:07:20,  1.83s/it] 63%|██████▎   | 3717/5922 [1:50:33<1:13:02,  1.99s/it] 63%|██████▎   | 3718/5922 [1:50:34<1:10:52,  1.93s/it] 63%|██████▎   | 3719/5922 [1:50:36<1:11:26,  1.95s/it] 63%|██████▎   | 3720/5922 [1:50:39<1:14:23,  2.03s/it] 63%|██████▎   | 3721/5922 [1:50:40<1:07:48,  1.85s/it] 63%|██████▎   | 3722/5922 [1:50:41<1:02:57,  1.72s/it] 63%|██████▎   | 3723/5922 [1:50:43<1:05:28,  1.79s/it] 63%|██████▎   | 3724/5922 [1:50:45<1:01:08,  1.67s/it] 63%|██████▎   | 3725/5922 [1:50:46<58:43,  1.60s/it]                                                       {'loss': 0.1372, 'grad_norm': 0.4775303366993633, 'learning_rate': 6.86333149097301e-06, 'epoch': 1.89}
 63%|██████▎   | 3725/5922 [1:50:46<58:43,  1.60s/it] 63%|██████▎   | 3726/5922 [1:50:48<57:02,  1.56s/it] 63%|██████▎   | 3727/5922 [1:50:50<1:01:05,  1.67s/it] 63%|██████▎   | 3728/5922 [1:50:52<1:04:13,  1.76s/it] 63%|██████▎   | 3729/5922 [1:50:54<1:06:07,  1.81s/it] 63%|██████▎   | 3730/5922 [1:50:55<1:01:20,  1.68s/it] 63%|██████▎   | 3731/5922 [1:50:57<1:04:06,  1.76s/it] 63%|██████▎   | 3732/5922 [1:50:58<1:00:34,  1.66s/it] 63%|██████▎   | 3733/5922 [1:51:00<1:03:09,  1.73s/it] 63%|██████▎   | 3734/5922 [1:51:02<1:03:37,  1.74s/it] 63%|██████▎   | 3735/5922 [1:51:04<1:05:22,  1.79s/it] 63%|██████▎   | 3736/5922 [1:51:06<1:08:22,  1.88s/it] 63%|██████▎   | 3737/5922 [1:51:08<1:04:58,  1.78s/it] 63%|██████▎   | 3738/5922 [1:51:10<1:07:07,  1.84s/it] 63%|██████▎   | 3739/5922 [1:51:11<1:08:12,  1.87s/it] 63%|██████▎   | 3740/5922 [1:51:13<1:05:08,  1.79s/it] 63%|██████▎   | 3741/5922 [1:51:14<1:00:38,  1.67s/it] 63%|██████▎   | 3742/5922 [1:51:16<57:28,  1.58s/it]   63%|██████▎   | 3743/5922 [1:51:18<1:01:16,  1.69s/it] 63%|██████▎   | 3744/5922 [1:51:19<57:33,  1.59s/it]   63%|██████▎   | 3745/5922 [1:51:21<1:01:56,  1.71s/it] 63%|██████▎   | 3746/5922 [1:51:23<1:04:13,  1.77s/it] 63%|██████▎   | 3747/5922 [1:51:25<1:10:15,  1.94s/it] 63%|██████▎   | 3748/5922 [1:51:27<1:12:16,  1.99s/it] 63%|██████▎   | 3749/5922 [1:51:29<1:05:22,  1.81s/it] 63%|██████▎   | 3750/5922 [1:51:30<1:03:40,  1.76s/it]                                                       {'loss': 0.1389, 'grad_norm': 0.4020732310795316, 'learning_rate': 6.746074520727563e-06, 'epoch': 1.9}
 63%|██████▎   | 3750/5922 [1:51:30<1:03:40,  1.76s/it] 63%|██████▎   | 3751/5922 [1:51:32<1:04:18,  1.78s/it] 63%|██████▎   | 3752/5922 [1:51:34<1:02:03,  1.72s/it] 63%|██████▎   | 3753/5922 [1:51:35<58:19,  1.61s/it]   63%|██████▎   | 3754/5922 [1:51:37<1:01:38,  1.71s/it] 63%|██████▎   | 3755/5922 [1:51:39<58:12,  1.61s/it]   63%|██████▎   | 3756/5922 [1:51:41<1:07:27,  1.87s/it] 63%|██████▎   | 3757/5922 [1:51:43<1:12:58,  2.02s/it] 63%|██████▎   | 3758/5922 [1:51:45<1:07:09,  1.86s/it] 63%|██████▎   | 3759/5922 [1:51:47<1:07:54,  1.88s/it] 63%|██████▎   | 3760/5922 [1:51:48<1:02:24,  1.73s/it] 64%|██████▎   | 3761/5922 [1:51:50<58:44,  1.63s/it]   64%|██████▎   | 3762/5922 [1:51:52<1:02:03,  1.72s/it] 64%|██████▎   | 3763/5922 [1:51:54<1:05:08,  1.81s/it] 64%|██████▎   | 3764/5922 [1:51:55<1:00:12,  1.67s/it] 64%|██████▎   | 3765/5922 [1:51:56<57:13,  1.59s/it]   64%|██████▎   | 3766/5922 [1:51:58<1:01:14,  1.70s/it] 64%|██████▎   | 3767/5922 [1:52:00<57:37,  1.60s/it]   64%|██████▎   | 3768/5922 [1:52:02<1:01:13,  1.71s/it] 64%|██████▎   | 3769/5922 [1:52:04<1:04:12,  1.79s/it] 64%|██████▎   | 3770/5922 [1:52:05<1:05:08,  1.82s/it] 64%|██████▎   | 3771/5922 [1:52:07<1:00:27,  1.69s/it] 64%|██████▎   | 3772/5922 [1:52:09<1:03:06,  1.76s/it] 64%|██████▎   | 3773/5922 [1:52:10<1:00:59,  1.70s/it] 64%|██████▎   | 3774/5922 [1:52:12<58:24,  1.63s/it]   64%|██████▎   | 3775/5922 [1:52:13<56:08,  1.57s/it]                                                     {'loss': 0.142, 'grad_norm': 0.3774218465520159, 'learning_rate': 6.629491406769446e-06, 'epoch': 1.91}
 64%|██████▎   | 3775/5922 [1:52:13<56:08,  1.57s/it] 64%|██████▍   | 3776/5922 [1:52:15<1:00:06,  1.68s/it] 64%|██████▍   | 3777/5922 [1:52:18<1:07:11,  1.88s/it] 64%|██████▍   | 3778/5922 [1:52:20<1:10:10,  1.96s/it] 64%|██████▍   | 3779/5922 [1:52:21<1:07:58,  1.90s/it] 64%|██████▍   | 3780/5922 [1:52:23<1:02:38,  1.75s/it] 64%|██████▍   | 3781/5922 [1:52:25<1:04:41,  1.81s/it] 64%|██████▍   | 3782/5922 [1:52:26<1:00:09,  1.69s/it] 64%|██████▍   | 3783/5922 [1:52:28<56:51,  1.59s/it]   64%|██████▍   | 3784/5922 [1:52:29<55:12,  1.55s/it] 64%|██████▍   | 3785/5922 [1:52:30<53:08,  1.49s/it] 64%|██████▍   | 3786/5922 [1:52:32<53:28,  1.50s/it] 64%|██████▍   | 3787/5922 [1:52:33<51:52,  1.46s/it] 64%|██████▍   | 3788/5922 [1:52:35<50:55,  1.43s/it] 64%|██████▍   | 3789/5922 [1:52:37<58:32,  1.65s/it] 64%|██████▍   | 3790/5922 [1:52:39<1:06:27,  1.87s/it] 64%|██████▍   | 3791/5922 [1:52:41<1:07:23,  1.90s/it] 64%|██████▍   | 3792/5922 [1:52:43<1:04:19,  1.81s/it] 64%|██████▍   | 3793/5922 [1:52:45<1:05:34,  1.85s/it] 64%|██████▍   | 3794/5922 [1:52:46<1:01:54,  1.75s/it] 64%|██████▍   | 3795/5922 [1:52:48<1:02:09,  1.75s/it] 64%|██████▍   | 3796/5922 [1:52:49<58:09,  1.64s/it]   64%|██████▍   | 3797/5922 [1:52:51<1:01:31,  1.74s/it] 64%|██████▍   | 3798/5922 [1:52:53<1:02:34,  1.77s/it] 64%|██████▍   | 3799/5922 [1:52:55<1:01:12,  1.73s/it] 64%|██████▍   | 3800/5922 [1:52:57<1:08:19,  1.93s/it]                                                       {'loss': 0.1365, 'grad_norm': 0.3943582086998081, 'learning_rate': 6.513603076595697e-06, 'epoch': 1.93}
 64%|██████▍   | 3800/5922 [1:52:57<1:08:19,  1.93s/it] 64%|██████▍   | 3801/5922 [1:52:59<1:07:53,  1.92s/it] 64%|██████▍   | 3802/5922 [1:53:01<1:03:48,  1.81s/it] 64%|██████▍   | 3803/5922 [1:53:03<1:05:26,  1.85s/it] 64%|██████▍   | 3804/5922 [1:53:04<1:00:12,  1.71s/it] 64%|██████▍   | 3805/5922 [1:53:06<1:02:09,  1.76s/it] 64%|██████▍   | 3806/5922 [1:53:07<57:58,  1.64s/it]   64%|██████▍   | 3807/5922 [1:53:09<55:33,  1.58s/it] 64%|██████▍   | 3808/5922 [1:53:11<1:01:14,  1.74s/it] 64%|██████▍   | 3809/5922 [1:53:13<1:08:52,  1.96s/it] 64%|██████▍   | 3810/5922 [1:53:15<1:08:08,  1.94s/it] 64%|██████▍   | 3811/5922 [1:53:17<1:07:51,  1.93s/it] 64%|██████▍   | 3812/5922 [1:53:19<1:07:45,  1.93s/it] 64%|██████▍   | 3813/5922 [1:53:21<1:06:18,  1.89s/it] 64%|██████▍   | 3814/5922 [1:53:22<1:00:56,  1.73s/it] 64%|██████▍   | 3815/5922 [1:53:24<1:05:12,  1.86s/it] 64%|██████▍   | 3816/5922 [1:53:26<1:00:23,  1.72s/it] 64%|██████▍   | 3817/5922 [1:53:28<1:04:41,  1.84s/it] 64%|██████▍   | 3818/5922 [1:53:29<1:00:31,  1.73s/it] 64%|██████▍   | 3819/5922 [1:53:31<58:09,  1.66s/it]   65%|██████▍   | 3820/5922 [1:53:33<1:00:54,  1.74s/it] 65%|██████▍   | 3821/5922 [1:53:34<57:01,  1.63s/it]   65%|██████▍   | 3822/5922 [1:53:36<56:08,  1.60s/it] 65%|██████▍   | 3823/5922 [1:53:37<55:30,  1.59s/it] 65%|██████▍   | 3824/5922 [1:53:39<58:50,  1.68s/it] 65%|██████▍   | 3825/5922 [1:53:40<55:36,  1.59s/it]                                                     {'loss': 0.1354, 'grad_norm': 0.4077906359023342, 'learning_rate': 6.3984303329847266e-06, 'epoch': 1.94}
 65%|██████▍   | 3825/5922 [1:53:40<55:36,  1.59s/it] 65%|██████▍   | 3826/5922 [1:53:42<58:13,  1.67s/it] 65%|██████▍   | 3827/5922 [1:53:44<55:06,  1.58s/it] 65%|██████▍   | 3828/5922 [1:53:45<54:47,  1.57s/it] 65%|██████▍   | 3829/5922 [1:53:47<1:00:21,  1.73s/it] 65%|██████▍   | 3830/5922 [1:53:49<56:27,  1.62s/it]   65%|██████▍   | 3831/5922 [1:53:51<1:03:08,  1.81s/it] 65%|██████▍   | 3832/5922 [1:53:52<59:54,  1.72s/it]   65%|██████▍   | 3833/5922 [1:53:54<1:01:58,  1.78s/it] 65%|██████▍   | 3834/5922 [1:53:56<1:05:51,  1.89s/it] 65%|██████▍   | 3835/5922 [1:53:59<1:10:19,  2.02s/it] 65%|██████▍   | 3836/5922 [1:54:00<1:04:20,  1.85s/it] 65%|██████▍   | 3837/5922 [1:54:02<1:03:43,  1.83s/it] 65%|██████▍   | 3838/5922 [1:54:04<1:03:34,  1.83s/it] 65%|██████▍   | 3839/5922 [1:54:06<1:10:30,  2.03s/it] 65%|██████▍   | 3840/5922 [1:54:08<1:03:50,  1.84s/it] 65%|██████▍   | 3841/5922 [1:54:10<1:03:59,  1.85s/it] 65%|██████▍   | 3842/5922 [1:54:11<59:23,  1.71s/it]   65%|██████▍   | 3843/5922 [1:54:13<1:00:58,  1.76s/it] 65%|██████▍   | 3844/5922 [1:54:15<1:08:16,  1.97s/it] 65%|██████▍   | 3845/5922 [1:54:17<1:06:12,  1.91s/it] 65%|██████▍   | 3846/5922 [1:54:18<1:00:26,  1.75s/it] 65%|██████▍   | 3847/5922 [1:54:20<1:02:26,  1.81s/it] 65%|██████▍   | 3848/5922 [1:54:23<1:05:51,  1.91s/it] 65%|██████▍   | 3849/5922 [1:54:24<1:05:59,  1.91s/it] 65%|██████▌   | 3850/5922 [1:54:26<1:01:04,  1.77s/it]                                                       {'loss': 0.1382, 'grad_norm': 0.4179413299105341, 'learning_rate': 6.283993850262077e-06, 'epoch': 1.95}
 65%|██████▌   | 3850/5922 [1:54:26<1:01:04,  1.77s/it] 65%|██████▌   | 3851/5922 [1:54:27<57:44,  1.67s/it]   65%|██████▌   | 3852/5922 [1:54:29<1:00:17,  1.75s/it] 65%|██████▌   | 3853/5922 [1:54:31<1:02:20,  1.81s/it] 65%|██████▌   | 3854/5922 [1:54:34<1:09:04,  2.00s/it] 65%|██████▌   | 3855/5922 [1:54:36<1:10:14,  2.04s/it] 65%|██████▌   | 3856/5922 [1:54:38<1:08:48,  2.00s/it] 65%|██████▌   | 3857/5922 [1:54:39<1:03:48,  1.85s/it] 65%|██████▌   | 3858/5922 [1:54:41<59:11,  1.72s/it]   65%|██████▌   | 3859/5922 [1:54:43<1:01:29,  1.79s/it] 65%|██████▌   | 3860/5922 [1:54:44<57:32,  1.67s/it]   65%|██████▌   | 3861/5922 [1:54:46<1:00:15,  1.75s/it] 65%|██████▌   | 3862/5922 [1:54:47<56:55,  1.66s/it]   65%|██████▌   | 3863/5922 [1:54:50<1:02:54,  1.83s/it] 65%|██████▌   | 3864/5922 [1:54:51<1:00:13,  1.76s/it] 65%|██████▌   | 3865/5922 [1:54:53<57:06,  1.67s/it]   65%|██████▌   | 3866/5922 [1:54:54<54:17,  1.58s/it] 65%|██████▌   | 3867/5922 [1:54:55<52:34,  1.53s/it] 65%|██████▌   | 3868/5922 [1:54:57<57:26,  1.68s/it] 65%|██████▌   | 3869/5922 [1:54:59<54:41,  1.60s/it] 65%|██████▌   | 3870/5922 [1:55:01<1:01:14,  1.79s/it] 65%|██████▌   | 3871/5922 [1:55:03<1:02:01,  1.81s/it] 65%|██████▌   | 3872/5922 [1:55:05<1:04:31,  1.89s/it] 65%|██████▌   | 3873/5922 [1:55:07<1:01:12,  1.79s/it] 65%|██████▌   | 3874/5922 [1:55:08<58:12,  1.71s/it]   65%|██████▌   | 3875/5922 [1:55:10<59:00,  1.73s/it]                                                     {'loss': 0.1299, 'grad_norm': 0.3794811598594524, 'learning_rate': 6.17031417058922e-06, 'epoch': 1.96}
 65%|██████▌   | 3875/5922 [1:55:10<59:00,  1.73s/it] 65%|██████▌   | 3876/5922 [1:55:11<55:52,  1.64s/it] 65%|██████▌   | 3877/5922 [1:55:13<55:36,  1.63s/it] 65%|██████▌   | 3878/5922 [1:55:14<53:47,  1.58s/it] 66%|██████▌   | 3879/5922 [1:55:16<57:06,  1.68s/it] 66%|██████▌   | 3880/5922 [1:55:18<58:38,  1.72s/it] 66%|██████▌   | 3881/5922 [1:55:20<56:24,  1.66s/it] 66%|██████▌   | 3882/5922 [1:55:22<58:52,  1.73s/it] 66%|██████▌   | 3883/5922 [1:55:23<55:14,  1.63s/it] 66%|██████▌   | 3884/5922 [1:55:25<1:03:28,  1.87s/it] 66%|██████▌   | 3885/5922 [1:55:27<58:40,  1.73s/it]   66%|██████▌   | 3886/5922 [1:55:29<1:00:42,  1.79s/it] 66%|██████▌   | 3887/5922 [1:55:31<1:02:22,  1.84s/it] 66%|██████▌   | 3888/5922 [1:55:32<1:00:58,  1.80s/it] 66%|██████▌   | 3889/5922 [1:55:34<56:47,  1.68s/it]   66%|██████▌   | 3890/5922 [1:55:35<56:36,  1.67s/it] 66%|██████▌   | 3891/5922 [1:55:37<54:35,  1.61s/it] 66%|██████▌   | 3892/5922 [1:55:39<55:09,  1.63s/it] 66%|██████▌   | 3893/5922 [1:55:40<53:37,  1.59s/it] 66%|██████▌   | 3894/5922 [1:55:42<57:05,  1.69s/it] 66%|██████▌   | 3895/5922 [1:55:44<59:28,  1.76s/it] 66%|██████▌   | 3896/5922 [1:55:46<1:06:49,  1.98s/it] 66%|██████▌   | 3897/5922 [1:55:48<1:02:56,  1.86s/it] 66%|██████▌   | 3898/5922 [1:55:49<57:51,  1.72s/it]   66%|██████▌   | 3899/5922 [1:55:51<59:44,  1.77s/it] 66%|██████▌   | 3900/5922 [1:55:53<55:42,  1.65s/it]                                                     {'loss': 0.1356, 'grad_norm': 0.39478294979357526, 'learning_rate': 6.0574117002761254e-06, 'epoch': 1.98}
 66%|██████▌   | 3900/5922 [1:55:53<55:42,  1.65s/it] 66%|██████▌   | 3901/5922 [1:55:54<52:40,  1.56s/it] 66%|██████▌   | 3902/5922 [1:55:55<50:41,  1.51s/it] 66%|██████▌   | 3903/5922 [1:55:57<55:17,  1.64s/it] 66%|██████▌   | 3904/5922 [1:55:59<54:29,  1.62s/it] 66%|██████▌   | 3905/5922 [1:56:01<57:37,  1.71s/it] 66%|██████▌   | 3906/5922 [1:56:03<59:45,  1.78s/it] 66%|██████▌   | 3907/5922 [1:56:05<1:06:00,  1.97s/it] 66%|██████▌   | 3908/5922 [1:56:07<59:58,  1.79s/it]   66%|██████▌   | 3909/5922 [1:56:08<55:51,  1.66s/it] 66%|██████▌   | 3910/5922 [1:56:10<58:18,  1.74s/it] 66%|██████▌   | 3911/5922 [1:56:11<55:08,  1.64s/it] 66%|██████▌   | 3912/5922 [1:56:13<52:20,  1.56s/it] 66%|██████▌   | 3913/5922 [1:56:15<55:46,  1.67s/it] 66%|██████▌   | 3914/5922 [1:56:16<52:47,  1.58s/it] 66%|██████▌   | 3915/5922 [1:56:18<54:17,  1.62s/it] 66%|██████▌   | 3916/5922 [1:56:19<53:37,  1.60s/it] 66%|██████▌   | 3917/5922 [1:56:21<55:55,  1.67s/it] 66%|██████▌   | 3918/5922 [1:56:23<58:51,  1.76s/it] 66%|██████▌   | 3919/5922 [1:56:25<59:19,  1.78s/it] 66%|██████▌   | 3920/5922 [1:56:26<55:28,  1.66s/it] 66%|██████▌   | 3921/5922 [1:56:28<52:34,  1.58s/it] 66%|██████▌   | 3922/5922 [1:56:29<50:21,  1.51s/it] 66%|██████▌   | 3923/5922 [1:56:30<49:01,  1.47s/it] 66%|██████▋   | 3924/5922 [1:56:32<48:15,  1.45s/it] 66%|██████▋   | 3925/5922 [1:56:34<53:29,  1.61s/it]                                                     {'loss': 0.1279, 'grad_norm': 0.45382119309155594, 'learning_rate': 5.945306706118142e-06, 'epoch': 1.99}
 66%|██████▋   | 3925/5922 [1:56:34<53:29,  1.61s/it] 66%|██████▋   | 3926/5922 [1:56:35<52:17,  1.57s/it] 66%|██████▋   | 3927/5922 [1:56:37<50:58,  1.53s/it] 66%|██████▋   | 3928/5922 [1:56:38<49:36,  1.49s/it] 66%|██████▋   | 3929/5922 [1:56:39<48:38,  1.46s/it] 66%|██████▋   | 3930/5922 [1:56:41<54:44,  1.65s/it] 66%|██████▋   | 3931/5922 [1:56:43<57:09,  1.72s/it] 66%|██████▋   | 3932/5922 [1:56:45<53:24,  1.61s/it] 66%|██████▋   | 3933/5922 [1:56:47<56:12,  1.70s/it] 66%|██████▋   | 3934/5922 [1:56:48<53:02,  1.60s/it] 66%|██████▋   | 3935/5922 [1:56:50<1:01:32,  1.86s/it] 66%|██████▋   | 3936/5922 [1:56:52<56:57,  1.72s/it]   66%|██████▋   | 3937/5922 [1:56:54<59:59,  1.81s/it] 66%|██████▋   | 3938/5922 [1:56:56<1:01:07,  1.85s/it] 67%|██████▋   | 3939/5922 [1:56:57<56:29,  1.71s/it]   67%|██████▋   | 3940/5922 [1:56:59<53:08,  1.61s/it] 67%|██████▋   | 3941/5922 [1:57:01<57:11,  1.73s/it] 67%|██████▋   | 3942/5922 [1:57:03<58:50,  1.78s/it] 67%|██████▋   | 3943/5922 [1:57:05<1:03:32,  1.93s/it] 67%|██████▋   | 3944/5922 [1:57:07<1:01:58,  1.88s/it] 67%|██████▋   | 3945/5922 [1:57:08<57:05,  1.73s/it]   67%|██████▋   | 3946/5922 [1:57:09<53:09,  1.61s/it] 67%|██████▋   | 3947/5922 [1:57:11<50:58,  1.55s/it] 67%|██████▋   | 3948/5922 [1:57:11<42:06,  1.28s/it] 67%|██████▋   | 3949/5922 [1:57:14<53:50,  1.64s/it] 67%|██████▋   | 3950/5922 [1:57:16<56:32,  1.72s/it]                                                     {'loss': 0.1336, 'grad_norm': 0.48105641475077704, 'learning_rate': 5.834019311758e-06, 'epoch': 2.0}
 67%|██████▋   | 3950/5922 [1:57:16<56:32,  1.72s/it] 67%|██████▋   | 3951/5922 [1:57:17<53:54,  1.64s/it] 67%|██████▋   | 3952/5922 [1:57:19<53:18,  1.62s/it] 67%|██████▋   | 3953/5922 [1:57:21<55:59,  1.71s/it] 67%|██████▋   | 3954/5922 [1:57:22<53:30,  1.63s/it] 67%|██████▋   | 3955/5922 [1:57:24<51:38,  1.58s/it] 67%|██████▋   | 3956/5922 [1:57:25<50:16,  1.53s/it] 67%|██████▋   | 3957/5922 [1:57:27<58:36,  1.79s/it] 67%|██████▋   | 3958/5922 [1:57:29<1:00:21,  1.84s/it] 67%|██████▋   | 3959/5922 [1:57:31<1:01:10,  1.87s/it] 67%|██████▋   | 3960/5922 [1:57:33<1:00:22,  1.85s/it] 67%|██████▋   | 3961/5922 [1:57:34<56:21,  1.72s/it]   67%|██████▋   | 3962/5922 [1:57:36<52:51,  1.62s/it] 67%|██████▋   | 3963/5922 [1:57:37<52:01,  1.59s/it] 67%|██████▋   | 3964/5922 [1:57:40<57:04,  1.75s/it] 67%|██████▋   | 3965/5922 [1:57:41<53:14,  1.63s/it] 67%|██████▋   | 3966/5922 [1:57:42<52:28,  1.61s/it] 67%|██████▋   | 3967/5922 [1:57:44<49:58,  1.53s/it] 67%|██████▋   | 3968/5922 [1:57:46<52:55,  1.63s/it] 67%|██████▋   | 3969/5922 [1:57:47<52:43,  1.62s/it] 67%|██████▋   | 3970/5922 [1:57:49<54:42,  1.68s/it] 67%|██████▋   | 3971/5922 [1:57:51<57:02,  1.75s/it] 67%|██████▋   | 3972/5922 [1:57:53<59:11,  1.82s/it] 67%|██████▋   | 3973/5922 [1:57:54<56:17,  1.73s/it] 67%|██████▋   | 3974/5922 [1:57:56<57:48,  1.78s/it] 67%|██████▋   | 3975/5922 [1:57:58<58:59,  1.82s/it]                                                     {'loss': 0.1266, 'grad_norm': 0.49086742525534016, 'learning_rate': 5.7235694940734465e-06, 'epoch': 2.01}
 67%|██████▋   | 3975/5922 [1:57:58<58:59,  1.82s/it] 67%|██████▋   | 3976/5922 [1:58:00<54:17,  1.67s/it] 67%|██████▋   | 3977/5922 [1:58:01<54:18,  1.68s/it] 67%|██████▋   | 3978/5922 [1:58:03<51:44,  1.60s/it] 67%|██████▋   | 3979/5922 [1:58:05<58:46,  1.82s/it] 67%|██████▋   | 3980/5922 [1:58:06<54:18,  1.68s/it] 67%|██████▋   | 3981/5922 [1:58:08<56:33,  1.75s/it] 67%|██████▋   | 3982/5922 [1:58:10<53:04,  1.64s/it] 67%|██████▋   | 3983/5922 [1:58:11<51:49,  1.60s/it] 67%|██████▋   | 3984/5922 [1:58:13<49:28,  1.53s/it] 67%|██████▋   | 3985/5922 [1:58:14<52:53,  1.64s/it] 67%|██████▋   | 3986/5922 [1:58:16<55:40,  1.73s/it] 67%|██████▋   | 3987/5922 [1:58:18<53:12,  1.65s/it] 67%|██████▋   | 3988/5922 [1:58:19<50:36,  1.57s/it] 67%|██████▋   | 3989/5922 [1:58:21<53:49,  1.67s/it] 67%|██████▋   | 3990/5922 [1:58:23<54:34,  1.69s/it] 67%|██████▋   | 3991/5922 [1:58:25<56:20,  1.75s/it] 67%|██████▋   | 3992/5922 [1:58:27<58:36,  1.82s/it] 67%|██████▋   | 3993/5922 [1:58:29<59:59,  1.87s/it] 67%|██████▋   | 3994/5922 [1:58:31<1:05:41,  2.04s/it] 67%|██████▋   | 3995/5922 [1:58:33<58:59,  1.84s/it]   67%|██████▋   | 3996/5922 [1:58:34<54:29,  1.70s/it] 67%|██████▋   | 3997/5922 [1:58:36<57:37,  1.80s/it] 68%|██████▊   | 3998/5922 [1:58:37<53:16,  1.66s/it] 68%|██████▊   | 3999/5922 [1:58:39<51:18,  1.60s/it] 68%|██████▊   | 4000/5922 [1:58:40<48:44,  1.52s/it]                                                     {'loss': 0.1211, 'grad_norm': 0.40391576764544534, 'learning_rate': 5.613977079591272e-06, 'epoch': 2.03}
 68%|██████▊   | 4000/5922 [1:58:40<48:44,  1.52s/it][INFO|trainer.py:3993] 2025-08-30 15:47:31,861 >> Saving model checkpoint to saves/qwen3-1.7B/lora/sft/checkpoint-4000
[INFO|configuration_utils.py:696] 2025-08-30 15:47:31,873 >> loading configuration file /home/qianwenhao/LLM/Qwen3-1.7B/config.json
[INFO|configuration_utils.py:770] 2025-08-30 15:47:31,874 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "max_position_embeddings": 40960,
  "max_window_layers": 28,
  "model_type": "qwen3",
  "num_attention_heads": 16,
  "num_hidden_layers": 28,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|tokenization_utils_base.py:2356] 2025-08-30 15:47:31,890 >> chat template saved in saves/qwen3-1.7B/lora/sft/checkpoint-4000/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-08-30 15:47:31,891 >> tokenizer config file saved in saves/qwen3-1.7B/lora/sft/checkpoint-4000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-08-30 15:47:31,891 >> Special tokens file saved in saves/qwen3-1.7B/lora/sft/checkpoint-4000/special_tokens_map.json
[2025-08-30 15:47:32,051] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step3999 is about to be saved!
[2025-08-30 15:47:32,060] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: saves/qwen3-1.7B/lora/sft/checkpoint-4000/global_step3999/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-08-30 15:47:32,060] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-4000/global_step3999/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-08-30 15:47:32,065] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-4000/global_step3999/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-08-30 15:47:32,066] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-4000/global_step3999/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-08-30 15:47:32,077] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-4000/global_step3999/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-08-30 15:47:32,078] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved saves/qwen3-1.7B/lora/sft/checkpoint-4000/global_step3999/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-08-30 15:47:32,085] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3999 is ready now!
 68%|██████▊   | 4001/5922 [1:58:44<1:16:15,  2.38s/it] 68%|██████▊   | 4002/5922 [1:58:46<1:08:04,  2.13s/it] 68%|██████▊   | 4003/5922 [1:58:48<1:06:07,  2.07s/it] 68%|██████▊   | 4004/5922 [1:58:49<59:27,  1.86s/it]   68%|██████▊   | 4005/5922 [1:58:51<56:04,  1.76s/it] 68%|██████▊   | 4006/5922 [1:58:53<58:05,  1.82s/it] 68%|██████▊   | 4007/5922 [1:58:54<54:08,  1.70s/it] 68%|██████▊   | 4008/5922 [1:58:56<57:47,  1.81s/it] 68%|██████▊   | 4009/5922 [1:58:58<53:45,  1.69s/it] 68%|██████▊   | 4010/5922 [1:58:59<52:10,  1.64s/it] 68%|██████▊   | 4011/5922 [1:59:01<55:05,  1.73s/it] 68%|██████▊   | 4012/5922 [1:59:03<1:00:20,  1.90s/it] 68%|██████▊   | 4013/5922 [1:59:06<1:05:39,  2.06s/it] 68%|██████▊   | 4014/5922 [1:59:07<59:07,  1.86s/it]   68%|██████▊   | 4015/5922 [1:59:09<59:43,  1.88s/it] 68%|██████▊   | 4016/5922 [1:59:11<1:00:30,  1.90s/it] 68%|██████▊   | 4017/5922 [1:59:13<55:32,  1.75s/it]   68%|██████▊   | 4018/5922 [1:59:14<53:45,  1.69s/it] 68%|██████▊   | 4019/5922 [1:59:16<55:44,  1.76s/it] 68%|██████▊   | 4020/5922 [1:59:18<53:37,  1.69s/it] 68%|██████▊   | 4021/5922 [1:59:19<52:25,  1.65s/it] 68%|██████▊   | 4022/5922 [1:59:21<56:53,  1.80s/it] 68%|██████▊   | 4023/5922 [1:59:23<52:58,  1.67s/it] 68%|██████▊   | 4024/5922 [1:59:25<55:24,  1.75s/it] 68%|██████▊   | 4025/5922 [1:59:26<56:53,  1.80s/it]                                                     {'loss': 0.1381, 'grad_norm': 0.41636499899223606, 'learning_rate': 5.5052617409283025e-06, 'epoch': 2.04}
 68%|██████▊   | 4025/5922 [1:59:26<56:53,  1.80s/it] 68%|██████▊   | 4026/5922 [1:59:28<53:02,  1.68s/it] 68%|██████▊   | 4027/5922 [1:59:30<53:10,  1.68s/it] 68%|██████▊   | 4028/5922 [1:59:31<55:22,  1.75s/it] 68%|██████▊   | 4029/5922 [1:59:33<53:37,  1.70s/it] 68%|██████▊   | 4030/5922 [1:59:34<50:44,  1.61s/it] 68%|██████▊   | 4031/5922 [1:59:36<48:42,  1.55s/it] 68%|██████▊   | 4032/5922 [1:59:38<49:40,  1.58s/it] 68%|██████▊   | 4033/5922 [1:59:39<47:38,  1.51s/it] 68%|██████▊   | 4034/5922 [1:59:40<48:02,  1.53s/it] 68%|██████▊   | 4035/5922 [1:59:42<50:24,  1.60s/it] 68%|██████▊   | 4036/5922 [1:59:44<48:39,  1.55s/it] 68%|██████▊   | 4037/5922 [1:59:45<47:10,  1.50s/it] 68%|██████▊   | 4038/5922 [1:59:46<46:33,  1.48s/it] 68%|██████▊   | 4039/5922 [1:59:48<45:34,  1.45s/it] 68%|██████▊   | 4040/5922 [1:59:49<44:48,  1.43s/it] 68%|██████▊   | 4041/5922 [1:59:51<44:25,  1.42s/it] 68%|██████▊   | 4042/5922 [1:59:52<45:37,  1.46s/it] 68%|██████▊   | 4043/5922 [1:59:54<45:26,  1.45s/it] 68%|██████▊   | 4044/5922 [1:59:56<49:39,  1.59s/it] 68%|██████▊   | 4045/5922 [1:59:58<57:46,  1.85s/it] 68%|██████▊   | 4046/5922 [2:00:00<1:01:54,  1.98s/it] 68%|██████▊   | 4047/5922 [2:00:02<56:24,  1.81s/it]   68%|██████▊   | 4048/5922 [2:00:03<52:22,  1.68s/it] 68%|██████▊   | 4049/5922 [2:00:05<54:33,  1.75s/it] 68%|██████▊   | 4050/5922 [2:00:06<51:18,  1.64s/it]                                                     {'loss': 0.1306, 'grad_norm': 0.3349010377201273, 'learning_rate': 5.397442993260027e-06, 'epoch': 2.05}
 68%|██████▊   | 4050/5922 [2:00:06<51:18,  1.64s/it] 68%|██████▊   | 4051/5922 [2:00:09<59:14,  1.90s/it] 68%|██████▊   | 4052/5922 [2:00:11<59:10,  1.90s/it] 68%|██████▊   | 4053/5922 [2:00:13<59:19,  1.90s/it] 68%|██████▊   | 4054/5922 [2:00:14<57:59,  1.86s/it] 68%|██████▊   | 4055/5922 [2:00:16<59:17,  1.91s/it] 68%|██████▊   | 4056/5922 [2:00:18<59:28,  1.91s/it] 69%|██████▊   | 4057/5922 [2:00:20<59:25,  1.91s/it] 69%|██████▊   | 4058/5922 [2:00:22<55:25,  1.78s/it] 69%|██████▊   | 4059/5922 [2:00:24<56:50,  1.83s/it] 69%|██████▊   | 4060/5922 [2:00:25<52:33,  1.69s/it] 69%|██████▊   | 4061/5922 [2:00:27<54:15,  1.75s/it] 69%|██████▊   | 4062/5922 [2:00:29<55:49,  1.80s/it] 69%|██████▊   | 4063/5922 [2:00:30<51:50,  1.67s/it] 69%|██████▊   | 4064/5922 [2:00:32<55:05,  1.78s/it] 69%|██████▊   | 4065/5922 [2:00:34<50:59,  1.65s/it] 69%|██████▊   | 4066/5922 [2:00:35<48:22,  1.56s/it] 69%|██████▊   | 4067/5922 [2:00:37<48:10,  1.56s/it] 69%|██████▊   | 4068/5922 [2:00:38<51:41,  1.67s/it] 69%|██████▊   | 4069/5922 [2:00:40<53:02,  1.72s/it] 69%|██████▊   | 4070/5922 [2:00:42<53:13,  1.72s/it] 69%|██████▊   | 4071/5922 [2:00:43<50:06,  1.62s/it] 69%|██████▉   | 4072/5922 [2:00:45<47:55,  1.55s/it] 69%|██████▉   | 4073/5922 [2:00:47<51:55,  1.68s/it] 69%|██████▉   | 4074/5922 [2:00:48<48:56,  1.59s/it] 69%|██████▉   | 4075/5922 [2:00:50<46:46,  1.52s/it]                                                     {'loss': 0.1397, 'grad_norm': 0.45439266301456194, 'learning_rate': 5.290540190817471e-06, 'epoch': 2.06}
 69%|██████▉   | 4075/5922 [2:00:50<46:46,  1.52s/it] 69%|██████▉   | 4076/5922 [2:00:51<50:43,  1.65s/it] 69%|██████▉   | 4077/5922 [2:00:53<48:25,  1.57s/it] 69%|██████▉   | 4078/5922 [2:00:55<50:19,  1.64s/it] 69%|██████▉   | 4079/5922 [2:00:56<47:56,  1.56s/it] 69%|██████▉   | 4080/5922 [2:00:58<49:44,  1.62s/it] 69%|██████▉   | 4081/5922 [2:01:00<52:37,  1.72s/it] 69%|██████▉   | 4082/5922 [2:01:02<55:03,  1.80s/it] 69%|██████▉   | 4083/5922 [2:01:03<54:34,  1.78s/it] 69%|██████▉   | 4084/5922 [2:01:05<50:29,  1.65s/it] 69%|██████▉   | 4085/5922 [2:01:07<52:54,  1.73s/it] 69%|██████▉   | 4086/5922 [2:01:09<57:46,  1.89s/it] 69%|██████▉   | 4087/5922 [2:01:11<54:28,  1.78s/it] 69%|██████▉   | 4088/5922 [2:01:12<54:28,  1.78s/it] 69%|██████▉   | 4089/5922 [2:01:14<50:40,  1.66s/it] 69%|██████▉   | 4090/5922 [2:01:16<53:09,  1.74s/it] 69%|██████▉   | 4091/5922 [2:01:18<54:44,  1.79s/it] 69%|██████▉   | 4092/5922 [2:01:20<57:11,  1.88s/it] 69%|██████▉   | 4093/5922 [2:01:21<53:31,  1.76s/it] 69%|██████▉   | 4094/5922 [2:01:22<50:03,  1.64s/it] 69%|██████▉   | 4095/5922 [2:01:24<52:33,  1.73s/it] 69%|██████▉   | 4096/5922 [2:01:26<49:15,  1.62s/it] 69%|██████▉   | 4097/5922 [2:01:28<52:51,  1.74s/it] 69%|██████▉   | 4098/5922 [2:01:29<49:38,  1.63s/it] 69%|██████▉   | 4099/5922 [2:01:31<49:04,  1.61s/it] 69%|██████▉   | 4100/5922 [2:01:32<50:19,  1.66s/it]                                                     {'loss': 0.1303, 'grad_norm': 0.5255063091853127, 'learning_rate': 5.1845725234129996e-06, 'epoch': 2.08}
 69%|██████▉   | 4100/5922 [2:01:32<50:19,  1.66s/it] 69%|██████▉   | 4101/5922 [2:01:34<47:42,  1.57s/it] 69%|██████▉   | 4102/5922 [2:01:35<47:48,  1.58s/it] 69%|██████▉   | 4103/5922 [2:01:37<51:21,  1.69s/it] 69%|██████▉   | 4104/5922 [2:01:39<48:23,  1.60s/it] 69%|██████▉   | 4105/5922 [2:01:41<50:17,  1.66s/it] 69%|██████▉   | 4106/5922 [2:01:42<52:48,  1.74s/it] 69%|██████▉   | 4107/5922 [2:01:44<51:29,  1.70s/it] 69%|██████▉   | 4108/5922 [2:01:46<53:48,  1.78s/it] 69%|██████▉   | 4109/5922 [2:01:48<54:51,  1.82s/it] 69%|██████▉   | 4110/5922 [2:01:50<1:00:57,  2.02s/it] 69%|██████▉   | 4111/5922 [2:01:52<1:00:04,  1.99s/it] 69%|██████▉   | 4112/5922 [2:01:54<1:00:08,  1.99s/it] 69%|██████▉   | 4113/5922 [2:01:56<59:20,  1.97s/it]   69%|██████▉   | 4114/5922 [2:01:58<53:50,  1.79s/it] 69%|██████▉   | 4115/5922 [2:02:00<54:48,  1.82s/it] 70%|██████▉   | 4116/5922 [2:02:02<59:38,  1.98s/it] 70%|██████▉   | 4117/5922 [2:02:04<59:56,  1.99s/it] 70%|██████▉   | 4118/5922 [2:02:05<54:57,  1.83s/it] 70%|██████▉   | 4119/5922 [2:02:07<51:30,  1.71s/it] 70%|██████▉   | 4120/5922 [2:02:09<51:58,  1.73s/it] 70%|██████▉   | 4121/5922 [2:02:10<53:22,  1.78s/it] 70%|██████▉   | 4122/5922 [2:02:12<54:30,  1.82s/it] 70%|██████▉   | 4123/5922 [2:02:14<50:20,  1.68s/it] 70%|██████▉   | 4124/5922 [2:02:15<47:30,  1.59s/it] 70%|██████▉   | 4125/5922 [2:02:17<50:24,  1.68s/it]                                                     {'loss': 0.136, 'grad_norm': 0.45729441089182254, 'learning_rate': 5.0795590129955886e-06, 'epoch': 2.09}
 70%|██████▉   | 4125/5922 [2:02:17<50:24,  1.68s/it] 70%|██████▉   | 4126/5922 [2:02:18<47:15,  1.58s/it] 70%|██████▉   | 4127/5922 [2:02:21<54:41,  1.83s/it] 70%|██████▉   | 4128/5922 [2:02:23<59:38,  1.99s/it] 70%|██████▉   | 4129/5922 [2:02:25<53:55,  1.80s/it] 70%|██████▉   | 4130/5922 [2:02:26<54:50,  1.84s/it] 70%|██████▉   | 4131/5922 [2:02:28<51:04,  1.71s/it] 70%|██████▉   | 4132/5922 [2:02:29<48:37,  1.63s/it] 70%|██████▉   | 4133/5922 [2:02:31<48:52,  1.64s/it] 70%|██████▉   | 4134/5922 [2:02:32<47:28,  1.59s/it] 70%|██████▉   | 4135/5922 [2:02:34<45:44,  1.54s/it] 70%|██████▉   | 4136/5922 [2:02:36<48:22,  1.62s/it] 70%|██████▉   | 4137/5922 [2:02:37<48:08,  1.62s/it] 70%|██████▉   | 4138/5922 [2:02:39<50:48,  1.71s/it] 70%|██████▉   | 4139/5922 [2:02:41<53:58,  1.82s/it] 70%|██████▉   | 4140/5922 [2:02:44<59:42,  2.01s/it] 70%|██████▉   | 4141/5922 [2:02:46<1:02:41,  2.11s/it] 70%|██████▉   | 4142/5922 [2:02:48<1:02:04,  2.09s/it] 70%|██████▉   | 4143/5922 [2:02:49<55:39,  1.88s/it]   70%|██████▉   | 4144/5922 [2:02:51<51:35,  1.74s/it] 70%|██████▉   | 4145/5922 [2:02:53<51:02,  1.72s/it] 70%|███████   | 4146/5922 [2:02:55<57:26,  1.94s/it] 70%|███████   | 4147/5922 [2:02:57<57:18,  1.94s/it] 70%|███████   | 4148/5922 [2:02:59<55:45,  1.89s/it] 70%|███████   | 4149/5922 [2:03:01<55:58,  1.89s/it] 70%|███████   | 4150/5922 [2:03:02<52:58,  1.79s/it]                                                     {'loss': 0.1465, 'grad_norm': 0.5469250973995678, 'learning_rate': 4.975518510236262e-06, 'epoch': 2.1}
 70%|███████   | 4150/5922 [2:03:02<52:58,  1.79s/it] 70%|███████   | 4151/5922 [2:03:04<52:19,  1.77s/it] 70%|███████   | 4152/5922 [2:03:05<49:18,  1.67s/it] 70%|███████   | 4153/5922 [2:03:08<55:05,  1.87s/it] 70%|███████   | 4154/5922 [2:03:10<56:45,  1.93s/it] 70%|███████   | 4155/5922 [2:03:12<56:47,  1.93s/it] 70%|███████   | 4156/5922 [2:03:14<57:14,  1.94s/it] 70%|███████   | 4157/5922 [2:03:15<52:09,  1.77s/it] 70%|███████   | 4158/5922 [2:03:16<48:34,  1.65s/it] 70%|███████   | 4159/5922 [2:03:19<54:51,  1.87s/it] 70%|███████   | 4160/5922 [2:03:20<50:44,  1.73s/it] 70%|███████   | 4161/5922 [2:03:22<49:11,  1.68s/it] 70%|███████   | 4162/5922 [2:03:24<51:29,  1.76s/it] 70%|███████   | 4163/5922 [2:03:26<56:36,  1.93s/it] 70%|███████   | 4164/5922 [2:03:28<53:23,  1.82s/it] 70%|███████   | 4165/5922 [2:03:29<49:57,  1.71s/it] 70%|███████   | 4166/5922 [2:03:30<46:54,  1.60s/it] 70%|███████   | 4167/5922 [2:03:32<45:09,  1.54s/it] 70%|███████   | 4168/5922 [2:03:34<52:39,  1.80s/it] 70%|███████   | 4169/5922 [2:03:37<57:57,  1.98s/it] 70%|███████   | 4170/5922 [2:03:39<1:02:17,  2.13s/it] 70%|███████   | 4171/5922 [2:03:41<1:03:16,  2.17s/it] 70%|███████   | 4172/5922 [2:03:43<56:26,  1.93s/it]   70%|███████   | 4173/5922 [2:03:44<52:34,  1.80s/it] 70%|███████   | 4174/5922 [2:03:46<53:44,  1.84s/it] 70%|███████   | 4175/5922 [2:03:48<54:17,  1.86s/it]                                                     {'loss': 0.1402, 'grad_norm': 0.4367248960779216, 'learning_rate': 4.872469691144257e-06, 'epoch': 2.12}
 70%|███████   | 4175/5922 [2:03:48<54:17,  1.86s/it] 71%|███████   | 4176/5922 [2:03:50<50:49,  1.75s/it] 71%|███████   | 4177/5922 [2:03:52<56:35,  1.95s/it] 71%|███████   | 4178/5922 [2:03:54<55:59,  1.93s/it] 71%|███████   | 4179/5922 [2:03:55<53:36,  1.85s/it] 71%|███████   | 4180/5922 [2:03:57<54:26,  1.88s/it] 71%|███████   | 4181/5922 [2:03:59<50:08,  1.73s/it] 71%|███████   | 4182/5922 [2:04:01<51:35,  1.78s/it] 71%|███████   | 4183/5922 [2:04:02<50:03,  1.73s/it] 71%|███████   | 4184/5922 [2:04:04<50:18,  1.74s/it] 71%|███████   | 4185/5922 [2:04:05<47:25,  1.64s/it] 71%|███████   | 4186/5922 [2:04:07<45:24,  1.57s/it] 71%|███████   | 4187/5922 [2:04:08<44:04,  1.52s/it] 71%|███████   | 4188/5922 [2:04:10<42:53,  1.48s/it] 71%|███████   | 4189/5922 [2:04:12<46:01,  1.59s/it] 71%|███████   | 4190/5922 [2:04:13<48:21,  1.68s/it] 71%|███████   | 4191/5922 [2:04:15<50:31,  1.75s/it] 71%|███████   | 4192/5922 [2:04:17<51:56,  1.80s/it] 71%|███████   | 4193/5922 [2:04:19<48:12,  1.67s/it] 71%|███████   | 4194/5922 [2:04:20<47:41,  1.66s/it] 71%|███████   | 4195/5922 [2:04:22<49:52,  1.73s/it] 71%|███████   | 4196/5922 [2:04:25<56:07,  1.95s/it] 71%|███████   | 4197/5922 [2:04:27<55:52,  1.94s/it] 71%|███████   | 4198/5922 [2:04:28<51:10,  1.78s/it] 71%|███████   | 4199/5922 [2:04:30<57:06,  1.99s/it] 71%|███████   | 4200/5922 [2:04:32<51:51,  1.81s/it]                                                     {'loss': 0.1289, 'grad_norm': 0.39027095222615293, 'learning_rate': 4.770431053714538e-06, 'epoch': 2.13}
 71%|███████   | 4200/5922 [2:04:32<51:51,  1.81s/it] 71%|███████   | 4201/5922 [2:04:34<51:50,  1.81s/it] 71%|███████   | 4202/5922 [2:04:35<47:59,  1.67s/it] 71%|███████   | 4203/5922 [2:04:37<48:49,  1.70s/it] 71%|███████   | 4204/5922 [2:04:39<49:33,  1.73s/it] 71%|███████   | 4205/5922 [2:04:41<51:22,  1.80s/it] 71%|███████   | 4206/5922 [2:04:42<48:27,  1.69s/it] 71%|███████   | 4207/5922 [2:04:44<53:12,  1.86s/it] 71%|███████   | 4208/5922 [2:04:47<58:25,  2.05s/it] 71%|███████   | 4209/5922 [2:04:49<1:01:50,  2.17s/it] 71%|███████   | 4210/5922 [2:04:51<56:39,  1.99s/it]   71%|███████   | 4211/5922 [2:04:53<57:29,  2.02s/it] 71%|███████   | 4212/5922 [2:04:55<56:30,  1.98s/it] 71%|███████   | 4213/5922 [2:04:57<56:16,  1.98s/it] 71%|███████   | 4214/5922 [2:04:59<56:00,  1.97s/it] 71%|███████   | 4215/5922 [2:05:00<51:14,  1.80s/it] 71%|███████   | 4216/5922 [2:05:01<47:48,  1.68s/it] 71%|███████   | 4217/5922 [2:05:04<54:33,  1.92s/it] 71%|███████   | 4218/5922 [2:05:05<49:49,  1.75s/it] 71%|███████   | 4219/5922 [2:05:07<46:53,  1.65s/it] 71%|███████▏  | 4220/5922 [2:05:09<49:09,  1.73s/it] 71%|███████▏  | 4221/5922 [2:05:10<47:16,  1.67s/it] 71%|███████▏  | 4222/5922 [2:05:12<49:36,  1.75s/it] 71%|███████▏  | 4223/5922 [2:05:14<51:09,  1.81s/it] 71%|███████▏  | 4224/5922 [2:05:16<51:59,  1.84s/it] 71%|███████▏  | 4225/5922 [2:05:17<47:54,  1.69s/it]                                                     {'loss': 0.131, 'grad_norm': 0.4248748281818339, 'learning_rate': 4.669420914607309e-06, 'epoch': 2.14}
 71%|███████▏  | 4225/5922 [2:05:17<47:54,  1.69s/it] 71%|███████▏  | 4226/5922 [2:05:19<47:08,  1.67s/it] 71%|███████▏  | 4227/5922 [2:05:20<45:49,  1.62s/it] 71%|███████▏  | 4228/5922 [2:05:22<46:59,  1.66s/it] 71%|███████▏  | 4229/5922 [2:05:24<49:15,  1.75s/it] 71%|███████▏  | 4230/5922 [2:05:26<50:46,  1.80s/it] 71%|███████▏  | 4231/5922 [2:05:28<48:20,  1.72s/it] 71%|███████▏  | 4232/5922 [2:05:29<46:45,  1.66s/it] 71%|███████▏  | 4233/5922 [2:05:31<52:14,  1.86s/it] 71%|███████▏  | 4234/5922 [2:05:33<49:10,  1.75s/it] 72%|███████▏  | 4235/5922 [2:05:34<45:43,  1.63s/it] 72%|███████▏  | 4236/5922 [2:05:37<52:36,  1.87s/it] 72%|███████▏  | 4237/5922 [2:05:38<48:15,  1.72s/it] 72%|███████▏  | 4238/5922 [2:05:40<54:17,  1.93s/it] 72%|███████▏  | 4239/5922 [2:05:42<49:39,  1.77s/it] 72%|███████▏  | 4240/5922 [2:05:43<46:27,  1.66s/it] 72%|███████▏  | 4241/5922 [2:05:46<51:34,  1.84s/it] 72%|███████▏  | 4242/5922 [2:05:47<47:36,  1.70s/it] 72%|███████▏  | 4243/5922 [2:05:48<46:45,  1.67s/it] 72%|███████▏  | 4244/5922 [2:05:50<44:20,  1.59s/it] 72%|███████▏  | 4245/5922 [2:05:52<47:06,  1.69s/it] 72%|███████▏  | 4246/5922 [2:05:53<44:18,  1.59s/it] 72%|███████▏  | 4247/5922 [2:05:55<46:49,  1.68s/it] 72%|███████▏  | 4248/5922 [2:05:57<48:59,  1.76s/it] 72%|███████▏  | 4249/5922 [2:05:59<52:10,  1.87s/it] 72%|███████▏  | 4250/5922 [2:06:01<49:16,  1.77s/it]                                                     {'loss': 0.1222, 'grad_norm': 0.46293876558140634, 'learning_rate': 4.569457405859991e-06, 'epoch': 2.15}
 72%|███████▏  | 4250/5922 [2:06:01<49:16,  1.77s/it] 72%|███████▏  | 4251/5922 [2:06:02<45:55,  1.65s/it] 72%|███████▏  | 4252/5922 [2:06:04<48:08,  1.73s/it] 72%|███████▏  | 4253/5922 [2:06:05<45:19,  1.63s/it] 72%|███████▏  | 4254/5922 [2:06:07<43:10,  1.55s/it] 72%|███████▏  | 4255/5922 [2:06:08<41:44,  1.50s/it] 72%|███████▏  | 4256/5922 [2:06:10<41:06,  1.48s/it] 72%|███████▏  | 4257/5922 [2:06:11<44:46,  1.61s/it] 72%|███████▏  | 4258/5922 [2:06:13<44:13,  1.59s/it] 72%|███████▏  | 4259/5922 [2:06:14<43:11,  1.56s/it] 72%|███████▏  | 4260/5922 [2:06:16<45:00,  1.62s/it] 72%|███████▏  | 4261/5922 [2:06:18<47:14,  1.71s/it] 72%|███████▏  | 4262/5922 [2:06:19<44:06,  1.59s/it] 72%|███████▏  | 4263/5922 [2:06:21<43:48,  1.58s/it] 72%|███████▏  | 4264/5922 [2:06:23<43:17,  1.57s/it] 72%|███████▏  | 4265/5922 [2:06:24<45:30,  1.65s/it] 72%|███████▏  | 4266/5922 [2:06:27<50:29,  1.83s/it] 72%|███████▏  | 4267/5922 [2:06:28<46:30,  1.69s/it] 72%|███████▏  | 4268/5922 [2:06:30<48:13,  1.75s/it] 72%|███████▏  | 4269/5922 [2:06:31<45:43,  1.66s/it] 72%|███████▏  | 4270/5922 [2:06:33<47:16,  1.72s/it] 72%|███████▏  | 4271/5922 [2:06:35<44:30,  1.62s/it] 72%|███████▏  | 4272/5922 [2:06:37<47:54,  1.74s/it] 72%|███████▏  | 4273/5922 [2:06:39<50:11,  1.83s/it] 72%|███████▏  | 4274/5922 [2:06:40<46:23,  1.69s/it] 72%|███████▏  | 4275/5922 [2:06:42<49:16,  1.80s/it]                                                     {'loss': 0.1306, 'grad_norm': 0.41876887739834395, 'learning_rate': 4.470558471632451e-06, 'epoch': 2.17}
 72%|███████▏  | 4275/5922 [2:06:42<49:16,  1.80s/it] 72%|███████▏  | 4276/5922 [2:06:45<54:53,  2.00s/it] 72%|███████▏  | 4277/5922 [2:06:47<57:52,  2.11s/it] 72%|███████▏  | 4278/5922 [2:06:48<51:47,  1.89s/it] 72%|███████▏  | 4279/5922 [2:06:50<47:41,  1.74s/it] 72%|███████▏  | 4280/5922 [2:06:51<44:55,  1.64s/it] 72%|███████▏  | 4281/5922 [2:06:53<47:20,  1.73s/it] 72%|███████▏  | 4282/5922 [2:06:55<48:46,  1.78s/it] 72%|███████▏  | 4283/5922 [2:06:57<48:17,  1.77s/it] 72%|███████▏  | 4284/5922 [2:06:59<49:28,  1.81s/it] 72%|███████▏  | 4285/5922 [2:07:00<50:24,  1.85s/it] 72%|███████▏  | 4286/5922 [2:07:02<46:44,  1.71s/it] 72%|███████▏  | 4287/5922 [2:07:04<48:01,  1.76s/it] 72%|███████▏  | 4288/5922 [2:07:06<53:36,  1.97s/it] 72%|███████▏  | 4289/5922 [2:07:08<52:10,  1.92s/it] 72%|███████▏  | 4290/5922 [2:07:10<52:09,  1.92s/it] 72%|███████▏  | 4291/5922 [2:07:12<51:31,  1.90s/it] 72%|███████▏  | 4292/5922 [2:07:13<47:23,  1.74s/it] 72%|███████▏  | 4293/5922 [2:07:15<50:13,  1.85s/it] 73%|███████▎  | 4294/5922 [2:07:17<50:54,  1.88s/it] 73%|███████▎  | 4295/5922 [2:07:19<50:30,  1.86s/it] 73%|███████▎  | 4296/5922 [2:07:21<51:01,  1.88s/it] 73%|███████▎  | 4297/5922 [2:07:23<48:12,  1.78s/it] 73%|███████▎  | 4298/5922 [2:07:24<47:42,  1.76s/it] 73%|███████▎  | 4299/5922 [2:07:26<46:07,  1.71s/it] 73%|███████▎  | 4300/5922 [2:07:28<47:12,  1.75s/it]                                                     {'loss': 0.134, 'grad_norm': 0.39301960550701914, 'learning_rate': 4.372741864985844e-06, 'epoch': 2.18}
 73%|███████▎  | 4300/5922 [2:07:28<47:12,  1.75s/it] 73%|███████▎  | 4301/5922 [2:07:30<51:45,  1.92s/it] 73%|███████▎  | 4302/5922 [2:07:32<51:59,  1.93s/it] 73%|███████▎  | 4303/5922 [2:07:33<48:23,  1.79s/it] 73%|███████▎  | 4304/5922 [2:07:35<46:02,  1.71s/it] 73%|███████▎  | 4305/5922 [2:07:36<44:33,  1.65s/it] 73%|███████▎  | 4306/5922 [2:07:38<42:29,  1.58s/it] 73%|███████▎  | 4307/5922 [2:07:39<41:14,  1.53s/it] 73%|███████▎  | 4308/5922 [2:07:41<40:11,  1.49s/it] 73%|███████▎  | 4309/5922 [2:07:42<39:34,  1.47s/it] 73%|███████▎  | 4310/5922 [2:07:43<38:55,  1.45s/it] 73%|███████▎  | 4311/5922 [2:07:45<42:08,  1.57s/it] 73%|███████▎  | 4312/5922 [2:07:47<45:03,  1.68s/it] 73%|███████▎  | 4313/5922 [2:07:49<43:07,  1.61s/it] 73%|███████▎  | 4314/5922 [2:07:50<43:02,  1.61s/it] 73%|███████▎  | 4315/5922 [2:07:53<48:43,  1.82s/it] 73%|███████▎  | 4316/5922 [2:07:55<49:33,  1.85s/it] 73%|███████▎  | 4317/5922 [2:07:56<45:57,  1.72s/it] 73%|███████▎  | 4318/5922 [2:07:58<47:31,  1.78s/it] 73%|███████▎  | 4319/5922 [2:08:00<48:46,  1.83s/it] 73%|███████▎  | 4320/5922 [2:08:01<45:59,  1.72s/it] 73%|███████▎  | 4321/5922 [2:08:03<45:45,  1.72s/it] 73%|███████▎  | 4322/5922 [2:08:05<50:25,  1.89s/it] 73%|███████▎  | 4323/5922 [2:08:07<50:32,  1.90s/it] 73%|███████▎  | 4324/5922 [2:08:09<46:16,  1.74s/it] 73%|███████▎  | 4325/5922 [2:08:10<47:44,  1.79s/it]                                                     {'loss': 0.1269, 'grad_norm': 0.51534723870604, 'learning_rate': 4.276025144695847e-06, 'epoch': 2.19}
 73%|███████▎  | 4325/5922 [2:08:10<47:44,  1.79s/it] 73%|███████▎  | 4326/5922 [2:08:12<44:29,  1.67s/it] 73%|███████▎  | 4327/5922 [2:08:13<42:17,  1.59s/it] 73%|███████▎  | 4328/5922 [2:08:15<45:30,  1.71s/it] 73%|███████▎  | 4329/5922 [2:08:18<51:25,  1.94s/it] 73%|███████▎  | 4330/5922 [2:08:19<46:55,  1.77s/it] 73%|███████▎  | 4331/5922 [2:08:21<49:26,  1.86s/it] 73%|███████▎  | 4332/5922 [2:08:24<54:03,  2.04s/it] 73%|███████▎  | 4333/5922 [2:08:25<49:04,  1.85s/it] 73%|███████▎  | 4334/5922 [2:08:26<45:34,  1.72s/it] 73%|███████▎  | 4335/5922 [2:08:28<47:00,  1.78s/it] 73%|███████▎  | 4336/5922 [2:08:30<43:52,  1.66s/it] 73%|███████▎  | 4337/5922 [2:08:31<41:40,  1.58s/it] 73%|███████▎  | 4338/5922 [2:08:33<44:52,  1.70s/it] 73%|███████▎  | 4339/5922 [2:08:35<42:44,  1.62s/it] 73%|███████▎  | 4340/5922 [2:08:37<45:16,  1.72s/it] 73%|███████▎  | 4341/5922 [2:08:38<42:31,  1.61s/it] 73%|███████▎  | 4342/5922 [2:08:39<40:53,  1.55s/it] 73%|███████▎  | 4343/5922 [2:08:41<39:30,  1.50s/it] 73%|███████▎  | 4344/5922 [2:08:43<43:52,  1.67s/it] 73%|███████▎  | 4345/5922 [2:08:45<50:15,  1.91s/it] 73%|███████▎  | 4346/5922 [2:08:47<46:04,  1.75s/it] 73%|███████▎  | 4347/5922 [2:08:49<47:21,  1.80s/it] 73%|███████▎  | 4348/5922 [2:08:51<51:32,  1.96s/it] 73%|███████▎  | 4349/5922 [2:08:53<49:30,  1.89s/it] 73%|███████▎  | 4350/5922 [2:08:54<46:30,  1.78s/it]                                                     {'loss': 0.1301, 'grad_norm': 0.450817942740974, 'learning_rate': 4.180425672100724e-06, 'epoch': 2.2}
 73%|███████▎  | 4350/5922 [2:08:54<46:30,  1.78s/it] 73%|███████▎  | 4351/5922 [2:08:56<46:56,  1.79s/it] 73%|███████▎  | 4352/5922 [2:08:58<45:57,  1.76s/it] 74%|███████▎  | 4353/5922 [2:08:59<42:47,  1.64s/it] 74%|███████▎  | 4354/5922 [2:09:00<40:42,  1.56s/it] 74%|███████▎  | 4355/5922 [2:09:03<47:38,  1.82s/it] 74%|███████▎  | 4356/5922 [2:09:04<44:02,  1.69s/it] 74%|███████▎  | 4357/5922 [2:09:06<41:43,  1.60s/it] 74%|███████▎  | 4358/5922 [2:09:08<48:34,  1.86s/it] 74%|███████▎  | 4359/5922 [2:09:10<48:50,  1.87s/it] 74%|███████▎  | 4360/5922 [2:09:11<45:02,  1.73s/it] 74%|███████▎  | 4361/5922 [2:09:13<46:30,  1.79s/it] 74%|███████▎  | 4362/5922 [2:09:15<48:53,  1.88s/it] 74%|███████▎  | 4363/5922 [2:09:17<48:33,  1.87s/it] 74%|███████▎  | 4364/5922 [2:09:19<44:43,  1.72s/it] 74%|███████▎  | 4365/5922 [2:09:20<42:07,  1.62s/it] 74%|███████▎  | 4366/5922 [2:09:21<41:22,  1.60s/it] 74%|███████▎  | 4367/5922 [2:09:23<44:06,  1.70s/it] 74%|███████▍  | 4368/5922 [2:09:25<41:47,  1.61s/it] 74%|███████▍  | 4369/5922 [2:09:27<44:56,  1.74s/it] 74%|███████▍  | 4370/5922 [2:09:29<46:20,  1.79s/it] 74%|███████▍  | 4371/5922 [2:09:30<42:58,  1.66s/it] 74%|███████▍  | 4372/5922 [2:09:32<45:23,  1.76s/it] 74%|███████▍  | 4373/5922 [2:09:34<46:39,  1.81s/it] 74%|███████▍  | 4374/5922 [2:09:36<44:32,  1.73s/it] 74%|███████▍  | 4375/5922 [2:09:38<47:08,  1.83s/it]                                                     {'loss': 0.1361, 'grad_norm': 0.46251051907492, 'learning_rate': 4.085960607984839e-06, 'epoch': 2.22}
 74%|███████▍  | 4375/5922 [2:09:38<47:08,  1.83s/it] 74%|███████▍  | 4376/5922 [2:09:40<51:29,  2.00s/it] 74%|███████▍  | 4377/5922 [2:09:41<46:43,  1.81s/it] 74%|███████▍  | 4378/5922 [2:09:43<47:37,  1.85s/it] 74%|███████▍  | 4379/5922 [2:09:45<43:46,  1.70s/it] 74%|███████▍  | 4380/5922 [2:09:46<41:20,  1.61s/it] 74%|███████▍  | 4381/5922 [2:09:47<39:27,  1.54s/it] 74%|███████▍  | 4382/5922 [2:09:49<41:08,  1.60s/it] 74%|███████▍  | 4383/5922 [2:09:51<39:26,  1.54s/it] 74%|███████▍  | 4384/5922 [2:09:52<41:58,  1.64s/it] 74%|███████▍  | 4385/5922 [2:09:54<40:35,  1.58s/it] 74%|███████▍  | 4386/5922 [2:09:55<39:12,  1.53s/it] 74%|███████▍  | 4387/5922 [2:09:57<38:08,  1.49s/it] 74%|███████▍  | 4388/5922 [2:09:58<37:09,  1.45s/it] 74%|███████▍  | 4389/5922 [2:10:00<36:36,  1.43s/it] 74%|███████▍  | 4390/5922 [2:10:01<38:21,  1.50s/it] 74%|███████▍  | 4391/5922 [2:10:03<41:52,  1.64s/it] 74%|███████▍  | 4392/5922 [2:10:05<40:53,  1.60s/it] 74%|███████▍  | 4393/5922 [2:10:07<43:10,  1.69s/it] 74%|███████▍  | 4394/5922 [2:10:08<42:16,  1.66s/it] 74%|███████▍  | 4395/5922 [2:10:10<44:10,  1.74s/it] 74%|███████▍  | 4396/5922 [2:10:12<44:08,  1.74s/it] 74%|███████▍  | 4397/5922 [2:10:14<44:53,  1.77s/it] 74%|███████▍  | 4398/5922 [2:10:15<41:49,  1.65s/it] 74%|███████▍  | 4399/5922 [2:10:17<41:51,  1.65s/it] 74%|███████▍  | 4400/5922 [2:10:19<44:04,  1.74s/it]                                                     {'loss': 0.128, 'grad_norm': 0.772487261840949, 'learning_rate': 3.992646909498179e-06, 'epoch': 2.23}
 74%|███████▍  | 4400/5922 [2:10:19<44:04,  1.74s/it] 74%|███████▍  | 4401/5922 [2:10:21<45:32,  1.80s/it] 74%|███████▍  | 4402/5922 [2:10:22<42:38,  1.68s/it] 74%|███████▍  | 4403/5922 [2:10:24<45:18,  1.79s/it] 74%|███████▍  | 4404/5922 [2:10:25<41:57,  1.66s/it] 74%|███████▍  | 4405/5922 [2:10:27<41:45,  1.65s/it] 74%|███████▍  | 4406/5922 [2:10:29<44:36,  1.77s/it] 74%|███████▍  | 4407/5922 [2:10:30<41:58,  1.66s/it] 74%|███████▍  | 4408/5922 [2:10:32<42:57,  1.70s/it] 74%|███████▍  | 4409/5922 [2:10:34<43:18,  1.72s/it] 74%|███████▍  | 4410/5922 [2:10:36<45:37,  1.81s/it] 74%|███████▍  | 4411/5922 [2:10:38<50:38,  2.01s/it] 75%|███████▍  | 4412/5922 [2:10:40<45:56,  1.83s/it] 75%|███████▍  | 4413/5922 [2:10:42<45:43,  1.82s/it] 75%|███████▍  | 4414/5922 [2:10:44<46:26,  1.85s/it] 75%|███████▍  | 4415/5922 [2:10:45<42:43,  1.70s/it] 75%|███████▍  | 4416/5922 [2:10:46<40:25,  1.61s/it] 75%|███████▍  | 4417/5922 [2:10:48<38:55,  1.55s/it] 75%|███████▍  | 4418/5922 [2:10:49<38:31,  1.54s/it] 75%|███████▍  | 4419/5922 [2:10:51<37:29,  1.50s/it] 75%|███████▍  | 4420/5922 [2:10:53<41:55,  1.67s/it] 75%|███████▍  | 4421/5922 [2:10:55<47:54,  1.92s/it] 75%|███████▍  | 4422/5922 [2:10:57<44:41,  1.79s/it] 75%|███████▍  | 4423/5922 [2:10:58<43:11,  1.73s/it] 75%|███████▍  | 4424/5922 [2:11:00<44:28,  1.78s/it] 75%|███████▍  | 4425/5922 [2:11:02<41:30,  1.66s/it]                                                     {'loss': 0.1364, 'grad_norm': 0.43079991370495446, 'learning_rate': 3.900501327112425e-06, 'epoch': 2.24}
 75%|███████▍  | 4425/5922 [2:11:02<41:30,  1.66s/it] 75%|███████▍  | 4426/5922 [2:11:04<45:47,  1.84s/it] 75%|███████▍  | 4427/5922 [2:11:05<43:27,  1.74s/it] 75%|███████▍  | 4428/5922 [2:11:07<42:25,  1.70s/it] 75%|███████▍  | 4429/5922 [2:11:09<47:07,  1.89s/it] 75%|███████▍  | 4430/5922 [2:11:11<49:04,  1.97s/it] 75%|███████▍  | 4431/5922 [2:11:13<44:42,  1.80s/it] 75%|███████▍  | 4432/5922 [2:11:14<41:43,  1.68s/it] 75%|███████▍  | 4433/5922 [2:11:17<47:40,  1.92s/it] 75%|███████▍  | 4434/5922 [2:11:18<43:38,  1.76s/it] 75%|███████▍  | 4435/5922 [2:11:20<44:26,  1.79s/it] 75%|███████▍  | 4436/5922 [2:11:21<41:21,  1.67s/it] 75%|███████▍  | 4437/5922 [2:11:23<42:47,  1.73s/it] 75%|███████▍  | 4438/5922 [2:11:25<44:01,  1.78s/it] 75%|███████▍  | 4439/5922 [2:11:27<41:56,  1.70s/it] 75%|███████▍  | 4440/5922 [2:11:28<42:55,  1.74s/it] 75%|███████▍  | 4441/5922 [2:11:30<40:19,  1.63s/it] 75%|███████▌  | 4442/5922 [2:11:32<42:55,  1.74s/it] 75%|███████▌  | 4443/5922 [2:11:33<40:15,  1.63s/it] 75%|███████▌  | 4444/5922 [2:11:35<38:21,  1.56s/it] 75%|███████▌  | 4445/5922 [2:11:37<42:12,  1.71s/it] 75%|███████▌  | 4446/5922 [2:11:39<43:42,  1.78s/it] 75%|███████▌  | 4447/5922 [2:11:40<43:20,  1.76s/it] 75%|███████▌  | 4448/5922 [2:11:42<44:52,  1.83s/it] 75%|███████▌  | 4449/5922 [2:11:44<45:35,  1.86s/it] 75%|███████▌  | 4450/5922 [2:11:46<45:59,  1.87s/it]                                                     {'loss': 0.1322, 'grad_norm': 0.4195591322057908, 'learning_rate': 3.809540401614106e-06, 'epoch': 2.25}
 75%|███████▌  | 4450/5922 [2:11:46<45:59,  1.87s/it] 75%|███████▌  | 4451/5922 [2:11:48<46:24,  1.89s/it] 75%|███████▌  | 4452/5922 [2:11:50<46:56,  1.92s/it] 75%|███████▌  | 4453/5922 [2:11:51<42:56,  1.75s/it] 75%|███████▌  | 4454/5922 [2:11:53<41:28,  1.70s/it] 75%|███████▌  | 4455/5922 [2:11:54<39:06,  1.60s/it] 75%|███████▌  | 4456/5922 [2:11:56<41:30,  1.70s/it] 75%|███████▌  | 4457/5922 [2:11:58<42:23,  1.74s/it] 75%|███████▌  | 4458/5922 [2:12:00<41:08,  1.69s/it] 75%|███████▌  | 4459/5922 [2:12:01<39:16,  1.61s/it] 75%|███████▌  | 4460/5922 [2:12:03<37:58,  1.56s/it] 75%|███████▌  | 4461/5922 [2:12:04<39:23,  1.62s/it] 75%|███████▌  | 4462/5922 [2:12:06<42:27,  1.74s/it] 75%|███████▌  | 4463/5922 [2:12:08<40:38,  1.67s/it] 75%|███████▌  | 4464/5922 [2:12:09<38:29,  1.58s/it] 75%|███████▌  | 4465/5922 [2:12:11<40:21,  1.66s/it] 75%|███████▌  | 4466/5922 [2:12:13<38:44,  1.60s/it] 75%|███████▌  | 4467/5922 [2:12:14<39:13,  1.62s/it] 75%|███████▌  | 4468/5922 [2:12:16<40:33,  1.67s/it] 75%|███████▌  | 4469/5922 [2:12:18<42:20,  1.75s/it] 75%|███████▌  | 4470/5922 [2:12:20<43:32,  1.80s/it] 75%|███████▌  | 4471/5922 [2:12:21<40:43,  1.68s/it] 76%|███████▌  | 4472/5922 [2:12:23<39:09,  1.62s/it] 76%|███████▌  | 4473/5922 [2:12:25<40:12,  1.66s/it] 76%|███████▌  | 4474/5922 [2:12:26<38:07,  1.58s/it] 76%|███████▌  | 4475/5922 [2:12:28<41:34,  1.72s/it]                                                     {'loss': 0.1242, 'grad_norm': 0.35480117019798957, 'learning_rate': 3.719780461135451e-06, 'epoch': 2.27}
 76%|███████▌  | 4475/5922 [2:12:28<41:34,  1.72s/it] 76%|███████▌  | 4476/5922 [2:12:29<39:02,  1.62s/it] 76%|███████▌  | 4477/5922 [2:12:31<41:19,  1.72s/it] 76%|███████▌  | 4478/5922 [2:12:34<46:57,  1.95s/it] 76%|███████▌  | 4479/5922 [2:12:35<42:44,  1.78s/it] 76%|███████▌  | 4480/5922 [2:12:37<43:52,  1.83s/it] 76%|███████▌  | 4481/5922 [2:12:39<40:58,  1.71s/it] 76%|███████▌  | 4482/5922 [2:12:40<38:29,  1.60s/it] 76%|███████▌  | 4483/5922 [2:12:41<37:36,  1.57s/it] 76%|███████▌  | 4484/5922 [2:12:44<43:54,  1.83s/it] 76%|███████▌  | 4485/5922 [2:12:46<43:42,  1.82s/it] 76%|███████▌  | 4486/5922 [2:12:48<44:14,  1.85s/it] 76%|███████▌  | 4487/5922 [2:12:49<41:10,  1.72s/it] 76%|███████▌  | 4488/5922 [2:12:50<39:23,  1.65s/it] 76%|███████▌  | 4489/5922 [2:12:53<42:41,  1.79s/it] 76%|███████▌  | 4490/5922 [2:12:54<39:38,  1.66s/it] 76%|███████▌  | 4491/5922 [2:12:56<40:27,  1.70s/it] 76%|███████▌  | 4492/5922 [2:12:57<38:15,  1.61s/it] 76%|███████▌  | 4493/5922 [2:12:59<42:28,  1.78s/it] 76%|███████▌  | 4494/5922 [2:13:01<40:52,  1.72s/it] 76%|███████▌  | 4495/5922 [2:13:03<43:55,  1.85s/it] 76%|███████▌  | 4496/5922 [2:13:05<43:44,  1.84s/it] 76%|███████▌  | 4497/5922 [2:13:06<41:49,  1.76s/it] 76%|███████▌  | 4498/5922 [2:13:08<43:08,  1.82s/it] 76%|███████▌  | 4499/5922 [2:13:11<46:22,  1.96s/it] 76%|███████▌  | 4500/5922 [2:13:13<49:57,  2.11s/it]                                                     {'loss': 0.1206, 'grad_norm': 0.49106950577902253, 'learning_rate': 3.631237618223322e-06, 'epoch': 2.28}
 76%|███████▌  | 4500/5922 [2:13:13<49:57,  2.11s/it][INFO|trainer.py:3993] 2025-08-30 16:02:04,811 >> Saving model checkpoint to saves/qwen3-1.7B/lora/sft/checkpoint-4500
[INFO|configuration_utils.py:696] 2025-08-30 16:02:04,823 >> loading configuration file /home/qianwenhao/LLM/Qwen3-1.7B/config.json
[INFO|configuration_utils.py:770] 2025-08-30 16:02:04,824 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "max_position_embeddings": 40960,
  "max_window_layers": 28,
  "model_type": "qwen3",
  "num_attention_heads": 16,
  "num_hidden_layers": 28,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|tokenization_utils_base.py:2356] 2025-08-30 16:02:04,839 >> chat template saved in saves/qwen3-1.7B/lora/sft/checkpoint-4500/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-08-30 16:02:04,840 >> tokenizer config file saved in saves/qwen3-1.7B/lora/sft/checkpoint-4500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-08-30 16:02:04,840 >> Special tokens file saved in saves/qwen3-1.7B/lora/sft/checkpoint-4500/special_tokens_map.json
[2025-08-30 16:02:05,000] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step4499 is about to be saved!
[2025-08-30 16:02:05,008] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: saves/qwen3-1.7B/lora/sft/checkpoint-4500/global_step4499/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-08-30 16:02:05,008] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-4500/global_step4499/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-08-30 16:02:05,014] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-4500/global_step4499/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-08-30 16:02:05,014] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-4500/global_step4499/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-08-30 16:02:05,026] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-4500/global_step4499/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-08-30 16:02:05,026] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved saves/qwen3-1.7B/lora/sft/checkpoint-4500/global_step4499/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-08-30 16:02:05,034] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4499 is ready now!
 76%|███████▌  | 4501/5922 [2:13:17<59:27,  2.51s/it] 76%|███████▌  | 4502/5922 [2:13:18<55:11,  2.33s/it] 76%|███████▌  | 4503/5922 [2:13:21<56:00,  2.37s/it] 76%|███████▌  | 4504/5922 [2:13:23<52:14,  2.21s/it] 76%|███████▌  | 4505/5922 [2:13:24<46:12,  1.96s/it] 76%|███████▌  | 4506/5922 [2:13:26<46:03,  1.95s/it] 76%|███████▌  | 4507/5922 [2:13:28<45:45,  1.94s/it] 76%|███████▌  | 4508/5922 [2:13:30<45:40,  1.94s/it] 76%|███████▌  | 4509/5922 [2:13:32<45:34,  1.94s/it] 76%|███████▌  | 4510/5922 [2:13:34<45:34,  1.94s/it] 76%|███████▌  | 4511/5922 [2:13:36<48:07,  2.05s/it] 76%|███████▌  | 4512/5922 [2:13:37<43:27,  1.85s/it] 76%|███████▌  | 4513/5922 [2:13:39<40:10,  1.71s/it] 76%|███████▌  | 4514/5922 [2:13:40<39:16,  1.67s/it] 76%|███████▌  | 4515/5922 [2:13:42<41:02,  1.75s/it] 76%|███████▋  | 4516/5922 [2:13:44<42:41,  1.82s/it] 76%|███████▋  | 4517/5922 [2:13:47<47:12,  2.02s/it] 76%|███████▋  | 4518/5922 [2:13:49<45:24,  1.94s/it] 76%|███████▋  | 4519/5922 [2:13:50<43:43,  1.87s/it] 76%|███████▋  | 4520/5922 [2:13:52<44:12,  1.89s/it] 76%|███████▋  | 4521/5922 [2:13:54<44:29,  1.91s/it] 76%|███████▋  | 4522/5922 [2:13:56<40:40,  1.74s/it] 76%|███████▋  | 4523/5922 [2:13:57<41:59,  1.80s/it] 76%|███████▋  | 4524/5922 [2:14:00<44:10,  1.90s/it] 76%|███████▋  | 4525/5922 [2:14:02<45:44,  1.96s/it]                                                     {'loss': 0.1364, 'grad_norm': 0.4304994696426151, 'learning_rate': 3.543927766946938e-06, 'epoch': 2.29}
 76%|███████▋  | 4525/5922 [2:14:02<45:44,  1.96s/it] 76%|███████▋  | 4526/5922 [2:14:04<45:51,  1.97s/it] 76%|███████▋  | 4527/5922 [2:14:05<44:25,  1.91s/it] 76%|███████▋  | 4528/5922 [2:14:07<44:22,  1.91s/it] 76%|███████▋  | 4529/5922 [2:14:09<44:19,  1.91s/it] 76%|███████▋  | 4530/5922 [2:14:12<47:32,  2.05s/it] 77%|███████▋  | 4531/5922 [2:14:13<42:46,  1.85s/it] 77%|███████▋  | 4532/5922 [2:14:15<42:37,  1.84s/it] 77%|███████▋  | 4533/5922 [2:14:16<39:18,  1.70s/it] 77%|███████▋  | 4534/5922 [2:14:18<37:33,  1.62s/it] 77%|███████▋  | 4535/5922 [2:14:19<35:58,  1.56s/it] 77%|███████▋  | 4536/5922 [2:14:21<38:28,  1.67s/it] 77%|███████▋  | 4537/5922 [2:14:22<36:28,  1.58s/it] 77%|███████▋  | 4538/5922 [2:14:24<39:11,  1.70s/it] 77%|███████▋  | 4539/5922 [2:14:27<44:27,  1.93s/it] 77%|███████▋  | 4540/5922 [2:14:28<42:32,  1.85s/it] 77%|███████▋  | 4541/5922 [2:14:30<43:04,  1.87s/it] 77%|███████▋  | 4542/5922 [2:14:32<43:19,  1.88s/it] 77%|███████▋  | 4543/5922 [2:14:35<46:10,  2.01s/it] 77%|███████▋  | 4544/5922 [2:14:36<43:16,  1.88s/it] 77%|███████▋  | 4545/5922 [2:14:38<42:58,  1.87s/it] 77%|███████▋  | 4546/5922 [2:14:39<39:52,  1.74s/it] 77%|███████▋  | 4547/5922 [2:14:42<42:42,  1.86s/it] 77%|███████▋  | 4548/5922 [2:14:44<46:10,  2.02s/it] 77%|███████▋  | 4549/5922 [2:14:45<41:41,  1.82s/it] 77%|███████▋  | 4550/5922 [2:14:47<42:13,  1.85s/it]                                                     {'loss': 0.1325, 'grad_norm': 0.4282318002598367, 'learning_rate': 3.457866580044756e-06, 'epoch': 2.31}
 77%|███████▋  | 4550/5922 [2:14:47<42:13,  1.85s/it] 77%|███████▋  | 4551/5922 [2:14:50<46:24,  2.03s/it] 77%|███████▋  | 4552/5922 [2:14:51<41:50,  1.83s/it] 77%|███████▋  | 4553/5922 [2:14:53<39:20,  1.72s/it] 77%|███████▋  | 4554/5922 [2:14:54<40:34,  1.78s/it] 77%|███████▋  | 4555/5922 [2:14:57<42:49,  1.88s/it] 77%|███████▋  | 4556/5922 [2:14:59<44:43,  1.96s/it] 77%|███████▋  | 4557/5922 [2:15:01<44:28,  1.95s/it] 77%|███████▋  | 4558/5922 [2:15:03<43:31,  1.91s/it] 77%|███████▋  | 4559/5922 [2:15:04<43:26,  1.91s/it] 77%|███████▋  | 4560/5922 [2:15:06<39:56,  1.76s/it] 77%|███████▋  | 4561/5922 [2:15:07<37:23,  1.65s/it] 77%|███████▋  | 4562/5922 [2:15:09<39:26,  1.74s/it] 77%|███████▋  | 4563/5922 [2:15:11<37:48,  1.67s/it] 77%|███████▋  | 4564/5922 [2:15:12<35:59,  1.59s/it] 77%|███████▋  | 4565/5922 [2:15:13<34:25,  1.52s/it] 77%|███████▋  | 4566/5922 [2:15:15<35:51,  1.59s/it] 77%|███████▋  | 4567/5922 [2:15:17<34:35,  1.53s/it] 77%|███████▋  | 4568/5922 [2:15:19<37:26,  1.66s/it] 77%|███████▋  | 4569/5922 [2:15:20<35:31,  1.58s/it] 77%|███████▋  | 4570/5922 [2:15:21<34:22,  1.53s/it] 77%|███████▋  | 4571/5922 [2:15:23<33:27,  1.49s/it] 77%|███████▋  | 4572/5922 [2:15:25<40:00,  1.78s/it] 77%|███████▋  | 4573/5922 [2:15:27<41:54,  1.86s/it] 77%|███████▋  | 4574/5922 [2:15:29<44:15,  1.97s/it] 77%|███████▋  | 4575/5922 [2:15:31<43:53,  1.95s/it]                                                     {'loss': 0.1319, 'grad_norm': 0.3745442628184003, 'learning_rate': 3.373069506111111e-06, 'epoch': 2.32}
 77%|███████▋  | 4575/5922 [2:15:31<43:53,  1.95s/it] 77%|███████▋  | 4576/5922 [2:15:33<42:33,  1.90s/it] 77%|███████▋  | 4577/5922 [2:15:35<39:04,  1.74s/it] 77%|███████▋  | 4578/5922 [2:15:36<37:12,  1.66s/it] 77%|███████▋  | 4579/5922 [2:15:37<35:23,  1.58s/it] 77%|███████▋  | 4580/5922 [2:15:39<37:38,  1.68s/it] 77%|███████▋  | 4581/5922 [2:15:41<35:33,  1.59s/it] 77%|███████▋  | 4582/5922 [2:15:43<37:50,  1.69s/it] 77%|███████▋  | 4583/5922 [2:15:45<40:23,  1.81s/it] 77%|███████▋  | 4584/5922 [2:15:46<37:32,  1.68s/it] 77%|███████▋  | 4585/5922 [2:15:48<39:00,  1.75s/it] 77%|███████▋  | 4586/5922 [2:15:50<43:13,  1.94s/it] 77%|███████▋  | 4587/5922 [2:15:52<39:21,  1.77s/it] 77%|███████▋  | 4588/5922 [2:15:54<41:53,  1.88s/it] 77%|███████▋  | 4589/5922 [2:15:56<42:07,  1.90s/it] 78%|███████▊  | 4590/5922 [2:15:57<39:20,  1.77s/it] 78%|███████▊  | 4591/5922 [2:15:59<40:01,  1.80s/it] 78%|███████▊  | 4592/5922 [2:16:01<37:20,  1.68s/it] 78%|███████▊  | 4593/5922 [2:16:03<39:00,  1.76s/it] 78%|███████▊  | 4594/5922 [2:16:04<36:18,  1.64s/it] 78%|███████▊  | 4595/5922 [2:16:06<38:01,  1.72s/it] 78%|███████▊  | 4596/5922 [2:16:07<36:40,  1.66s/it] 78%|███████▊  | 4597/5922 [2:16:09<37:40,  1.71s/it] 78%|███████▊  | 4598/5922 [2:16:11<38:53,  1.76s/it] 78%|███████▊  | 4599/5922 [2:16:13<37:22,  1.70s/it] 78%|███████▊  | 4600/5922 [2:16:14<36:07,  1.64s/it]                                                     {'loss': 0.1374, 'grad_norm': 0.4541707442183287, 'learning_rate': 3.2895517668230818e-06, 'epoch': 2.33}
 78%|███████▊  | 4600/5922 [2:16:14<36:07,  1.64s/it] 78%|███████▊  | 4601/5922 [2:16:16<38:10,  1.73s/it] 78%|███████▊  | 4602/5922 [2:16:18<36:30,  1.66s/it] 78%|███████▊  | 4603/5922 [2:16:19<35:53,  1.63s/it] 78%|███████▊  | 4604/5922 [2:16:21<38:02,  1.73s/it] 78%|███████▊  | 4605/5922 [2:16:23<41:00,  1.87s/it] 78%|███████▊  | 4606/5922 [2:16:25<37:40,  1.72s/it] 78%|███████▊  | 4607/5922 [2:16:26<36:38,  1.67s/it] 78%|███████▊  | 4608/5922 [2:16:28<34:38,  1.58s/it] 78%|███████▊  | 4609/5922 [2:16:29<36:31,  1.67s/it] 78%|███████▊  | 4610/5922 [2:16:31<38:11,  1.75s/it] 78%|███████▊  | 4611/5922 [2:16:33<35:43,  1.64s/it] 78%|███████▊  | 4612/5922 [2:16:35<37:29,  1.72s/it] 78%|███████▊  | 4613/5922 [2:16:36<35:20,  1.62s/it] 78%|███████▊  | 4614/5922 [2:16:38<38:02,  1.74s/it] 78%|███████▊  | 4615/5922 [2:16:40<40:07,  1.84s/it] 78%|███████▊  | 4616/5922 [2:16:42<40:43,  1.87s/it] 78%|███████▊  | 4617/5922 [2:16:45<44:32,  2.05s/it] 78%|███████▊  | 4618/5922 [2:16:46<43:32,  2.00s/it] 78%|███████▊  | 4619/5922 [2:16:48<43:40,  2.01s/it] 78%|███████▊  | 4620/5922 [2:16:51<44:58,  2.07s/it] 78%|███████▊  | 4621/5922 [2:16:52<40:17,  1.86s/it] 78%|███████▊  | 4622/5922 [2:16:54<39:53,  1.84s/it] 78%|███████▊  | 4623/5922 [2:16:55<36:52,  1.70s/it] 78%|███████▊  | 4624/5922 [2:16:57<34:47,  1.61s/it] 78%|███████▊  | 4625/5922 [2:16:59<40:04,  1.85s/it]                                                     {'loss': 0.1244, 'grad_norm': 0.4090357295773668, 'learning_rate': 3.2073283542080837e-06, 'epoch': 2.34}
 78%|███████▊  | 4625/5922 [2:16:59<40:04,  1.85s/it] 78%|███████▊  | 4626/5922 [2:17:01<43:34,  2.02s/it] 78%|███████▊  | 4627/5922 [2:17:03<43:04,  2.00s/it] 78%|███████▊  | 4628/5922 [2:17:05<42:41,  1.98s/it] 78%|███████▊  | 4629/5922 [2:17:07<40:02,  1.86s/it] 78%|███████▊  | 4630/5922 [2:17:08<37:05,  1.72s/it] 78%|███████▊  | 4631/5922 [2:17:10<34:45,  1.62s/it] 78%|███████▊  | 4632/5922 [2:17:12<37:01,  1.72s/it] 78%|███████▊  | 4633/5922 [2:17:14<38:30,  1.79s/it] 78%|███████▊  | 4634/5922 [2:17:16<42:55,  2.00s/it] 78%|███████▊  | 4635/5922 [2:17:17<38:45,  1.81s/it] 78%|███████▊  | 4636/5922 [2:17:19<38:50,  1.81s/it] 78%|███████▊  | 4637/5922 [2:17:21<37:18,  1.74s/it] 78%|███████▊  | 4638/5922 [2:17:23<37:25,  1.75s/it] 78%|███████▊  | 4639/5922 [2:17:24<35:02,  1.64s/it] 78%|███████▊  | 4640/5922 [2:17:25<33:10,  1.55s/it] 78%|███████▊  | 4641/5922 [2:17:27<36:32,  1.71s/it] 78%|███████▊  | 4642/5922 [2:17:29<36:15,  1.70s/it] 78%|███████▊  | 4643/5922 [2:17:31<37:32,  1.76s/it] 78%|███████▊  | 4644/5922 [2:17:32<35:08,  1.65s/it] 78%|███████▊  | 4645/5922 [2:17:34<37:03,  1.74s/it] 78%|███████▊  | 4646/5922 [2:17:36<38:14,  1.80s/it] 78%|███████▊  | 4647/5922 [2:17:38<35:32,  1.67s/it] 78%|███████▊  | 4648/5922 [2:17:39<33:52,  1.60s/it] 79%|███████▊  | 4649/5922 [2:17:41<38:15,  1.80s/it] 79%|███████▊  | 4650/5922 [2:17:43<38:48,  1.83s/it]                                                     {'loss': 0.1276, 'grad_norm': 0.49928560928997584, 'learning_rate': 3.1264140279527156e-06, 'epoch': 2.36}
 79%|███████▊  | 4650/5922 [2:17:43<38:48,  1.83s/it] 79%|███████▊  | 4651/5922 [2:17:45<39:34,  1.87s/it] 79%|███████▊  | 4652/5922 [2:17:47<39:14,  1.85s/it] 79%|███████▊  | 4653/5922 [2:17:49<43:03,  2.04s/it] 79%|███████▊  | 4654/5922 [2:17:51<38:55,  1.84s/it] 79%|███████▊  | 4655/5922 [2:17:52<35:51,  1.70s/it] 79%|███████▊  | 4656/5922 [2:17:54<37:22,  1.77s/it] 79%|███████▊  | 4657/5922 [2:17:56<40:44,  1.93s/it] 79%|███████▊  | 4658/5922 [2:17:59<43:51,  2.08s/it] 79%|███████▊  | 4659/5922 [2:18:00<40:30,  1.92s/it] 79%|███████▊  | 4660/5922 [2:18:02<40:30,  1.93s/it] 79%|███████▊  | 4661/5922 [2:18:04<37:12,  1.77s/it] 79%|███████▊  | 4662/5922 [2:18:06<38:08,  1.82s/it] 79%|███████▊  | 4663/5922 [2:18:07<35:20,  1.68s/it] 79%|███████▉  | 4664/5922 [2:18:09<34:35,  1.65s/it] 79%|███████▉  | 4665/5922 [2:18:10<32:53,  1.57s/it] 79%|███████▉  | 4666/5922 [2:18:11<31:45,  1.52s/it] 79%|███████▉  | 4667/5922 [2:18:13<34:04,  1.63s/it] 79%|███████▉  | 4668/5922 [2:18:15<35:54,  1.72s/it] 79%|███████▉  | 4669/5922 [2:18:17<33:47,  1.62s/it] 79%|███████▉  | 4670/5922 [2:18:18<33:13,  1.59s/it] 79%|███████▉  | 4671/5922 [2:18:20<31:55,  1.53s/it] 79%|███████▉  | 4672/5922 [2:18:21<33:56,  1.63s/it] 79%|███████▉  | 4673/5922 [2:18:23<32:19,  1.55s/it] 79%|███████▉  | 4674/5922 [2:18:25<34:36,  1.66s/it] 79%|███████▉  | 4675/5922 [2:18:26<32:48,  1.58s/it]                                                     {'loss': 0.1355, 'grad_norm': 0.45987690283559385, 'learning_rate': 3.0468233127532605e-06, 'epoch': 2.37}
 79%|███████▉  | 4675/5922 [2:18:26<32:48,  1.58s/it] 79%|███████▉  | 4676/5922 [2:18:28<34:58,  1.68s/it] 79%|███████▉  | 4677/5922 [2:18:29<33:12,  1.60s/it] 79%|███████▉  | 4678/5922 [2:18:32<36:23,  1.76s/it] 79%|███████▉  | 4679/5922 [2:18:33<34:01,  1.64s/it] 79%|███████▉  | 4680/5922 [2:18:35<35:02,  1.69s/it] 79%|███████▉  | 4681/5922 [2:18:36<34:02,  1.65s/it] 79%|███████▉  | 4682/5922 [2:18:38<32:31,  1.57s/it] 79%|███████▉  | 4683/5922 [2:18:39<31:22,  1.52s/it] 79%|███████▉  | 4684/5922 [2:18:41<31:16,  1.52s/it] 79%|███████▉  | 4685/5922 [2:18:42<30:21,  1.47s/it] 79%|███████▉  | 4686/5922 [2:18:44<36:34,  1.78s/it] 79%|███████▉  | 4687/5922 [2:18:46<33:59,  1.65s/it] 79%|███████▉  | 4688/5922 [2:18:48<39:06,  1.90s/it] 79%|███████▉  | 4689/5922 [2:18:50<36:57,  1.80s/it] 79%|███████▉  | 4690/5922 [2:18:51<34:30,  1.68s/it] 79%|███████▉  | 4691/5922 [2:18:53<35:52,  1.75s/it] 79%|███████▉  | 4692/5922 [2:18:55<37:03,  1.81s/it] 79%|███████▉  | 4693/5922 [2:18:57<38:21,  1.87s/it] 79%|███████▉  | 4694/5922 [2:18:59<38:53,  1.90s/it] 79%|███████▉  | 4695/5922 [2:19:01<36:01,  1.76s/it] 79%|███████▉  | 4696/5922 [2:19:02<35:28,  1.74s/it] 79%|███████▉  | 4697/5922 [2:19:04<35:57,  1.76s/it] 79%|███████▉  | 4698/5922 [2:19:06<39:37,  1.94s/it] 79%|███████▉  | 4699/5922 [2:19:08<38:45,  1.90s/it] 79%|███████▉  | 4700/5922 [2:19:10<39:13,  1.93s/it]                                                     {'loss': 0.1329, 'grad_norm': 0.4656682479029636, 'learning_rate': 2.968570495708425e-06, 'epoch': 2.38}
 79%|███████▉  | 4700/5922 [2:19:10<39:13,  1.93s/it] 79%|███████▉  | 4701/5922 [2:19:12<35:51,  1.76s/it] 79%|███████▉  | 4702/5922 [2:19:14<40:01,  1.97s/it] 79%|███████▉  | 4703/5922 [2:19:16<39:42,  1.95s/it] 79%|███████▉  | 4704/5922 [2:19:18<42:43,  2.10s/it] 79%|███████▉  | 4705/5922 [2:19:20<41:15,  2.03s/it] 79%|███████▉  | 4706/5922 [2:19:22<37:32,  1.85s/it] 79%|███████▉  | 4707/5922 [2:19:24<37:20,  1.84s/it] 80%|███████▉  | 4708/5922 [2:19:25<37:58,  1.88s/it] 80%|███████▉  | 4709/5922 [2:19:27<36:22,  1.80s/it] 80%|███████▉  | 4710/5922 [2:19:29<37:06,  1.84s/it] 80%|███████▉  | 4711/5922 [2:19:30<34:28,  1.71s/it] 80%|███████▉  | 4712/5922 [2:19:32<32:44,  1.62s/it] 80%|███████▉  | 4713/5922 [2:19:33<31:27,  1.56s/it] 80%|███████▉  | 4714/5922 [2:19:35<30:25,  1.51s/it] 80%|███████▉  | 4715/5922 [2:19:36<32:18,  1.61s/it] 80%|███████▉  | 4716/5922 [2:19:38<31:05,  1.55s/it] 80%|███████▉  | 4717/5922 [2:19:40<33:22,  1.66s/it] 80%|███████▉  | 4718/5922 [2:19:41<31:55,  1.59s/it] 80%|███████▉  | 4719/5922 [2:19:43<30:52,  1.54s/it] 80%|███████▉  | 4720/5922 [2:19:44<30:03,  1.50s/it] 80%|███████▉  | 4721/5922 [2:19:45<29:22,  1.47s/it] 80%|███████▉  | 4722/5922 [2:19:47<29:05,  1.45s/it] 80%|███████▉  | 4723/5922 [2:19:49<30:46,  1.54s/it] 80%|███████▉  | 4724/5922 [2:19:51<33:38,  1.68s/it] 80%|███████▉  | 4725/5922 [2:19:52<32:01,  1.60s/it]                                                     {'loss': 0.1292, 'grad_norm': 0.3987270103793462, 'learning_rate': 2.8916696237546913e-06, 'epoch': 2.39}
 80%|███████▉  | 4725/5922 [2:19:52<32:01,  1.60s/it] 80%|███████▉  | 4726/5922 [2:19:53<30:49,  1.55s/it] 80%|███████▉  | 4727/5922 [2:19:56<34:27,  1.73s/it] 80%|███████▉  | 4728/5922 [2:19:57<32:36,  1.64s/it] 80%|███████▉  | 4729/5922 [2:19:59<31:28,  1.58s/it] 80%|███████▉  | 4730/5922 [2:20:00<33:48,  1.70s/it] 80%|███████▉  | 4731/5922 [2:20:02<34:31,  1.74s/it] 80%|███████▉  | 4732/5922 [2:20:04<32:59,  1.66s/it] 80%|███████▉  | 4733/5922 [2:20:06<37:49,  1.91s/it] 80%|███████▉  | 4734/5922 [2:20:08<34:51,  1.76s/it] 80%|███████▉  | 4735/5922 [2:20:10<35:04,  1.77s/it] 80%|███████▉  | 4736/5922 [2:20:12<37:38,  1.90s/it] 80%|███████▉  | 4737/5922 [2:20:14<37:32,  1.90s/it] 80%|████████  | 4738/5922 [2:20:16<40:23,  2.05s/it] 80%|████████  | 4739/5922 [2:20:17<36:53,  1.87s/it] 80%|████████  | 4740/5922 [2:20:19<37:08,  1.89s/it] 80%|████████  | 4741/5922 [2:20:21<34:24,  1.75s/it] 80%|████████  | 4742/5922 [2:20:23<36:27,  1.85s/it] 80%|████████  | 4743/5922 [2:20:25<36:24,  1.85s/it] 80%|████████  | 4744/5922 [2:20:27<36:08,  1.84s/it] 80%|████████  | 4745/5922 [2:20:28<36:36,  1.87s/it] 80%|████████  | 4746/5922 [2:20:30<34:14,  1.75s/it] 80%|████████  | 4747/5922 [2:20:32<35:23,  1.81s/it] 80%|████████  | 4748/5922 [2:20:34<34:44,  1.78s/it] 80%|████████  | 4749/5922 [2:20:36<35:45,  1.83s/it] 80%|████████  | 4750/5922 [2:20:38<36:29,  1.87s/it]                                                     {'loss': 0.1277, 'grad_norm': 0.4425820160275363, 'learning_rate': 2.8161345011447966e-06, 'epoch': 2.41}
 80%|████████  | 4750/5922 [2:20:38<36:29,  1.87s/it] 80%|████████  | 4751/5922 [2:20:39<35:22,  1.81s/it] 80%|████████  | 4752/5922 [2:20:41<33:52,  1.74s/it] 80%|████████  | 4753/5922 [2:20:43<37:36,  1.93s/it] 80%|████████  | 4754/5922 [2:20:45<34:59,  1.80s/it] 80%|████████  | 4755/5922 [2:20:46<32:48,  1.69s/it] 80%|████████  | 4756/5922 [2:20:47<31:11,  1.60s/it] 80%|████████  | 4757/5922 [2:20:49<32:04,  1.65s/it] 80%|████████  | 4758/5922 [2:20:52<36:41,  1.89s/it] 80%|████████  | 4759/5922 [2:20:54<39:54,  2.06s/it] 80%|████████  | 4760/5922 [2:20:56<39:25,  2.04s/it] 80%|████████  | 4761/5922 [2:20:58<36:17,  1.88s/it] 80%|████████  | 4762/5922 [2:21:00<39:46,  2.06s/it] 80%|████████  | 4763/5922 [2:21:02<39:04,  2.02s/it] 80%|████████  | 4764/5922 [2:21:04<40:54,  2.12s/it] 80%|████████  | 4765/5922 [2:21:06<37:43,  1.96s/it] 80%|████████  | 4766/5922 [2:21:08<37:40,  1.96s/it] 80%|████████  | 4767/5922 [2:21:10<37:34,  1.95s/it] 81%|████████  | 4768/5922 [2:21:12<37:57,  1.97s/it] 81%|████████  | 4769/5922 [2:21:14<37:42,  1.96s/it] 81%|████████  | 4770/5922 [2:21:16<37:29,  1.95s/it] 81%|████████  | 4771/5922 [2:21:17<34:28,  1.80s/it] 81%|████████  | 4772/5922 [2:21:19<35:05,  1.83s/it] 81%|████████  | 4773/5922 [2:21:21<35:42,  1.87s/it] 81%|████████  | 4774/5922 [2:21:23<34:11,  1.79s/it] 81%|████████  | 4775/5922 [2:21:24<33:11,  1.74s/it]                                                     {'loss': 0.1378, 'grad_norm': 0.396092673290087, 'learning_rate': 2.741978686969767e-06, 'epoch': 2.42}
 81%|████████  | 4775/5922 [2:21:24<33:11,  1.74s/it] 81%|████████  | 4776/5922 [2:21:27<36:36,  1.92s/it] 81%|████████  | 4777/5922 [2:21:29<36:28,  1.91s/it] 81%|████████  | 4778/5922 [2:21:30<36:27,  1.91s/it] 81%|████████  | 4779/5922 [2:21:32<33:32,  1.76s/it] 81%|████████  | 4780/5922 [2:21:34<33:20,  1.75s/it] 81%|████████  | 4781/5922 [2:21:35<34:13,  1.80s/it] 81%|████████  | 4782/5922 [2:21:37<35:25,  1.86s/it] 81%|████████  | 4783/5922 [2:21:39<35:46,  1.88s/it] 81%|████████  | 4784/5922 [2:21:41<33:01,  1.74s/it] 81%|████████  | 4785/5922 [2:21:43<34:09,  1.80s/it] 81%|████████  | 4786/5922 [2:21:45<35:01,  1.85s/it] 81%|████████  | 4787/5922 [2:21:47<34:55,  1.85s/it] 81%|████████  | 4788/5922 [2:21:48<35:22,  1.87s/it] 81%|████████  | 4789/5922 [2:21:50<32:34,  1.73s/it] 81%|████████  | 4790/5922 [2:21:52<33:26,  1.77s/it] 81%|████████  | 4791/5922 [2:21:53<33:00,  1.75s/it] 81%|████████  | 4792/5922 [2:21:55<33:45,  1.79s/it] 81%|████████  | 4793/5922 [2:21:57<31:48,  1.69s/it] 81%|████████  | 4794/5922 [2:21:58<30:13,  1.61s/it] 81%|████████  | 4795/5922 [2:22:00<31:32,  1.68s/it] 81%|████████  | 4796/5922 [2:22:02<33:01,  1.76s/it] 81%|████████  | 4797/5922 [2:22:04<36:55,  1.97s/it] 81%|████████  | 4798/5922 [2:22:06<34:34,  1.85s/it] 81%|████████  | 4799/5922 [2:22:07<32:05,  1.71s/it] 81%|████████  | 4800/5922 [2:22:09<30:23,  1.63s/it]                                                     {'loss': 0.1392, 'grad_norm': 0.4873466110123866, 'learning_rate': 2.6692154927249718e-06, 'epoch': 2.43}
 81%|████████  | 4800/5922 [2:22:09<30:23,  1.63s/it] 81%|████████  | 4801/5922 [2:22:11<31:46,  1.70s/it] 81%|████████  | 4802/5922 [2:22:12<30:49,  1.65s/it] 81%|████████  | 4803/5922 [2:22:14<29:26,  1.58s/it] 81%|████████  | 4804/5922 [2:22:16<34:22,  1.84s/it] 81%|████████  | 4805/5922 [2:22:18<36:29,  1.96s/it] 81%|████████  | 4806/5922 [2:22:20<33:13,  1.79s/it] 81%|████████  | 4807/5922 [2:22:21<32:19,  1.74s/it] 81%|████████  | 4808/5922 [2:22:23<33:36,  1.81s/it] 81%|████████  | 4809/5922 [2:22:25<32:13,  1.74s/it] 81%|████████  | 4810/5922 [2:22:27<33:26,  1.80s/it] 81%|████████  | 4811/5922 [2:22:28<31:53,  1.72s/it] 81%|████████▏ | 4812/5922 [2:22:31<35:54,  1.94s/it] 81%|████████▏ | 4813/5922 [2:22:33<35:46,  1.94s/it] 81%|████████▏ | 4814/5922 [2:22:34<32:51,  1.78s/it] 81%|████████▏ | 4815/5922 [2:22:36<34:18,  1.86s/it] 81%|████████▏ | 4816/5922 [2:22:38<33:13,  1.80s/it] 81%|████████▏ | 4817/5922 [2:22:40<36:32,  1.98s/it] 81%|████████▏ | 4818/5922 [2:22:42<36:15,  1.97s/it] 81%|████████▏ | 4819/5922 [2:22:44<36:07,  1.97s/it] 81%|████████▏ | 4820/5922 [2:22:46<33:03,  1.80s/it] 81%|████████▏ | 4821/5922 [2:22:47<31:11,  1.70s/it] 81%|████████▏ | 4822/5922 [2:22:50<35:10,  1.92s/it] 81%|████████▏ | 4823/5922 [2:22:51<34:08,  1.86s/it] 81%|████████▏ | 4824/5922 [2:22:53<34:34,  1.89s/it] 81%|████████▏ | 4825/5922 [2:22:55<33:56,  1.86s/it]                                                     {'loss': 0.1364, 'grad_norm': 0.4429984078700232, 'learning_rate': 2.5978579799206027e-06, 'epoch': 2.44}
 81%|████████▏ | 4825/5922 [2:22:55<33:56,  1.86s/it] 81%|████████▏ | 4826/5922 [2:22:56<31:32,  1.73s/it] 82%|████████▏ | 4827/5922 [2:22:58<30:35,  1.68s/it] 82%|████████▏ | 4828/5922 [2:22:59<29:15,  1.60s/it] 82%|████████▏ | 4829/5922 [2:23:02<33:23,  1.83s/it] 82%|████████▏ | 4830/5922 [2:23:03<31:11,  1.71s/it] 82%|████████▏ | 4831/5922 [2:23:05<29:28,  1.62s/it] 82%|████████▏ | 4832/5922 [2:23:06<30:27,  1.68s/it] 82%|████████▏ | 4833/5922 [2:23:08<29:38,  1.63s/it] 82%|████████▏ | 4834/5922 [2:23:10<31:00,  1.71s/it] 82%|████████▏ | 4835/5922 [2:23:12<30:49,  1.70s/it] 82%|████████▏ | 4836/5922 [2:23:14<32:42,  1.81s/it] 82%|████████▏ | 4837/5922 [2:23:15<30:29,  1.69s/it] 82%|████████▏ | 4838/5922 [2:23:17<34:38,  1.92s/it] 82%|████████▏ | 4839/5922 [2:23:19<31:51,  1.77s/it] 82%|████████▏ | 4840/5922 [2:23:21<32:38,  1.81s/it] 82%|████████▏ | 4841/5922 [2:23:22<30:21,  1.68s/it] 82%|████████▏ | 4842/5922 [2:23:24<28:48,  1.60s/it] 82%|████████▏ | 4843/5922 [2:23:25<28:48,  1.60s/it] 82%|████████▏ | 4844/5922 [2:23:27<29:43,  1.65s/it] 82%|████████▏ | 4845/5922 [2:23:28<28:30,  1.59s/it] 82%|████████▏ | 4846/5922 [2:23:30<30:15,  1.69s/it] 82%|████████▏ | 4847/5922 [2:23:32<31:38,  1.77s/it] 82%|████████▏ | 4848/5922 [2:23:34<33:25,  1.87s/it] 82%|████████▏ | 4849/5922 [2:23:36<30:54,  1.73s/it] 82%|████████▏ | 4850/5922 [2:23:38<32:02,  1.79s/it]                                                     {'loss': 0.1261, 'grad_norm': 0.4558017411595716, 'learning_rate': 2.5279189577370623e-06, 'epoch': 2.46}
 82%|████████▏ | 4850/5922 [2:23:38<32:02,  1.79s/it] 82%|████████▏ | 4851/5922 [2:23:40<34:04,  1.91s/it] 82%|████████▏ | 4852/5922 [2:23:41<32:14,  1.81s/it] 82%|████████▏ | 4853/5922 [2:23:44<35:34,  2.00s/it] 82%|████████▏ | 4854/5922 [2:23:45<32:18,  1.81s/it] 82%|████████▏ | 4855/5922 [2:23:47<32:59,  1.86s/it] 82%|████████▏ | 4856/5922 [2:23:49<32:50,  1.85s/it] 82%|████████▏ | 4857/5922 [2:23:50<30:31,  1.72s/it] 82%|████████▏ | 4858/5922 [2:23:53<34:22,  1.94s/it] 82%|████████▏ | 4859/5922 [2:23:54<31:34,  1.78s/it] 82%|████████▏ | 4860/5922 [2:23:56<29:36,  1.67s/it] 82%|████████▏ | 4861/5922 [2:23:58<31:48,  1.80s/it] 82%|████████▏ | 4862/5922 [2:24:00<34:24,  1.95s/it] 82%|████████▏ | 4863/5922 [2:24:02<34:14,  1.94s/it] 82%|████████▏ | 4864/5922 [2:24:03<31:22,  1.78s/it] 82%|████████▏ | 4865/5922 [2:24:06<34:06,  1.94s/it] 82%|████████▏ | 4866/5922 [2:24:07<32:03,  1.82s/it] 82%|████████▏ | 4867/5922 [2:24:09<30:30,  1.74s/it] 82%|████████▏ | 4868/5922 [2:24:11<30:22,  1.73s/it] 82%|████████▏ | 4869/5922 [2:24:12<30:35,  1.74s/it] 82%|████████▏ | 4870/5922 [2:24:14<28:52,  1.65s/it] 82%|████████▏ | 4871/5922 [2:24:15<28:19,  1.62s/it] 82%|████████▏ | 4872/5922 [2:24:18<32:50,  1.88s/it] 82%|████████▏ | 4873/5922 [2:24:20<33:47,  1.93s/it] 82%|████████▏ | 4874/5922 [2:24:21<31:00,  1.77s/it] 82%|████████▏ | 4875/5922 [2:24:23<31:51,  1.83s/it]                                                     {'loss': 0.1275, 'grad_norm': 0.4487219740291419, 'learning_rate': 2.4594109807255957e-06, 'epoch': 2.47}
 82%|████████▏ | 4875/5922 [2:24:23<31:51,  1.83s/it] 82%|████████▏ | 4876/5922 [2:24:25<32:30,  1.87s/it] 82%|████████▏ | 4877/5922 [2:24:27<33:44,  1.94s/it] 82%|████████▏ | 4878/5922 [2:24:29<33:14,  1.91s/it] 82%|████████▏ | 4879/5922 [2:24:31<30:31,  1.76s/it] 82%|████████▏ | 4880/5922 [2:24:32<31:29,  1.81s/it] 82%|████████▏ | 4881/5922 [2:24:34<29:46,  1.72s/it] 82%|████████▏ | 4882/5922 [2:24:36<29:42,  1.71s/it] 82%|████████▏ | 4883/5922 [2:24:37<28:29,  1.65s/it] 82%|████████▏ | 4884/5922 [2:24:39<30:20,  1.75s/it] 82%|████████▏ | 4885/5922 [2:24:41<31:21,  1.81s/it] 83%|████████▎ | 4886/5922 [2:24:43<31:47,  1.84s/it] 83%|████████▎ | 4887/5922 [2:24:44<29:39,  1.72s/it] 83%|████████▎ | 4888/5922 [2:24:46<28:06,  1.63s/it] 83%|████████▎ | 4889/5922 [2:24:47<27:02,  1.57s/it] 83%|████████▎ | 4890/5922 [2:24:49<29:22,  1.71s/it] 83%|████████▎ | 4891/5922 [2:24:51<30:34,  1.78s/it] 83%|████████▎ | 4892/5922 [2:24:53<30:45,  1.79s/it] 83%|████████▎ | 4893/5922 [2:24:55<32:00,  1.87s/it] 83%|████████▎ | 4894/5922 [2:24:57<29:40,  1.73s/it] 83%|████████▎ | 4895/5922 [2:24:59<30:38,  1.79s/it] 83%|████████▎ | 4896/5922 [2:25:00<29:40,  1.74s/it] 83%|████████▎ | 4897/5922 [2:25:03<33:27,  1.96s/it] 83%|████████▎ | 4898/5922 [2:25:04<32:32,  1.91s/it] 83%|████████▎ | 4899/5922 [2:25:06<32:47,  1.92s/it] 83%|████████▎ | 4900/5922 [2:25:09<34:44,  2.04s/it]                                                     {'loss': 0.1322, 'grad_norm': 0.40786227327455177, 'learning_rate': 2.392346346554687e-06, 'epoch': 2.48}
 83%|████████▎ | 4900/5922 [2:25:09<34:44,  2.04s/it] 83%|████████▎ | 4901/5922 [2:25:10<31:47,  1.87s/it] 83%|████████▎ | 4902/5922 [2:25:13<34:34,  2.03s/it] 83%|████████▎ | 4903/5922 [2:25:14<31:10,  1.84s/it] 83%|████████▎ | 4904/5922 [2:25:15<29:04,  1.71s/it] 83%|████████▎ | 4905/5922 [2:25:18<32:50,  1.94s/it] 83%|████████▎ | 4906/5922 [2:25:20<35:29,  2.10s/it] 83%|████████▎ | 4907/5922 [2:25:22<32:22,  1.91s/it] 83%|████████▎ | 4908/5922 [2:25:24<31:55,  1.89s/it] 83%|████████▎ | 4909/5922 [2:25:26<32:08,  1.90s/it] 83%|████████▎ | 4910/5922 [2:25:27<29:52,  1.77s/it] 83%|████████▎ | 4911/5922 [2:25:29<30:44,  1.82s/it] 83%|████████▎ | 4912/5922 [2:25:30<28:40,  1.70s/it] 83%|████████▎ | 4913/5922 [2:25:32<29:04,  1.73s/it] 83%|████████▎ | 4914/5922 [2:25:34<29:01,  1.73s/it] 83%|████████▎ | 4915/5922 [2:25:36<30:05,  1.79s/it] 83%|████████▎ | 4916/5922 [2:25:38<30:18,  1.81s/it] 83%|████████▎ | 4917/5922 [2:25:40<30:43,  1.83s/it] 83%|████████▎ | 4918/5922 [2:25:41<28:40,  1.71s/it] 83%|████████▎ | 4919/5922 [2:25:42<26:54,  1.61s/it] 83%|████████▎ | 4920/5922 [2:25:44<25:38,  1.54s/it] 83%|████████▎ | 4921/5922 [2:25:46<27:35,  1.65s/it] 83%|████████▎ | 4922/5922 [2:25:47<26:21,  1.58s/it] 83%|████████▎ | 4923/5922 [2:25:49<28:03,  1.69s/it] 83%|████████▎ | 4924/5922 [2:25:51<27:40,  1.66s/it] 83%|████████▎ | 4925/5922 [2:25:53<28:55,  1.74s/it]                                                     {'loss': 0.1448, 'grad_norm': 0.4137196997840979, 'learning_rate': 2.326737093802523e-06, 'epoch': 2.5}
 83%|████████▎ | 4925/5922 [2:25:53<28:55,  1.74s/it] 83%|████████▎ | 4926/5922 [2:25:54<27:57,  1.68s/it] 83%|████████▎ | 4927/5922 [2:25:56<27:09,  1.64s/it] 83%|████████▎ | 4928/5922 [2:25:58<28:29,  1.72s/it] 83%|████████▎ | 4929/5922 [2:25:59<26:49,  1.62s/it] 83%|████████▎ | 4930/5922 [2:26:00<25:35,  1.55s/it] 83%|████████▎ | 4931/5922 [2:26:02<24:58,  1.51s/it] 83%|████████▎ | 4932/5922 [2:26:04<26:58,  1.63s/it] 83%|████████▎ | 4933/5922 [2:26:06<31:07,  1.89s/it] 83%|████████▎ | 4934/5922 [2:26:08<31:24,  1.91s/it] 83%|████████▎ | 4935/5922 [2:26:10<30:38,  1.86s/it] 83%|████████▎ | 4936/5922 [2:26:11<28:37,  1.74s/it] 83%|████████▎ | 4937/5922 [2:26:13<26:41,  1.63s/it] 83%|████████▎ | 4938/5922 [2:26:15<30:06,  1.84s/it] 83%|████████▎ | 4939/5922 [2:26:17<31:22,  1.92s/it] 83%|████████▎ | 4940/5922 [2:26:19<31:44,  1.94s/it] 83%|████████▎ | 4941/5922 [2:26:21<31:40,  1.94s/it] 83%|████████▎ | 4942/5922 [2:26:23<30:29,  1.87s/it] 83%|████████▎ | 4943/5922 [2:26:24<28:06,  1.72s/it] 83%|████████▎ | 4944/5922 [2:26:25<26:33,  1.63s/it] 84%|████████▎ | 4945/5922 [2:26:27<27:56,  1.72s/it] 84%|████████▎ | 4946/5922 [2:26:29<27:55,  1.72s/it] 84%|████████▎ | 4947/5922 [2:26:31<28:57,  1.78s/it] 84%|████████▎ | 4948/5922 [2:26:32<27:03,  1.67s/it] 84%|████████▎ | 4949/5922 [2:26:34<28:21,  1.75s/it] 84%|████████▎ | 4950/5922 [2:26:36<29:20,  1.81s/it]                                                     {'loss': 0.1257, 'grad_norm': 0.3973368235179451, 'learning_rate': 2.2625949997959902e-06, 'epoch': 2.51}
 84%|████████▎ | 4950/5922 [2:26:36<29:20,  1.81s/it] 84%|████████▎ | 4951/5922 [2:26:38<30:34,  1.89s/it] 84%|████████▎ | 4952/5922 [2:26:40<30:12,  1.87s/it] 84%|████████▎ | 4953/5922 [2:26:42<28:03,  1.74s/it] 84%|████████▎ | 4954/5922 [2:26:43<26:29,  1.64s/it] 84%|████████▎ | 4955/5922 [2:26:45<26:28,  1.64s/it] 84%|████████▎ | 4956/5922 [2:26:46<26:51,  1.67s/it] 84%|████████▎ | 4957/5922 [2:26:48<26:56,  1.68s/it] 84%|████████▎ | 4958/5922 [2:26:50<27:58,  1.74s/it] 84%|████████▎ | 4959/5922 [2:26:52<28:00,  1.74s/it] 84%|████████▍ | 4960/5922 [2:26:54<30:24,  1.90s/it] 84%|████████▍ | 4961/5922 [2:26:56<31:57,  1.99s/it] 84%|████████▍ | 4962/5922 [2:26:58<30:49,  1.93s/it] 84%|████████▍ | 4963/5922 [2:27:00<32:18,  2.02s/it] 84%|████████▍ | 4964/5922 [2:27:02<31:55,  2.00s/it] 84%|████████▍ | 4965/5922 [2:27:04<28:55,  1.81s/it] 84%|████████▍ | 4966/5922 [2:27:05<29:00,  1.82s/it] 84%|████████▍ | 4967/5922 [2:27:07<27:00,  1.70s/it] 84%|████████▍ | 4968/5922 [2:27:09<27:54,  1.76s/it] 84%|████████▍ | 4969/5922 [2:27:11<28:47,  1.81s/it] 84%|████████▍ | 4970/5922 [2:27:12<27:17,  1.72s/it] 84%|████████▍ | 4971/5922 [2:27:14<28:09,  1.78s/it] 84%|████████▍ | 4972/5922 [2:27:16<28:15,  1.78s/it] 84%|████████▍ | 4973/5922 [2:27:18<28:55,  1.83s/it] 84%|████████▍ | 4974/5922 [2:27:19<27:20,  1.73s/it] 84%|████████▍ | 4975/5922 [2:27:21<27:36,  1.75s/it]                                                     {'loss': 0.1242, 'grad_norm': 0.4997613084440004, 'learning_rate': 2.1999315784965564e-06, 'epoch': 2.52}
 84%|████████▍ | 4975/5922 [2:27:21<27:36,  1.75s/it] 84%|████████▍ | 4976/5922 [2:27:23<30:11,  1.91s/it] 84%|████████▍ | 4977/5922 [2:27:25<30:06,  1.91s/it] 84%|████████▍ | 4978/5922 [2:27:27<27:47,  1.77s/it] 84%|████████▍ | 4979/5922 [2:27:28<26:07,  1.66s/it] 84%|████████▍ | 4980/5922 [2:27:30<28:34,  1.82s/it] 84%|████████▍ | 4981/5922 [2:27:33<31:31,  2.01s/it] 84%|████████▍ | 4982/5922 [2:27:35<31:06,  1.99s/it] 84%|████████▍ | 4983/5922 [2:27:36<28:19,  1.81s/it] 84%|████████▍ | 4984/5922 [2:27:38<26:21,  1.69s/it] 84%|████████▍ | 4985/5922 [2:27:40<27:46,  1.78s/it] 84%|████████▍ | 4986/5922 [2:27:41<26:38,  1.71s/it] 84%|████████▍ | 4987/5922 [2:27:42<25:06,  1.61s/it] 84%|████████▍ | 4988/5922 [2:27:44<26:30,  1.70s/it] 84%|████████▍ | 4989/5922 [2:27:47<29:28,  1.90s/it] 84%|████████▍ | 4990/5922 [2:27:49<29:30,  1.90s/it] 84%|████████▍ | 4991/5922 [2:27:50<27:07,  1.75s/it] 84%|████████▍ | 4992/5922 [2:27:51<25:31,  1.65s/it] 84%|████████▍ | 4993/5922 [2:27:53<26:43,  1.73s/it] 84%|████████▍ | 4994/5922 [2:27:55<25:56,  1.68s/it] 84%|████████▍ | 4995/5922 [2:27:56<24:32,  1.59s/it] 84%|████████▍ | 4996/5922 [2:27:58<23:57,  1.55s/it] 84%|████████▍ | 4997/5922 [2:28:00<28:09,  1.83s/it] 84%|████████▍ | 4998/5922 [2:28:02<28:18,  1.84s/it] 84%|████████▍ | 4999/5922 [2:28:04<26:23,  1.72s/it] 84%|████████▍ | 5000/5922 [2:28:06<29:55,  1.95s/it]                                                     {'loss': 0.1341, 'grad_norm': 0.5051049782053768, 'learning_rate': 2.1387580784334415e-06, 'epoch': 2.53}
 84%|████████▍ | 5000/5922 [2:28:06<29:55,  1.95s/it][INFO|trainer.py:3993] 2025-08-30 16:16:57,782 >> Saving model checkpoint to saves/qwen3-1.7B/lora/sft/checkpoint-5000
[INFO|configuration_utils.py:696] 2025-08-30 16:16:57,795 >> loading configuration file /home/qianwenhao/LLM/Qwen3-1.7B/config.json
[INFO|configuration_utils.py:770] 2025-08-30 16:16:57,795 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "max_position_embeddings": 40960,
  "max_window_layers": 28,
  "model_type": "qwen3",
  "num_attention_heads": 16,
  "num_hidden_layers": 28,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|tokenization_utils_base.py:2356] 2025-08-30 16:16:57,812 >> chat template saved in saves/qwen3-1.7B/lora/sft/checkpoint-5000/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-08-30 16:16:57,812 >> tokenizer config file saved in saves/qwen3-1.7B/lora/sft/checkpoint-5000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-08-30 16:16:57,812 >> Special tokens file saved in saves/qwen3-1.7B/lora/sft/checkpoint-5000/special_tokens_map.json
[2025-08-30 16:16:57,972] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step4999 is about to be saved!
[2025-08-30 16:16:57,981] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: saves/qwen3-1.7B/lora/sft/checkpoint-5000/global_step4999/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-08-30 16:16:57,981] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-5000/global_step4999/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-08-30 16:16:57,986] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-5000/global_step4999/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-08-30 16:16:57,988] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-5000/global_step4999/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-08-30 16:16:57,999] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-5000/global_step4999/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-08-30 16:16:57,999] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved saves/qwen3-1.7B/lora/sft/checkpoint-5000/global_step4999/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-08-30 16:16:58,008] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4999 is ready now!
 84%|████████▍ | 5001/5922 [2:28:10<37:30,  2.44s/it] 84%|████████▍ | 5002/5922 [2:28:11<33:45,  2.20s/it] 84%|████████▍ | 5003/5922 [2:28:13<30:04,  1.96s/it] 84%|████████▍ | 5004/5922 [2:28:15<29:48,  1.95s/it] 85%|████████▍ | 5005/5922 [2:28:17<32:04,  2.10s/it] 85%|████████▍ | 5006/5922 [2:28:19<31:48,  2.08s/it] 85%|████████▍ | 5007/5922 [2:28:21<31:06,  2.04s/it] 85%|████████▍ | 5008/5922 [2:28:23<30:04,  1.97s/it] 85%|████████▍ | 5009/5922 [2:28:24<28:02,  1.84s/it] 85%|████████▍ | 5010/5922 [2:28:26<28:25,  1.87s/it] 85%|████████▍ | 5011/5922 [2:28:28<28:38,  1.89s/it] 85%|████████▍ | 5012/5922 [2:28:30<27:52,  1.84s/it] 85%|████████▍ | 5013/5922 [2:28:32<28:17,  1.87s/it] 85%|████████▍ | 5014/5922 [2:28:34<28:20,  1.87s/it] 85%|████████▍ | 5015/5922 [2:28:35<26:06,  1.73s/it] 85%|████████▍ | 5016/5922 [2:28:37<25:53,  1.71s/it] 85%|████████▍ | 5017/5922 [2:28:39<26:44,  1.77s/it] 85%|████████▍ | 5018/5922 [2:28:40<24:58,  1.66s/it] 85%|████████▍ | 5019/5922 [2:28:42<26:17,  1.75s/it] 85%|████████▍ | 5020/5922 [2:28:44<26:30,  1.76s/it] 85%|████████▍ | 5021/5922 [2:28:45<24:47,  1.65s/it] 85%|████████▍ | 5022/5922 [2:28:48<28:30,  1.90s/it] 85%|████████▍ | 5023/5922 [2:28:50<28:37,  1.91s/it] 85%|████████▍ | 5024/5922 [2:28:52<28:35,  1.91s/it] 85%|████████▍ | 5025/5922 [2:28:53<26:55,  1.80s/it]                                                     {'loss': 0.1287, 'grad_norm': 0.535536870909518, 'learning_rate': 2.079085480684412e-06, 'epoch': 2.55}
 85%|████████▍ | 5025/5922 [2:28:53<26:55,  1.80s/it] 85%|████████▍ | 5026/5922 [2:28:55<25:04,  1.68s/it] 85%|████████▍ | 5027/5922 [2:28:57<28:39,  1.92s/it] 85%|████████▍ | 5028/5922 [2:28:59<28:41,  1.93s/it] 85%|████████▍ | 5029/5922 [2:29:00<26:24,  1.77s/it] 85%|████████▍ | 5030/5922 [2:29:02<24:50,  1.67s/it] 85%|████████▍ | 5031/5922 [2:29:04<25:53,  1.74s/it] 85%|████████▍ | 5032/5922 [2:29:05<24:22,  1.64s/it] 85%|████████▍ | 5033/5922 [2:29:07<25:39,  1.73s/it] 85%|████████▌ | 5034/5922 [2:29:09<24:40,  1.67s/it] 85%|████████▌ | 5035/5922 [2:29:10<23:38,  1.60s/it] 85%|████████▌ | 5036/5922 [2:29:13<27:27,  1.86s/it] 85%|████████▌ | 5037/5922 [2:29:15<27:53,  1.89s/it] 85%|████████▌ | 5038/5922 [2:29:16<26:36,  1.81s/it] 85%|████████▌ | 5039/5922 [2:29:18<27:03,  1.84s/it] 85%|████████▌ | 5040/5922 [2:29:19<25:07,  1.71s/it] 85%|████████▌ | 5041/5922 [2:29:21<23:58,  1.63s/it] 85%|████████▌ | 5042/5922 [2:29:23<25:20,  1.73s/it] 85%|████████▌ | 5043/5922 [2:29:25<26:24,  1.80s/it] 85%|████████▌ | 5044/5922 [2:29:26<24:40,  1.69s/it] 85%|████████▌ | 5045/5922 [2:29:28<24:54,  1.70s/it] 85%|████████▌ | 5046/5922 [2:29:30<24:09,  1.65s/it] 85%|████████▌ | 5047/5922 [2:29:31<23:51,  1.64s/it] 85%|████████▌ | 5048/5922 [2:29:33<24:08,  1.66s/it] 85%|████████▌ | 5049/5922 [2:29:34<23:08,  1.59s/it] 85%|████████▌ | 5050/5922 [2:29:36<22:23,  1.54s/it]                                                     {'loss': 0.1239, 'grad_norm': 0.4453376375884847, 'learning_rate': 2.020924496904616e-06, 'epoch': 2.56}
 85%|████████▌ | 5050/5922 [2:29:36<22:23,  1.54s/it] 85%|████████▌ | 5051/5922 [2:29:37<22:24,  1.54s/it] 85%|████████▌ | 5052/5922 [2:29:39<23:58,  1.65s/it] 85%|████████▌ | 5053/5922 [2:29:41<24:09,  1.67s/it] 85%|████████▌ | 5054/5922 [2:29:43<24:42,  1.71s/it] 85%|████████▌ | 5055/5922 [2:29:44<25:08,  1.74s/it] 85%|████████▌ | 5056/5922 [2:29:46<25:58,  1.80s/it] 85%|████████▌ | 5057/5922 [2:29:48<25:54,  1.80s/it] 85%|████████▌ | 5058/5922 [2:29:50<26:02,  1.81s/it] 85%|████████▌ | 5059/5922 [2:29:51<24:30,  1.70s/it] 85%|████████▌ | 5060/5922 [2:29:53<25:32,  1.78s/it] 85%|████████▌ | 5061/5922 [2:29:55<24:24,  1.70s/it] 85%|████████▌ | 5062/5922 [2:29:56<23:07,  1.61s/it] 85%|████████▌ | 5063/5922 [2:29:58<24:26,  1.71s/it] 86%|████████▌ | 5064/5922 [2:30:00<26:17,  1.84s/it] 86%|████████▌ | 5065/5922 [2:30:02<26:52,  1.88s/it] 86%|████████▌ | 5066/5922 [2:30:04<25:00,  1.75s/it] 86%|████████▌ | 5067/5922 [2:30:06<25:44,  1.81s/it] 86%|████████▌ | 5068/5922 [2:30:08<26:14,  1.84s/it] 86%|████████▌ | 5069/5922 [2:30:09<25:14,  1.78s/it] 86%|████████▌ | 5070/5922 [2:30:11<25:26,  1.79s/it] 86%|████████▌ | 5071/5922 [2:30:13<26:08,  1.84s/it] 86%|████████▌ | 5072/5922 [2:30:15<24:50,  1.75s/it] 86%|████████▌ | 5073/5922 [2:30:17<25:26,  1.80s/it] 86%|████████▌ | 5074/5922 [2:30:18<24:37,  1.74s/it] 86%|████████▌ | 5075/5922 [2:30:20<26:02,  1.84s/it]                                                     {'loss': 0.1317, 'grad_norm': 0.4928586665535973, 'learning_rate': 1.964285567403753e-06, 'epoch': 2.57}
 86%|████████▌ | 5075/5922 [2:30:20<26:02,  1.84s/it] 86%|████████▌ | 5076/5922 [2:30:22<24:16,  1.72s/it] 86%|████████▌ | 5077/5922 [2:30:23<23:23,  1.66s/it] 86%|████████▌ | 5078/5922 [2:30:25<22:22,  1.59s/it] 86%|████████▌ | 5079/5922 [2:30:26<21:49,  1.55s/it] 86%|████████▌ | 5080/5922 [2:30:28<21:08,  1.51s/it] 86%|████████▌ | 5081/5922 [2:30:29<20:31,  1.46s/it] 86%|████████▌ | 5082/5922 [2:30:31<21:46,  1.56s/it] 86%|████████▌ | 5083/5922 [2:30:33<23:16,  1.66s/it] 86%|████████▌ | 5084/5922 [2:30:35<24:43,  1.77s/it] 86%|████████▌ | 5085/5922 [2:30:36<23:20,  1.67s/it] 86%|████████▌ | 5086/5922 [2:30:38<26:19,  1.89s/it] 86%|████████▌ | 5087/5922 [2:30:40<25:59,  1.87s/it] 86%|████████▌ | 5088/5922 [2:30:42<25:50,  1.86s/it] 86%|████████▌ | 5089/5922 [2:30:43<23:53,  1.72s/it] 86%|████████▌ | 5090/5922 [2:30:45<22:48,  1.65s/it] 86%|████████▌ | 5091/5922 [2:30:47<24:00,  1.73s/it] 86%|████████▌ | 5092/5922 [2:30:49<24:54,  1.80s/it] 86%|████████▌ | 5093/5922 [2:30:51<25:35,  1.85s/it] 86%|████████▌ | 5094/5922 [2:30:53<25:53,  1.88s/it] 86%|████████▌ | 5095/5922 [2:30:54<24:42,  1.79s/it] 86%|████████▌ | 5096/5922 [2:30:56<23:52,  1.73s/it] 86%|████████▌ | 5097/5922 [2:30:57<22:30,  1.64s/it] 86%|████████▌ | 5098/5922 [2:30:59<21:49,  1.59s/it] 86%|████████▌ | 5099/5922 [2:31:01<25:13,  1.84s/it] 86%|████████▌ | 5100/5922 [2:31:03<23:20,  1.70s/it]                                                     {'loss': 0.1259, 'grad_norm': 0.40702699089785166, 'learning_rate': 1.9091788592719695e-06, 'epoch': 2.58}
 86%|████████▌ | 5100/5922 [2:31:03<23:20,  1.70s/it] 86%|████████▌ | 5101/5922 [2:31:04<22:05,  1.61s/it] 86%|████████▌ | 5102/5922 [2:31:06<23:26,  1.72s/it] 86%|████████▌ | 5103/5922 [2:31:08<26:25,  1.94s/it] 86%|████████▌ | 5104/5922 [2:31:10<24:13,  1.78s/it] 86%|████████▌ | 5105/5922 [2:31:12<26:37,  1.96s/it] 86%|████████▌ | 5106/5922 [2:31:14<24:23,  1.79s/it] 86%|████████▌ | 5107/5922 [2:31:15<24:34,  1.81s/it] 86%|████████▋ | 5108/5922 [2:31:17<23:02,  1.70s/it] 86%|████████▋ | 5109/5922 [2:31:19<24:31,  1.81s/it] 86%|████████▋ | 5110/5922 [2:31:21<25:00,  1.85s/it] 86%|████████▋ | 5111/5922 [2:31:23<25:20,  1.88s/it] 86%|████████▋ | 5112/5922 [2:31:25<24:59,  1.85s/it] 86%|████████▋ | 5113/5922 [2:31:27<26:43,  1.98s/it] 86%|████████▋ | 5114/5922 [2:31:28<24:24,  1.81s/it] 86%|████████▋ | 5115/5922 [2:31:30<23:50,  1.77s/it] 86%|████████▋ | 5116/5922 [2:31:32<24:39,  1.84s/it] 86%|████████▋ | 5117/5922 [2:31:34<25:07,  1.87s/it] 86%|████████▋ | 5118/5922 [2:31:36<27:30,  2.05s/it] 86%|████████▋ | 5119/5922 [2:31:38<27:10,  2.03s/it] 86%|████████▋ | 5120/5922 [2:31:40<26:43,  2.00s/it] 86%|████████▋ | 5121/5922 [2:31:43<27:14,  2.04s/it] 86%|████████▋ | 5122/5922 [2:31:44<24:45,  1.86s/it] 87%|████████▋ | 5123/5922 [2:31:45<22:53,  1.72s/it] 87%|████████▋ | 5124/5922 [2:31:47<23:11,  1.74s/it] 87%|████████▋ | 5125/5922 [2:31:49<22:39,  1.71s/it]                                                     {'loss': 0.1332, 'grad_norm': 0.46234464682242987, 'learning_rate': 1.855614264554797e-06, 'epoch': 2.6}
 87%|████████▋ | 5125/5922 [2:31:49<22:39,  1.71s/it] 87%|████████▋ | 5126/5922 [2:31:50<21:21,  1.61s/it] 87%|████████▋ | 5127/5922 [2:31:52<24:01,  1.81s/it] 87%|████████▋ | 5128/5922 [2:31:54<24:27,  1.85s/it] 87%|████████▋ | 5129/5922 [2:31:56<25:18,  1.92s/it] 87%|████████▋ | 5130/5922 [2:31:58<24:39,  1.87s/it] 87%|████████▋ | 5131/5922 [2:32:00<22:44,  1.72s/it] 87%|████████▋ | 5132/5922 [2:32:01<21:45,  1.65s/it] 87%|████████▋ | 5133/5922 [2:32:03<23:39,  1.80s/it] 87%|████████▋ | 5134/5922 [2:32:05<24:09,  1.84s/it] 87%|████████▋ | 5135/5922 [2:32:07<23:38,  1.80s/it] 87%|████████▋ | 5136/5922 [2:32:09<23:44,  1.81s/it] 87%|████████▋ | 5137/5922 [2:32:11<24:05,  1.84s/it] 87%|████████▋ | 5138/5922 [2:32:13<26:33,  2.03s/it] 87%|████████▋ | 5139/5922 [2:32:15<26:15,  2.01s/it] 87%|████████▋ | 5140/5922 [2:32:17<25:42,  1.97s/it] 87%|████████▋ | 5141/5922 [2:32:19<24:20,  1.87s/it] 87%|████████▋ | 5142/5922 [2:32:21<25:59,  2.00s/it] 87%|████████▋ | 5143/5922 [2:32:22<23:34,  1.82s/it] 87%|████████▋ | 5144/5922 [2:32:24<21:53,  1.69s/it] 87%|████████▋ | 5145/5922 [2:32:26<24:55,  1.92s/it] 87%|████████▋ | 5146/5922 [2:32:28<22:50,  1.77s/it] 87%|████████▋ | 5147/5922 [2:32:29<21:50,  1.69s/it] 87%|████████▋ | 5148/5922 [2:32:31<22:19,  1.73s/it] 87%|████████▋ | 5149/5922 [2:32:33<23:02,  1.79s/it] 87%|████████▋ | 5150/5922 [2:32:35<25:17,  1.97s/it]                                                     {'loss': 0.1322, 'grad_norm': 0.42451019353133856, 'learning_rate': 1.8036013984774453e-06, 'epoch': 2.61}
 87%|████████▋ | 5150/5922 [2:32:35<25:17,  1.97s/it] 87%|████████▋ | 5151/5922 [2:32:37<25:16,  1.97s/it] 87%|████████▋ | 5152/5922 [2:32:39<24:53,  1.94s/it] 87%|████████▋ | 5153/5922 [2:32:41<25:21,  1.98s/it] 87%|████████▋ | 5154/5922 [2:32:43<23:20,  1.82s/it] 87%|████████▋ | 5155/5922 [2:32:44<23:16,  1.82s/it] 87%|████████▋ | 5156/5922 [2:32:47<25:46,  2.02s/it] 87%|████████▋ | 5157/5922 [2:32:48<23:54,  1.88s/it] 87%|████████▋ | 5158/5922 [2:32:50<23:58,  1.88s/it] 87%|████████▋ | 5159/5922 [2:32:52<24:20,  1.91s/it] 87%|████████▋ | 5160/5922 [2:32:54<22:16,  1.75s/it] 87%|████████▋ | 5161/5922 [2:32:56<23:28,  1.85s/it] 87%|████████▋ | 5162/5922 [2:32:57<21:44,  1.72s/it] 87%|████████▋ | 5163/5922 [2:32:59<22:20,  1.77s/it] 87%|████████▋ | 5164/5922 [2:33:00<20:49,  1.65s/it] 87%|████████▋ | 5165/5922 [2:33:02<22:07,  1.75s/it] 87%|████████▋ | 5166/5922 [2:33:04<22:42,  1.80s/it] 87%|████████▋ | 5167/5922 [2:33:06<23:14,  1.85s/it] 87%|████████▋ | 5168/5922 [2:33:08<21:25,  1.71s/it] 87%|████████▋ | 5169/5922 [2:33:09<20:27,  1.63s/it] 87%|████████▋ | 5170/5922 [2:33:11<20:27,  1.63s/it] 87%|████████▋ | 5171/5922 [2:33:13<21:14,  1.70s/it] 87%|████████▋ | 5172/5922 [2:33:15<23:25,  1.87s/it] 87%|████████▋ | 5173/5922 [2:33:16<21:34,  1.73s/it] 87%|████████▋ | 5174/5922 [2:33:18<22:00,  1.76s/it] 87%|████████▋ | 5175/5922 [2:33:20<22:34,  1.81s/it]                                                     {'loss': 0.1386, 'grad_norm': 0.40781405353626393, 'learning_rate': 1.7531495977188254e-06, 'epoch': 2.62}
 87%|████████▋ | 5175/5922 [2:33:20<22:34,  1.81s/it] 87%|████████▋ | 5176/5922 [2:33:23<25:05,  2.02s/it] 87%|████████▋ | 5177/5922 [2:33:24<22:51,  1.84s/it] 87%|████████▋ | 5178/5922 [2:33:25<21:10,  1.71s/it] 87%|████████▋ | 5179/5922 [2:33:28<23:40,  1.91s/it] 87%|████████▋ | 5180/5922 [2:33:29<22:18,  1.80s/it] 87%|████████▋ | 5181/5922 [2:33:31<20:42,  1.68s/it] 88%|████████▊ | 5182/5922 [2:33:32<20:27,  1.66s/it] 88%|████████▊ | 5183/5922 [2:33:34<21:25,  1.74s/it] 88%|████████▊ | 5184/5922 [2:33:36<20:11,  1.64s/it] 88%|████████▊ | 5185/5922 [2:33:38<21:13,  1.73s/it] 88%|████████▊ | 5186/5922 [2:33:39<21:50,  1.78s/it] 88%|████████▊ | 5187/5922 [2:33:41<22:09,  1.81s/it] 88%|████████▊ | 5188/5922 [2:33:43<21:27,  1.75s/it] 88%|████████▊ | 5189/5922 [2:33:44<20:04,  1.64s/it] 88%|████████▊ | 5190/5922 [2:33:46<21:09,  1.73s/it] 88%|████████▊ | 5191/5922 [2:33:48<19:50,  1.63s/it] 88%|████████▊ | 5192/5922 [2:33:49<19:32,  1.61s/it] 88%|████████▊ | 5193/5922 [2:33:51<20:42,  1.70s/it] 88%|████████▊ | 5194/5922 [2:33:53<20:43,  1.71s/it] 88%|████████▊ | 5195/5922 [2:33:55<21:26,  1.77s/it] 88%|████████▊ | 5196/5922 [2:33:57<21:57,  1.81s/it] 88%|████████▊ | 5197/5922 [2:33:58<20:55,  1.73s/it] 88%|████████▊ | 5198/5922 [2:34:00<21:02,  1.74s/it] 88%|████████▊ | 5199/5922 [2:34:02<21:40,  1.80s/it] 88%|████████▊ | 5200/5922 [2:34:03<20:18,  1.69s/it]                                                     {'loss': 0.1359, 'grad_norm': 0.40909050424221055, 'learning_rate': 1.704267918735522e-06, 'epoch': 2.63}
 88%|████████▊ | 5200/5922 [2:34:03<20:18,  1.69s/it] 88%|████████▊ | 5201/5922 [2:34:05<19:17,  1.61s/it] 88%|████████▊ | 5202/5922 [2:34:06<19:42,  1.64s/it] 88%|████████▊ | 5203/5922 [2:34:08<20:38,  1.72s/it] 88%|████████▊ | 5204/5922 [2:34:11<22:41,  1.90s/it] 88%|████████▊ | 5205/5922 [2:34:12<20:52,  1.75s/it] 88%|████████▊ | 5206/5922 [2:34:13<19:34,  1.64s/it] 88%|████████▊ | 5207/5922 [2:34:15<18:35,  1.56s/it] 88%|████████▊ | 5208/5922 [2:34:17<21:47,  1.83s/it] 88%|████████▊ | 5209/5922 [2:34:19<20:06,  1.69s/it] 88%|████████▊ | 5210/5922 [2:34:21<21:11,  1.79s/it] 88%|████████▊ | 5211/5922 [2:34:23<21:12,  1.79s/it] 88%|████████▊ | 5212/5922 [2:34:24<21:18,  1.80s/it] 88%|████████▊ | 5213/5922 [2:34:26<21:45,  1.84s/it] 88%|████████▊ | 5214/5922 [2:34:28<22:34,  1.91s/it] 88%|████████▊ | 5215/5922 [2:34:30<21:18,  1.81s/it] 88%|████████▊ | 5216/5922 [2:34:31<19:43,  1.68s/it] 88%|████████▊ | 5217/5922 [2:34:33<20:31,  1.75s/it] 88%|████████▊ | 5218/5922 [2:34:35<20:02,  1.71s/it] 88%|████████▊ | 5219/5922 [2:34:36<19:47,  1.69s/it] 88%|████████▊ | 5220/5922 [2:34:38<19:16,  1.65s/it] 88%|████████▊ | 5221/5922 [2:34:40<21:00,  1.80s/it] 88%|████████▊ | 5222/5922 [2:34:42<19:37,  1.68s/it] 88%|████████▊ | 5223/5922 [2:34:44<21:03,  1.81s/it] 88%|████████▊ | 5224/5922 [2:34:46<23:01,  1.98s/it] 88%|████████▊ | 5225/5922 [2:34:47<20:57,  1.80s/it]                                                     {'loss': 0.1289, 'grad_norm': 0.3423931932970264, 'learning_rate': 1.6569651361361194e-06, 'epoch': 2.65}
 88%|████████▊ | 5225/5922 [2:34:47<20:57,  1.80s/it] 88%|████████▊ | 5226/5922 [2:34:49<21:23,  1.84s/it] 88%|████████▊ | 5227/5922 [2:34:51<21:40,  1.87s/it] 88%|████████▊ | 5228/5922 [2:34:53<21:39,  1.87s/it] 88%|████████▊ | 5229/5922 [2:34:55<21:11,  1.84s/it] 88%|████████▊ | 5230/5922 [2:34:57<21:24,  1.86s/it] 88%|████████▊ | 5231/5922 [2:34:58<20:05,  1.75s/it] 88%|████████▊ | 5232/5922 [2:35:01<22:02,  1.92s/it] 88%|████████▊ | 5233/5922 [2:35:03<22:10,  1.93s/it] 88%|████████▊ | 5234/5922 [2:35:05<22:02,  1.92s/it] 88%|████████▊ | 5235/5922 [2:35:06<20:11,  1.76s/it] 88%|████████▊ | 5236/5922 [2:35:07<19:17,  1.69s/it] 88%|████████▊ | 5237/5922 [2:35:10<21:50,  1.91s/it] 88%|████████▊ | 5238/5922 [2:35:12<22:16,  1.95s/it] 88%|████████▊ | 5239/5922 [2:35:13<20:27,  1.80s/it] 88%|████████▊ | 5240/5922 [2:35:16<22:23,  1.97s/it] 89%|████████▊ | 5241/5922 [2:35:18<22:40,  2.00s/it] 89%|████████▊ | 5242/5922 [2:35:20<24:13,  2.14s/it] 89%|████████▊ | 5243/5922 [2:35:22<21:37,  1.91s/it] 89%|████████▊ | 5244/5922 [2:35:23<20:18,  1.80s/it] 89%|████████▊ | 5245/5922 [2:35:25<18:50,  1.67s/it] 89%|████████▊ | 5246/5922 [2:35:26<17:50,  1.58s/it] 89%|████████▊ | 5247/5922 [2:35:27<17:44,  1.58s/it] 89%|████████▊ | 5248/5922 [2:35:30<19:37,  1.75s/it] 89%|████████▊ | 5249/5922 [2:35:32<21:42,  1.94s/it] 89%|████████▊ | 5250/5922 [2:35:34<21:41,  1.94s/it]                                                     {'loss': 0.1311, 'grad_norm': 0.381149701258791, 'learning_rate': 1.611249741106078e-06, 'epoch': 2.66}
 89%|████████▊ | 5250/5922 [2:35:34<21:41,  1.94s/it] 89%|████████▊ | 5251/5922 [2:35:35<20:01,  1.79s/it] 89%|████████▊ | 5252/5922 [2:35:37<18:45,  1.68s/it] 89%|████████▊ | 5253/5922 [2:35:38<17:44,  1.59s/it] 89%|████████▊ | 5254/5922 [2:35:40<18:04,  1.62s/it] 89%|████████▊ | 5255/5922 [2:35:42<18:17,  1.65s/it] 89%|████████▉ | 5256/5922 [2:35:43<18:10,  1.64s/it] 89%|████████▉ | 5257/5922 [2:35:45<17:41,  1.60s/it] 89%|████████▉ | 5258/5922 [2:35:47<19:05,  1.72s/it] 89%|████████▉ | 5259/5922 [2:35:49<21:27,  1.94s/it] 89%|████████▉ | 5260/5922 [2:35:52<22:51,  2.07s/it] 89%|████████▉ | 5261/5922 [2:35:53<21:36,  1.96s/it] 89%|████████▉ | 5262/5922 [2:35:55<19:38,  1.79s/it] 89%|████████▉ | 5263/5922 [2:35:57<20:05,  1.83s/it] 89%|████████▉ | 5264/5922 [2:35:59<21:59,  2.01s/it] 89%|████████▉ | 5265/5922 [2:36:01<21:47,  1.99s/it] 89%|████████▉ | 5266/5922 [2:36:03<21:30,  1.97s/it] 89%|████████▉ | 5267/5922 [2:36:04<19:36,  1.80s/it] 89%|████████▉ | 5268/5922 [2:36:06<20:09,  1.85s/it] 89%|████████▉ | 5269/5922 [2:36:09<21:44,  2.00s/it] 89%|████████▉ | 5270/5922 [2:36:10<19:38,  1.81s/it] 89%|████████▉ | 5271/5922 [2:36:12<19:59,  1.84s/it] 89%|████████▉ | 5272/5922 [2:36:13<18:25,  1.70s/it] 89%|████████▉ | 5273/5922 [2:36:15<19:08,  1.77s/it] 89%|████████▉ | 5274/5922 [2:36:17<19:39,  1.82s/it] 89%|████████▉ | 5275/5922 [2:36:19<19:18,  1.79s/it]                                                     {'loss': 0.1308, 'grad_norm': 0.5511251685294485, 'learning_rate': 1.5671299398835204e-06, 'epoch': 2.67}
 89%|████████▉ | 5275/5922 [2:36:19<19:18,  1.79s/it] 89%|████████▉ | 5276/5922 [2:36:21<19:10,  1.78s/it] 89%|████████▉ | 5277/5922 [2:36:22<17:57,  1.67s/it] 89%|████████▉ | 5278/5922 [2:36:23<17:20,  1.62s/it] 89%|████████▉ | 5279/5922 [2:36:25<18:15,  1.70s/it] 89%|████████▉ | 5280/5922 [2:36:27<17:19,  1.62s/it] 89%|████████▉ | 5281/5922 [2:36:29<18:19,  1.72s/it] 89%|████████▉ | 5282/5922 [2:36:31<19:03,  1.79s/it] 89%|████████▉ | 5283/5922 [2:36:33<21:09,  1.99s/it] 89%|████████▉ | 5284/5922 [2:36:35<20:40,  1.94s/it] 89%|████████▉ | 5285/5922 [2:36:36<19:02,  1.79s/it] 89%|████████▉ | 5286/5922 [2:36:38<18:06,  1.71s/it] 89%|████████▉ | 5287/5922 [2:36:39<17:02,  1.61s/it] 89%|████████▉ | 5288/5922 [2:36:41<16:14,  1.54s/it] 89%|████████▉ | 5289/5922 [2:36:43<17:30,  1.66s/it] 89%|████████▉ | 5290/5922 [2:36:44<16:32,  1.57s/it] 89%|████████▉ | 5291/5922 [2:36:45<16:13,  1.54s/it] 89%|████████▉ | 5292/5922 [2:36:47<17:27,  1.66s/it] 89%|████████▉ | 5293/5922 [2:36:50<19:54,  1.90s/it] 89%|████████▉ | 5294/5922 [2:36:52<19:53,  1.90s/it] 89%|████████▉ | 5295/5922 [2:36:54<21:37,  2.07s/it] 89%|████████▉ | 5296/5922 [2:36:57<22:50,  2.19s/it] 89%|████████▉ | 5297/5922 [2:36:58<20:17,  1.95s/it] 89%|████████▉ | 5298/5922 [2:36:59<18:24,  1.77s/it] 89%|████████▉ | 5299/5922 [2:37:01<17:31,  1.69s/it] 89%|████████▉ | 5300/5922 [2:37:03<18:48,  1.81s/it]                                                     {'loss': 0.1364, 'grad_norm': 0.4831071295793892, 'learning_rate': 1.5246136522861455e-06, 'epoch': 2.69}
 89%|████████▉ | 5300/5922 [2:37:03<18:48,  1.81s/it] 90%|████████▉ | 5301/5922 [2:37:05<19:05,  1.84s/it] 90%|████████▉ | 5302/5922 [2:37:06<17:39,  1.71s/it] 90%|████████▉ | 5303/5922 [2:37:08<16:48,  1.63s/it] 90%|████████▉ | 5304/5922 [2:37:10<17:49,  1.73s/it] 90%|████████▉ | 5305/5922 [2:37:12<18:24,  1.79s/it] 90%|████████▉ | 5306/5922 [2:37:14<19:09,  1.87s/it] 90%|████████▉ | 5307/5922 [2:37:16<18:50,  1.84s/it] 90%|████████▉ | 5308/5922 [2:37:17<18:13,  1.78s/it] 90%|████████▉ | 5309/5922 [2:37:19<18:26,  1.80s/it] 90%|████████▉ | 5310/5922 [2:37:21<18:48,  1.84s/it] 90%|████████▉ | 5311/5922 [2:37:22<17:27,  1.71s/it] 90%|████████▉ | 5312/5922 [2:37:24<17:25,  1.71s/it] 90%|████████▉ | 5313/5922 [2:37:25<16:27,  1.62s/it] 90%|████████▉ | 5314/5922 [2:37:27<16:14,  1.60s/it] 90%|████████▉ | 5315/5922 [2:37:28<15:39,  1.55s/it] 90%|████████▉ | 5316/5922 [2:37:30<16:59,  1.68s/it] 90%|████████▉ | 5317/5922 [2:37:32<17:53,  1.77s/it] 90%|████████▉ | 5318/5922 [2:37:34<18:17,  1.82s/it] 90%|████████▉ | 5319/5922 [2:37:36<17:18,  1.72s/it] 90%|████████▉ | 5320/5922 [2:37:37<16:37,  1.66s/it] 90%|████████▉ | 5321/5922 [2:37:40<19:07,  1.91s/it] 90%|████████▉ | 5322/5922 [2:37:41<17:37,  1.76s/it] 90%|████████▉ | 5323/5922 [2:37:43<18:35,  1.86s/it] 90%|████████▉ | 5324/5922 [2:37:45<18:48,  1.89s/it] 90%|████████▉ | 5325/5922 [2:37:47<18:46,  1.89s/it]                                                     {'loss': 0.1305, 'grad_norm': 0.4136176585888261, 'learning_rate': 1.4837085102895644e-06, 'epoch': 2.7}
 90%|████████▉ | 5325/5922 [2:37:47<18:46,  1.89s/it] 90%|████████▉ | 5326/5922 [2:37:49<17:19,  1.74s/it] 90%|████████▉ | 5327/5922 [2:37:51<17:47,  1.79s/it] 90%|████████▉ | 5328/5922 [2:37:52<16:37,  1.68s/it] 90%|████████▉ | 5329/5922 [2:37:54<17:43,  1.79s/it] 90%|█████████ | 5330/5922 [2:37:55<16:28,  1.67s/it] 90%|█████████ | 5331/5922 [2:37:57<15:50,  1.61s/it] 90%|█████████ | 5332/5922 [2:37:58<15:28,  1.57s/it] 90%|█████████ | 5333/5922 [2:38:00<15:02,  1.53s/it] 90%|█████████ | 5334/5922 [2:38:02<17:42,  1.81s/it] 90%|█████████ | 5335/5922 [2:38:04<17:19,  1.77s/it] 90%|█████████ | 5336/5922 [2:38:05<16:35,  1.70s/it] 90%|█████████ | 5337/5922 [2:38:07<17:15,  1.77s/it] 90%|█████████ | 5338/5922 [2:38:09<17:36,  1.81s/it] 90%|█████████ | 5339/5922 [2:38:11<16:27,  1.69s/it] 90%|█████████ | 5340/5922 [2:38:12<15:31,  1.60s/it] 90%|█████████ | 5341/5922 [2:38:14<16:26,  1.70s/it] 90%|█████████ | 5342/5922 [2:38:16<15:51,  1.64s/it] 90%|█████████ | 5343/5922 [2:38:17<15:39,  1.62s/it] 90%|█████████ | 5344/5922 [2:38:19<16:52,  1.75s/it] 90%|█████████ | 5345/5922 [2:38:21<17:23,  1.81s/it] 90%|█████████ | 5346/5922 [2:38:23<19:03,  1.99s/it] 90%|█████████ | 5347/5922 [2:38:25<18:49,  1.96s/it] 90%|█████████ | 5348/5922 [2:38:27<18:27,  1.93s/it] 90%|█████████ | 5349/5922 [2:38:29<18:24,  1.93s/it] 90%|█████████ | 5350/5922 [2:38:31<17:03,  1.79s/it]                                                     {'loss': 0.1257, 'grad_norm': 0.43481307500876376, 'learning_rate': 1.4444218566573117e-06, 'epoch': 2.71}
 90%|█████████ | 5350/5922 [2:38:31<17:03,  1.79s/it] 90%|█████████ | 5351/5922 [2:38:32<16:56,  1.78s/it] 90%|█████████ | 5352/5922 [2:38:34<16:25,  1.73s/it] 90%|█████████ | 5353/5922 [2:38:35<15:29,  1.63s/it] 90%|█████████ | 5354/5922 [2:38:37<14:50,  1.57s/it] 90%|█████████ | 5355/5922 [2:38:38<14:16,  1.51s/it] 90%|█████████ | 5356/5922 [2:38:40<15:27,  1.64s/it] 90%|█████████ | 5357/5922 [2:38:42<16:26,  1.75s/it] 90%|█████████ | 5358/5922 [2:38:45<18:16,  1.94s/it] 90%|█████████ | 5359/5922 [2:38:46<16:49,  1.79s/it] 91%|█████████ | 5360/5922 [2:38:48<17:15,  1.84s/it] 91%|█████████ | 5361/5922 [2:38:49<16:09,  1.73s/it] 91%|█████████ | 5362/5922 [2:38:51<15:18,  1.64s/it] 91%|█████████ | 5363/5922 [2:38:53<17:07,  1.84s/it] 91%|█████████ | 5364/5922 [2:38:55<16:37,  1.79s/it] 91%|█████████ | 5365/5922 [2:38:56<16:08,  1.74s/it] 91%|█████████ | 5366/5922 [2:38:58<15:10,  1.64s/it] 91%|█████████ | 5367/5922 [2:38:59<14:24,  1.56s/it] 91%|█████████ | 5368/5922 [2:39:01<13:56,  1.51s/it] 91%|█████████ | 5369/5922 [2:39:03<15:02,  1.63s/it] 91%|█████████ | 5370/5922 [2:39:04<14:19,  1.56s/it] 91%|█████████ | 5371/5922 [2:39:05<13:52,  1.51s/it] 91%|█████████ | 5372/5922 [2:39:07<15:00,  1.64s/it] 91%|█████████ | 5373/5922 [2:39:10<17:16,  1.89s/it] 91%|█████████ | 5374/5922 [2:39:11<16:29,  1.81s/it] 91%|█████████ | 5375/5922 [2:39:13<15:21,  1.68s/it]                                                     {'loss': 0.1249, 'grad_norm': 0.44485047441457587, 'learning_rate': 1.406760743622767e-06, 'epoch': 2.72}
 91%|█████████ | 5375/5922 [2:39:13<15:21,  1.68s/it] 91%|█████████ | 5376/5922 [2:39:14<15:12,  1.67s/it] 91%|█████████ | 5377/5922 [2:39:16<14:27,  1.59s/it] 91%|█████████ | 5378/5922 [2:39:18<16:50,  1.86s/it] 91%|█████████ | 5379/5922 [2:39:20<15:32,  1.72s/it] 91%|█████████ | 5380/5922 [2:39:21<15:42,  1.74s/it] 91%|█████████ | 5381/5922 [2:39:23<15:11,  1.69s/it] 91%|█████████ | 5382/5922 [2:39:25<16:21,  1.82s/it] 91%|█████████ | 5383/5922 [2:39:27<15:43,  1.75s/it] 91%|█████████ | 5384/5922 [2:39:28<15:20,  1.71s/it] 91%|█████████ | 5385/5922 [2:39:30<14:54,  1.67s/it] 91%|█████████ | 5386/5922 [2:39:31<14:11,  1.59s/it] 91%|█████████ | 5387/5922 [2:39:33<14:53,  1.67s/it] 91%|█████████ | 5388/5922 [2:39:35<14:12,  1.60s/it] 91%|█████████ | 5389/5922 [2:39:36<14:02,  1.58s/it] 91%|█████████ | 5390/5922 [2:39:38<13:59,  1.58s/it] 91%|█████████ | 5391/5922 [2:39:40<15:10,  1.72s/it] 91%|█████████ | 5392/5922 [2:39:41<14:28,  1.64s/it] 91%|█████████ | 5393/5922 [2:39:43<15:11,  1.72s/it] 91%|█████████ | 5394/5922 [2:39:45<15:51,  1.80s/it] 91%|█████████ | 5395/5922 [2:39:47<14:46,  1.68s/it] 91%|█████████ | 5396/5922 [2:39:48<14:06,  1.61s/it] 91%|█████████ | 5397/5922 [2:39:49<13:32,  1.55s/it] 91%|█████████ | 5398/5922 [2:39:51<14:32,  1.67s/it] 91%|█████████ | 5399/5922 [2:39:54<16:38,  1.91s/it] 91%|█████████ | 5400/5922 [2:39:55<15:37,  1.80s/it]                                                     {'loss': 0.1255, 'grad_norm': 0.48597655430651443, 'learning_rate': 1.3707319316232182e-06, 'epoch': 2.74}
 91%|█████████ | 5400/5922 [2:39:55<15:37,  1.80s/it] 91%|█████████ | 5401/5922 [2:39:57<14:39,  1.69s/it] 91%|█████████ | 5402/5922 [2:39:58<14:11,  1.64s/it] 91%|█████████ | 5403/5922 [2:40:01<16:15,  1.88s/it] 91%|█████████▏| 5404/5922 [2:40:03<17:43,  2.05s/it] 91%|█████████▏| 5405/5922 [2:40:05<18:23,  2.14s/it] 91%|█████████▏| 5406/5922 [2:40:07<16:33,  1.93s/it] 91%|█████████▏| 5407/5922 [2:40:09<16:10,  1.88s/it] 91%|█████████▏| 5408/5922 [2:40:11<16:42,  1.95s/it] 91%|█████████▏| 5409/5922 [2:40:13<16:57,  1.98s/it] 91%|█████████▏| 5410/5922 [2:40:15<18:09,  2.13s/it] 91%|█████████▏| 5411/5922 [2:40:17<16:52,  1.98s/it] 91%|█████████▏| 5412/5922 [2:40:19<16:10,  1.90s/it] 91%|█████████▏| 5413/5922 [2:40:20<14:49,  1.75s/it] 91%|█████████▏| 5414/5922 [2:40:22<13:59,  1.65s/it] 91%|█████████▏| 5415/5922 [2:40:23<13:22,  1.58s/it] 91%|█████████▏| 5416/5922 [2:40:25<15:36,  1.85s/it] 91%|█████████▏| 5417/5922 [2:40:27<15:32,  1.85s/it] 91%|█████████▏| 5418/5922 [2:40:29<14:24,  1.71s/it] 92%|█████████▏| 5419/5922 [2:40:30<13:36,  1.62s/it] 92%|█████████▏| 5420/5922 [2:40:33<15:42,  1.88s/it] 92%|█████████▏| 5421/5922 [2:40:34<15:46,  1.89s/it] 92%|█████████▏| 5422/5922 [2:40:36<15:58,  1.92s/it] 92%|█████████▏| 5423/5922 [2:40:38<15:56,  1.92s/it] 92%|█████████▏| 5424/5922 [2:40:40<14:42,  1.77s/it] 92%|█████████▏| 5425/5922 [2:40:41<13:56,  1.68s/it]                                                     {'loss': 0.1342, 'grad_norm': 0.5104970757426672, 'learning_rate': 1.3363418880863346e-06, 'epoch': 2.75}
 92%|█████████▏| 5425/5922 [2:40:41<13:56,  1.68s/it] 92%|█████████▏| 5426/5922 [2:40:43<14:33,  1.76s/it] 92%|█████████▏| 5427/5922 [2:40:45<14:58,  1.82s/it] 92%|█████████▏| 5428/5922 [2:40:47<15:30,  1.88s/it] 92%|█████████▏| 5429/5922 [2:40:49<15:10,  1.85s/it] 92%|█████████▏| 5430/5922 [2:40:51<15:27,  1.88s/it] 92%|█████████▏| 5431/5922 [2:40:52<14:15,  1.74s/it] 92%|█████████▏| 5432/5922 [2:40:55<15:25,  1.89s/it] 92%|█████████▏| 5433/5922 [2:40:56<14:12,  1.74s/it] 92%|█████████▏| 5434/5922 [2:40:58<13:55,  1.71s/it] 92%|█████████▏| 5435/5922 [2:41:00<14:27,  1.78s/it] 92%|█████████▏| 5436/5922 [2:41:01<13:32,  1.67s/it] 92%|█████████▏| 5437/5922 [2:41:03<14:07,  1.75s/it] 92%|█████████▏| 5438/5922 [2:41:04<13:13,  1.64s/it] 92%|█████████▏| 5439/5922 [2:41:06<13:56,  1.73s/it] 92%|█████████▏| 5440/5922 [2:41:08<13:08,  1.64s/it] 92%|█████████▏| 5441/5922 [2:41:10<14:16,  1.78s/it] 92%|█████████▏| 5442/5922 [2:41:11<13:43,  1.72s/it] 92%|█████████▏| 5443/5922 [2:41:13<14:41,  1.84s/it] 92%|█████████▏| 5444/5922 [2:41:15<13:41,  1.72s/it] 92%|█████████▏| 5445/5922 [2:41:16<13:05,  1.65s/it] 92%|█████████▏| 5446/5922 [2:41:18<13:42,  1.73s/it] 92%|█████████▏| 5447/5922 [2:41:20<12:53,  1.63s/it] 92%|█████████▏| 5448/5922 [2:41:21<12:55,  1.64s/it] 92%|█████████▏| 5449/5922 [2:41:23<13:36,  1.73s/it] 92%|█████████▏| 5450/5922 [2:41:25<13:10,  1.67s/it]                                                     {'loss': 0.1298, 'grad_norm': 0.3902246648779766, 'learning_rate': 1.3035967862691956e-06, 'epoch': 2.76}
 92%|█████████▏| 5450/5922 [2:41:25<13:10,  1.67s/it] 92%|█████████▏| 5451/5922 [2:41:27<13:28,  1.72s/it] 92%|█████████▏| 5452/5922 [2:41:29<14:17,  1.83s/it] 92%|█████████▏| 5453/5922 [2:41:30<14:05,  1.80s/it] 92%|█████████▏| 5454/5922 [2:41:32<13:44,  1.76s/it] 92%|█████████▏| 5455/5922 [2:41:34<12:53,  1.66s/it] 92%|█████████▏| 5456/5922 [2:41:35<13:06,  1.69s/it] 92%|█████████▏| 5457/5922 [2:41:37<12:47,  1.65s/it] 92%|█████████▏| 5458/5922 [2:41:39<13:40,  1.77s/it] 92%|█████████▏| 5459/5922 [2:41:41<13:36,  1.76s/it] 92%|█████████▏| 5460/5922 [2:41:43<14:15,  1.85s/it] 92%|█████████▏| 5461/5922 [2:41:44<13:39,  1.78s/it] 92%|█████████▏| 5462/5922 [2:41:47<15:02,  1.96s/it] 92%|█████████▏| 5463/5922 [2:41:49<14:56,  1.95s/it] 92%|█████████▏| 5464/5922 [2:41:50<13:39,  1.79s/it] 92%|█████████▏| 5465/5922 [2:41:51<12:45,  1.68s/it] 92%|█████████▏| 5466/5922 [2:41:54<14:07,  1.86s/it] 92%|█████████▏| 5467/5922 [2:41:55<12:58,  1.71s/it] 92%|█████████▏| 5468/5922 [2:41:57<12:59,  1.72s/it] 92%|█████████▏| 5469/5922 [2:41:59<14:21,  1.90s/it] 92%|█████████▏| 5470/5922 [2:42:01<14:04,  1.87s/it] 92%|█████████▏| 5471/5922 [2:42:03<14:23,  1.91s/it] 92%|█████████▏| 5472/5922 [2:42:05<14:25,  1.92s/it] 92%|█████████▏| 5473/5922 [2:42:07<14:48,  1.98s/it] 92%|█████████▏| 5474/5922 [2:42:09<14:37,  1.96s/it] 92%|█████████▏| 5475/5922 [2:42:11<14:27,  1.94s/it]                                                     {'loss': 0.1336, 'grad_norm': 0.6774149638066687, 'learning_rate': 1.2725025041501659e-06, 'epoch': 2.77}
 92%|█████████▏| 5475/5922 [2:42:11<14:27,  1.94s/it] 92%|█████████▏| 5476/5922 [2:42:13<14:25,  1.94s/it] 92%|█████████▏| 5477/5922 [2:42:14<13:13,  1.78s/it] 93%|█████████▎| 5478/5922 [2:42:16<13:35,  1.84s/it] 93%|█████████▎| 5479/5922 [2:42:18<13:52,  1.88s/it] 93%|█████████▎| 5480/5922 [2:42:20<14:00,  1.90s/it] 93%|█████████▎| 5481/5922 [2:42:22<14:03,  1.91s/it] 93%|█████████▎| 5482/5922 [2:42:24<14:06,  1.92s/it] 93%|█████████▎| 5483/5922 [2:42:26<13:25,  1.83s/it] 93%|█████████▎| 5484/5922 [2:42:27<12:53,  1.76s/it] 93%|█████████▎| 5485/5922 [2:42:29<13:12,  1.81s/it] 93%|█████████▎| 5486/5922 [2:42:31<12:13,  1.68s/it] 93%|█████████▎| 5487/5922 [2:42:32<11:36,  1.60s/it] 93%|█████████▎| 5488/5922 [2:42:34<12:04,  1.67s/it] 93%|█████████▎| 5489/5922 [2:42:35<11:51,  1.64s/it] 93%|█████████▎| 5490/5922 [2:42:37<12:31,  1.74s/it] 93%|█████████▎| 5491/5922 [2:42:39<11:48,  1.64s/it] 93%|█████████▎| 5492/5922 [2:42:41<12:28,  1.74s/it] 93%|█████████▎| 5493/5922 [2:42:43<13:02,  1.82s/it] 93%|█████████▎| 5494/5922 [2:42:44<12:11,  1.71s/it] 93%|█████████▎| 5495/5922 [2:42:46<12:55,  1.82s/it] 93%|█████████▎| 5496/5922 [2:42:48<13:12,  1.86s/it] 93%|█████████▎| 5497/5922 [2:42:50<13:18,  1.88s/it] 93%|█████████▎| 5498/5922 [2:42:52<13:27,  1.90s/it] 93%|█████████▎| 5499/5922 [2:42:54<12:34,  1.78s/it] 93%|█████████▎| 5500/5922 [2:42:55<12:47,  1.82s/it]                                                     {'loss': 0.1307, 'grad_norm': 0.42475718839395493, 'learning_rate': 1.2430646233737447e-06, 'epoch': 2.79}
 93%|█████████▎| 5500/5922 [2:42:55<12:47,  1.82s/it][INFO|trainer.py:3993] 2025-08-30 16:31:47,257 >> Saving model checkpoint to saves/qwen3-1.7B/lora/sft/checkpoint-5500
[INFO|configuration_utils.py:696] 2025-08-30 16:31:47,269 >> loading configuration file /home/qianwenhao/LLM/Qwen3-1.7B/config.json
[INFO|configuration_utils.py:770] 2025-08-30 16:31:47,270 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "max_position_embeddings": 40960,
  "max_window_layers": 28,
  "model_type": "qwen3",
  "num_attention_heads": 16,
  "num_hidden_layers": 28,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|tokenization_utils_base.py:2356] 2025-08-30 16:31:47,286 >> chat template saved in saves/qwen3-1.7B/lora/sft/checkpoint-5500/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-08-30 16:31:47,287 >> tokenizer config file saved in saves/qwen3-1.7B/lora/sft/checkpoint-5500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-08-30 16:31:47,287 >> Special tokens file saved in saves/qwen3-1.7B/lora/sft/checkpoint-5500/special_tokens_map.json
[2025-08-30 16:31:47,450] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step5499 is about to be saved!
[2025-08-30 16:31:47,459] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: saves/qwen3-1.7B/lora/sft/checkpoint-5500/global_step5499/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-08-30 16:31:47,459] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-5500/global_step5499/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-08-30 16:31:47,464] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-5500/global_step5499/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-08-30 16:31:47,465] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-5500/global_step5499/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-08-30 16:31:47,477] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-5500/global_step5499/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-08-30 16:31:47,477] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved saves/qwen3-1.7B/lora/sft/checkpoint-5500/global_step5499/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-08-30 16:31:47,485] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step5499 is ready now!
 93%|█████████▎| 5501/5922 [2:42:59<16:33,  2.36s/it] 93%|█████████▎| 5502/5922 [2:43:01<15:00,  2.14s/it] 93%|█████████▎| 5503/5922 [2:43:03<14:41,  2.10s/it] 93%|█████████▎| 5504/5922 [2:43:05<15:22,  2.21s/it] 93%|█████████▎| 5505/5922 [2:43:07<14:02,  2.02s/it] 93%|█████████▎| 5506/5922 [2:43:08<12:43,  1.83s/it] 93%|█████████▎| 5507/5922 [2:43:10<12:53,  1.86s/it] 93%|█████████▎| 5508/5922 [2:43:12<13:01,  1.89s/it] 93%|█████████▎| 5509/5922 [2:43:14<13:07,  1.91s/it] 93%|█████████▎| 5510/5922 [2:43:15<12:04,  1.76s/it] 93%|█████████▎| 5511/5922 [2:43:17<11:23,  1.66s/it] 93%|█████████▎| 5512/5922 [2:43:19<11:55,  1.75s/it] 93%|█████████▎| 5513/5922 [2:43:20<11:36,  1.70s/it] 93%|█████████▎| 5514/5922 [2:43:22<11:08,  1.64s/it] 93%|█████████▎| 5515/5922 [2:43:24<12:47,  1.89s/it] 93%|█████████▎| 5516/5922 [2:43:26<11:45,  1.74s/it] 93%|█████████▎| 5517/5922 [2:43:28<12:07,  1.80s/it] 93%|█████████▎| 5518/5922 [2:43:30<12:42,  1.89s/it] 93%|█████████▎| 5519/5922 [2:43:32<12:45,  1.90s/it] 93%|█████████▎| 5520/5922 [2:43:34<12:50,  1.92s/it] 93%|█████████▎| 5521/5922 [2:43:36<12:46,  1.91s/it] 93%|█████████▎| 5522/5922 [2:43:38<12:46,  1.92s/it] 93%|█████████▎| 5523/5922 [2:43:39<11:39,  1.75s/it] 93%|█████████▎| 5524/5922 [2:43:41<12:03,  1.82s/it] 93%|█████████▎| 5525/5922 [2:43:43<13:19,  2.01s/it]                                                     {'loss': 0.1377, 'grad_norm': 0.4929668059166395, 'learning_rate': 1.2152884282486266e-06, 'epoch': 2.8}
 93%|█████████▎| 5525/5922 [2:43:43<13:19,  2.01s/it] 93%|█████████▎| 5526/5922 [2:43:45<12:24,  1.88s/it] 93%|█████████▎| 5527/5922 [2:43:47<12:22,  1.88s/it] 93%|█████████▎| 5528/5922 [2:43:48<11:19,  1.72s/it] 93%|█████████▎| 5529/5922 [2:43:50<12:04,  1.84s/it] 93%|█████████▎| 5530/5922 [2:43:52<11:09,  1.71s/it] 93%|█████████▎| 5531/5922 [2:43:53<10:45,  1.65s/it] 93%|█████████▎| 5532/5922 [2:43:55<11:15,  1.73s/it] 93%|█████████▎| 5533/5922 [2:43:57<10:46,  1.66s/it] 93%|█████████▎| 5534/5922 [2:43:58<10:26,  1.61s/it] 93%|█████████▎| 5535/5922 [2:44:00<10:00,  1.55s/it] 93%|█████████▎| 5536/5922 [2:44:01<10:01,  1.56s/it] 93%|█████████▎| 5537/5922 [2:44:04<11:45,  1.83s/it] 94%|█████████▎| 5538/5922 [2:44:05<10:53,  1.70s/it] 94%|█████████▎| 5539/5922 [2:44:07<10:53,  1.71s/it] 94%|█████████▎| 5540/5922 [2:44:09<11:46,  1.85s/it] 94%|█████████▎| 5541/5922 [2:44:11<11:57,  1.88s/it] 94%|█████████▎| 5542/5922 [2:44:12<11:02,  1.74s/it] 94%|█████████▎| 5543/5922 [2:44:14<10:32,  1.67s/it] 94%|█████████▎| 5544/5922 [2:44:15<10:06,  1.61s/it] 94%|█████████▎| 5545/5922 [2:44:17<11:07,  1.77s/it] 94%|█████████▎| 5546/5922 [2:44:19<10:24,  1.66s/it] 94%|█████████▎| 5547/5922 [2:44:21<10:50,  1.74s/it] 94%|█████████▎| 5548/5922 [2:44:22<10:31,  1.69s/it] 94%|█████████▎| 5549/5922 [2:44:24<10:17,  1.66s/it] 94%|█████████▎| 5550/5922 [2:44:26<10:46,  1.74s/it]                                                     {'loss': 0.131, 'grad_norm': 0.5752723335089129, 'learning_rate': 1.1891789047991278e-06, 'epoch': 2.81}
 94%|█████████▎| 5550/5922 [2:44:26<10:46,  1.74s/it] 94%|█████████▎| 5551/5922 [2:44:28<11:50,  1.92s/it] 94%|█████████▍| 5552/5922 [2:44:30<12:12,  1.98s/it] 94%|█████████▍| 5553/5922 [2:44:32<12:04,  1.96s/it] 94%|█████████▍| 5554/5922 [2:44:34<12:15,  2.00s/it] 94%|█████████▍| 5555/5922 [2:44:36<11:11,  1.83s/it] 94%|█████████▍| 5556/5922 [2:44:37<10:36,  1.74s/it] 94%|█████████▍| 5557/5922 [2:44:39<10:46,  1.77s/it] 94%|█████████▍| 5558/5922 [2:44:41<11:01,  1.82s/it] 94%|█████████▍| 5559/5922 [2:44:42<10:14,  1.69s/it] 94%|█████████▍| 5560/5922 [2:44:45<11:29,  1.90s/it] 94%|█████████▍| 5561/5922 [2:44:47<11:33,  1.92s/it] 94%|█████████▍| 5562/5922 [2:44:48<10:42,  1.78s/it] 94%|█████████▍| 5563/5922 [2:44:50<10:54,  1.82s/it] 94%|█████████▍| 5564/5922 [2:44:52<11:55,  2.00s/it] 94%|█████████▍| 5565/5922 [2:44:54<11:44,  1.97s/it] 94%|█████████▍| 5566/5922 [2:44:56<10:41,  1.80s/it] 94%|█████████▍| 5567/5922 [2:44:57<09:57,  1.68s/it] 94%|█████████▍| 5568/5922 [2:44:59<10:20,  1.75s/it] 94%|█████████▍| 5569/5922 [2:45:01<10:38,  1.81s/it] 94%|█████████▍| 5570/5922 [2:45:03<10:58,  1.87s/it] 94%|█████████▍| 5571/5922 [2:45:05<10:48,  1.85s/it] 94%|█████████▍| 5572/5922 [2:45:07<11:38,  2.00s/it] 94%|█████████▍| 5573/5922 [2:45:09<10:34,  1.82s/it] 94%|█████████▍| 5574/5922 [2:45:11<11:42,  2.02s/it] 94%|█████████▍| 5575/5922 [2:45:13<12:16,  2.12s/it]                                                     {'loss': 0.1369, 'grad_norm': 0.38457537228926764, 'learning_rate': 1.1647407398701609e-06, 'epoch': 2.82}
 94%|█████████▍| 5575/5922 [2:45:13<12:16,  2.12s/it] 94%|█████████▍| 5576/5922 [2:45:15<11:43,  2.03s/it] 94%|█████████▍| 5577/5922 [2:45:17<10:50,  1.89s/it] 94%|█████████▍| 5578/5922 [2:45:18<10:01,  1.75s/it] 94%|█████████▍| 5579/5922 [2:45:21<11:03,  1.93s/it] 94%|█████████▍| 5580/5922 [2:45:23<11:02,  1.94s/it] 94%|█████████▍| 5581/5922 [2:45:24<10:12,  1.79s/it] 94%|█████████▍| 5582/5922 [2:45:26<10:42,  1.89s/it] 94%|█████████▍| 5583/5922 [2:45:28<10:10,  1.80s/it] 94%|█████████▍| 5584/5922 [2:45:30<10:13,  1.82s/it] 94%|█████████▍| 5585/5922 [2:45:31<09:31,  1.70s/it] 94%|█████████▍| 5586/5922 [2:45:33<09:57,  1.78s/it] 94%|█████████▍| 5587/5922 [2:45:34<09:18,  1.67s/it] 94%|█████████▍| 5588/5922 [2:45:36<09:23,  1.69s/it] 94%|█████████▍| 5589/5922 [2:45:38<10:18,  1.86s/it] 94%|█████████▍| 5590/5922 [2:45:40<10:44,  1.94s/it] 94%|█████████▍| 5591/5922 [2:45:42<10:31,  1.91s/it] 94%|█████████▍| 5592/5922 [2:45:44<10:34,  1.92s/it] 94%|█████████▍| 5593/5922 [2:45:46<10:34,  1.93s/it] 94%|█████████▍| 5594/5922 [2:45:48<10:37,  1.94s/it] 94%|█████████▍| 5595/5922 [2:45:50<10:24,  1.91s/it] 94%|█████████▍| 5596/5922 [2:45:52<09:58,  1.83s/it] 95%|█████████▍| 5597/5922 [2:45:53<09:15,  1.71s/it] 95%|█████████▍| 5598/5922 [2:45:55<08:43,  1.61s/it] 95%|█████████▍| 5599/5922 [2:45:56<08:39,  1.61s/it] 95%|█████████▍| 5600/5922 [2:45:58<09:08,  1.70s/it]                                                     {'loss': 0.131, 'grad_norm': 0.5419611968976676, 'learning_rate': 1.1419783202859136e-06, 'epoch': 2.84}
 95%|█████████▍| 5600/5922 [2:45:58<09:08,  1.70s/it] 95%|█████████▍| 5601/5922 [2:45:59<08:43,  1.63s/it] 95%|█████████▍| 5602/5922 [2:46:01<08:20,  1.56s/it] 95%|█████████▍| 5603/5922 [2:46:03<08:57,  1.68s/it] 95%|█████████▍| 5604/5922 [2:46:04<08:29,  1.60s/it] 95%|█████████▍| 5605/5922 [2:46:06<08:16,  1.57s/it] 95%|█████████▍| 5606/5922 [2:46:07<08:03,  1.53s/it] 95%|█████████▍| 5607/5922 [2:46:09<07:52,  1.50s/it] 95%|█████████▍| 5608/5922 [2:46:11<08:45,  1.67s/it] 95%|█████████▍| 5609/5922 [2:46:12<08:35,  1.65s/it] 95%|█████████▍| 5610/5922 [2:46:15<09:50,  1.89s/it] 95%|█████████▍| 5611/5922 [2:46:17<10:01,  1.93s/it] 95%|█████████▍| 5612/5922 [2:46:19<09:59,  1.93s/it] 95%|█████████▍| 5613/5922 [2:46:20<09:07,  1.77s/it] 95%|█████████▍| 5614/5922 [2:46:22<09:21,  1.82s/it] 95%|█████████▍| 5615/5922 [2:46:25<10:18,  2.01s/it] 95%|█████████▍| 5616/5922 [2:46:26<10:10,  2.00s/it] 95%|█████████▍| 5617/5922 [2:46:29<10:15,  2.02s/it] 95%|█████████▍| 5618/5922 [2:46:30<09:57,  1.96s/it] 95%|█████████▍| 5619/5922 [2:46:32<09:52,  1.95s/it] 95%|█████████▍| 5620/5922 [2:46:34<09:30,  1.89s/it] 95%|█████████▍| 5621/5922 [2:46:35<08:45,  1.75s/it] 95%|█████████▍| 5622/5922 [2:46:37<08:41,  1.74s/it] 95%|█████████▍| 5623/5922 [2:46:39<08:09,  1.64s/it] 95%|█████████▍| 5624/5922 [2:46:40<08:34,  1.72s/it] 95%|█████████▍| 5625/5922 [2:46:42<08:14,  1.67s/it]                                                     {'loss': 0.1296, 'grad_norm': 0.4621061095199513, 'learning_rate': 1.1208957320623811e-06, 'epoch': 2.85}
 95%|█████████▍| 5625/5922 [2:46:42<08:14,  1.67s/it] 95%|█████████▌| 5626/5922 [2:46:44<08:48,  1.79s/it] 95%|█████████▌| 5627/5922 [2:46:46<09:01,  1.83s/it] 95%|█████████▌| 5628/5922 [2:46:47<08:21,  1.71s/it] 95%|█████████▌| 5629/5922 [2:46:50<08:55,  1.83s/it] 95%|█████████▌| 5630/5922 [2:46:51<08:59,  1.85s/it] 95%|█████████▌| 5631/5922 [2:46:54<09:24,  1.94s/it] 95%|█████████▌| 5632/5922 [2:46:55<09:09,  1.90s/it] 95%|█████████▌| 5633/5922 [2:46:57<08:27,  1.76s/it] 95%|█████████▌| 5634/5922 [2:46:59<08:41,  1.81s/it] 95%|█████████▌| 5635/5922 [2:47:01<08:46,  1.84s/it] 95%|█████████▌| 5636/5922 [2:47:03<08:55,  1.87s/it] 95%|█████████▌| 5637/5922 [2:47:04<08:16,  1.74s/it] 95%|█████████▌| 5638/5922 [2:47:06<07:52,  1.66s/it] 95%|█████████▌| 5639/5922 [2:47:07<08:12,  1.74s/it] 95%|█████████▌| 5640/5922 [2:47:09<08:27,  1.80s/it] 95%|█████████▌| 5641/5922 [2:47:11<07:52,  1.68s/it] 95%|█████████▌| 5642/5922 [2:47:13<08:24,  1.80s/it] 95%|█████████▌| 5643/5922 [2:47:14<08:00,  1.72s/it] 95%|█████████▌| 5644/5922 [2:47:17<09:00,  1.95s/it] 95%|█████████▌| 5645/5922 [2:47:19<09:02,  1.96s/it] 95%|█████████▌| 5646/5922 [2:47:21<08:59,  1.95s/it] 95%|█████████▌| 5647/5922 [2:47:22<08:13,  1.80s/it] 95%|█████████▌| 5648/5922 [2:47:24<07:38,  1.67s/it] 95%|█████████▌| 5649/5922 [2:47:26<07:57,  1.75s/it] 95%|█████████▌| 5650/5922 [2:47:28<08:13,  1.81s/it]                                                     {'loss': 0.1397, 'grad_norm': 0.4260912812243894, 'learning_rate': 1.1014967596738953e-06, 'epoch': 2.86}
 95%|█████████▌| 5650/5922 [2:47:28<08:13,  1.81s/it] 95%|█████████▌| 5651/5922 [2:47:29<07:35,  1.68s/it] 95%|█████████▌| 5652/5922 [2:47:30<07:11,  1.60s/it] 95%|█████████▌| 5653/5922 [2:47:32<06:57,  1.55s/it] 95%|█████████▌| 5654/5922 [2:47:33<06:44,  1.51s/it] 95%|█████████▌| 5655/5922 [2:47:35<06:35,  1.48s/it] 96%|█████████▌| 5656/5922 [2:47:36<06:47,  1.53s/it] 96%|█████████▌| 5657/5922 [2:47:38<07:09,  1.62s/it] 96%|█████████▌| 5658/5922 [2:47:40<07:05,  1.61s/it] 96%|█████████▌| 5659/5922 [2:47:42<07:31,  1.72s/it] 96%|█████████▌| 5660/5922 [2:47:44<07:46,  1.78s/it] 96%|█████████▌| 5661/5922 [2:47:45<07:26,  1.71s/it] 96%|█████████▌| 5662/5922 [2:47:47<07:04,  1.63s/it] 96%|█████████▌| 5663/5922 [2:47:48<06:45,  1.57s/it] 96%|█████████▌| 5664/5922 [2:47:50<07:11,  1.67s/it] 96%|█████████▌| 5665/5922 [2:47:52<07:21,  1.72s/it] 96%|█████████▌| 5666/5922 [2:47:54<07:36,  1.78s/it] 96%|█████████▌| 5667/5922 [2:47:55<07:39,  1.80s/it] 96%|█████████▌| 5668/5922 [2:47:57<07:50,  1.85s/it] 96%|█████████▌| 5669/5922 [2:47:59<07:16,  1.72s/it] 96%|█████████▌| 5670/5922 [2:48:00<07:01,  1.67s/it] 96%|█████████▌| 5671/5922 [2:48:02<07:23,  1.77s/it] 96%|█████████▌| 5672/5922 [2:48:05<07:47,  1.87s/it] 96%|█████████▌| 5673/5922 [2:48:06<07:50,  1.89s/it] 96%|█████████▌| 5674/5922 [2:48:09<08:18,  2.01s/it] 96%|█████████▌| 5675/5922 [2:48:10<07:41,  1.87s/it]                                                     {'loss': 0.1244, 'grad_norm': 0.39501107107064687, 'learning_rate': 1.0837848853737914e-06, 'epoch': 2.88}
 96%|█████████▌| 5675/5922 [2:48:10<07:41,  1.87s/it] 96%|█████████▌| 5676/5922 [2:48:12<07:13,  1.76s/it] 96%|█████████▌| 5677/5922 [2:48:14<07:56,  1.95s/it] 96%|█████████▌| 5678/5922 [2:48:16<07:41,  1.89s/it] 96%|█████████▌| 5679/5922 [2:48:17<07:05,  1.75s/it] 96%|█████████▌| 5680/5922 [2:48:19<07:21,  1.82s/it] 96%|█████████▌| 5681/5922 [2:48:21<07:12,  1.80s/it] 96%|█████████▌| 5682/5922 [2:48:23<06:45,  1.69s/it] 96%|█████████▌| 5683/5922 [2:48:24<06:22,  1.60s/it] 96%|█████████▌| 5684/5922 [2:48:26<06:36,  1.67s/it] 96%|█████████▌| 5685/5922 [2:48:27<06:18,  1.60s/it] 96%|█████████▌| 5686/5922 [2:48:29<06:46,  1.72s/it] 96%|█████████▌| 5687/5922 [2:48:31<07:14,  1.85s/it] 96%|█████████▌| 5688/5922 [2:48:33<07:05,  1.82s/it] 96%|█████████▌| 5689/5922 [2:48:35<07:05,  1.83s/it] 96%|█████████▌| 5690/5922 [2:48:37<07:49,  2.03s/it] 96%|█████████▌| 5691/5922 [2:48:39<07:41,  2.00s/it] 96%|█████████▌| 5692/5922 [2:48:41<07:39,  2.00s/it] 96%|█████████▌| 5693/5922 [2:48:43<07:38,  2.00s/it] 96%|█████████▌| 5694/5922 [2:48:45<06:58,  1.84s/it] 96%|█████████▌| 5695/5922 [2:48:47<07:19,  1.94s/it] 96%|█████████▌| 5696/5922 [2:48:49<06:53,  1.83s/it] 96%|█████████▌| 5697/5922 [2:48:51<07:30,  2.00s/it] 96%|█████████▌| 5698/5922 [2:48:53<07:28,  2.00s/it] 96%|█████████▌| 5699/5922 [2:48:55<07:27,  2.01s/it] 96%|█████████▋| 5700/5922 [2:48:57<07:52,  2.13s/it]                                                     {'loss': 0.1301, 'grad_norm': 0.49165353431746234, 'learning_rate': 1.0677632885693112e-06, 'epoch': 2.89}
 96%|█████████▋| 5700/5922 [2:48:57<07:52,  2.13s/it] 96%|█████████▋| 5701/5922 [2:48:59<07:38,  2.08s/it] 96%|█████████▋| 5702/5922 [2:49:01<07:29,  2.04s/it] 96%|█████████▋| 5703/5922 [2:49:03<07:23,  2.02s/it] 96%|█████████▋| 5704/5922 [2:49:05<06:50,  1.88s/it] 96%|█████████▋| 5705/5922 [2:49:07<07:22,  2.04s/it] 96%|█████████▋| 5706/5922 [2:49:09<07:06,  1.98s/it] 96%|█████████▋| 5707/5922 [2:49:10<06:28,  1.81s/it] 96%|█████████▋| 5708/5922 [2:49:12<06:35,  1.85s/it] 96%|█████████▋| 5709/5922 [2:49:14<06:14,  1.76s/it] 96%|█████████▋| 5710/5922 [2:49:15<05:50,  1.65s/it] 96%|█████████▋| 5711/5922 [2:49:17<06:12,  1.77s/it] 96%|█████████▋| 5712/5922 [2:49:19<05:51,  1.67s/it] 96%|█████████▋| 5713/5922 [2:49:20<05:33,  1.60s/it] 96%|█████████▋| 5714/5922 [2:49:22<05:40,  1.64s/it] 97%|█████████▋| 5715/5922 [2:49:24<06:03,  1.75s/it] 97%|█████████▋| 5716/5922 [2:49:25<05:42,  1.66s/it] 97%|█████████▋| 5717/5922 [2:49:28<06:20,  1.86s/it] 97%|█████████▋| 5718/5922 [2:49:30<06:46,  1.99s/it] 97%|█████████▋| 5719/5922 [2:49:32<06:31,  1.93s/it] 97%|█████████▋| 5720/5922 [2:49:33<06:03,  1.80s/it] 97%|█████████▋| 5721/5922 [2:49:36<06:22,  1.90s/it] 97%|█████████▋| 5722/5922 [2:49:37<05:54,  1.77s/it] 97%|█████████▋| 5723/5922 [2:49:39<06:04,  1.83s/it] 97%|█████████▋| 5724/5922 [2:49:41<05:52,  1.78s/it] 97%|█████████▋| 5725/5922 [2:49:43<06:01,  1.83s/it]                                                     {'loss': 0.1329, 'grad_norm': 0.5069373658466365, 'learning_rate': 1.0534348452508802e-06, 'epoch': 2.9}
 97%|█████████▋| 5725/5922 [2:49:43<06:01,  1.83s/it] 97%|█████████▋| 5726/5922 [2:49:45<06:19,  1.93s/it] 97%|█████████▋| 5727/5922 [2:49:47<06:13,  1.92s/it] 97%|█████████▋| 5728/5922 [2:49:49<06:29,  2.01s/it] 97%|█████████▋| 5729/5922 [2:49:51<06:14,  1.94s/it] 97%|█████████▋| 5730/5922 [2:49:53<06:23,  2.00s/it] 97%|█████████▋| 5731/5922 [2:49:55<06:09,  1.94s/it] 97%|█████████▋| 5732/5922 [2:49:56<06:02,  1.91s/it] 97%|█████████▋| 5733/5922 [2:49:58<06:03,  1.92s/it] 97%|█████████▋| 5734/5922 [2:50:00<06:11,  1.97s/it] 97%|█████████▋| 5735/5922 [2:50:02<05:50,  1.87s/it] 97%|█████████▋| 5736/5922 [2:50:04<05:53,  1.90s/it] 97%|█████████▋| 5737/5922 [2:50:05<05:24,  1.76s/it] 97%|█████████▋| 5738/5922 [2:50:07<05:09,  1.68s/it] 97%|█████████▋| 5739/5922 [2:50:08<04:51,  1.60s/it] 97%|█████████▋| 5740/5922 [2:50:10<04:49,  1.59s/it] 97%|█████████▋| 5741/5922 [2:50:12<05:00,  1.66s/it] 97%|█████████▋| 5742/5922 [2:50:13<04:47,  1.60s/it] 97%|█████████▋| 5743/5922 [2:50:15<05:06,  1.71s/it] 97%|█████████▋| 5744/5922 [2:50:17<05:26,  1.83s/it] 97%|█████████▋| 5745/5922 [2:50:19<05:04,  1.72s/it] 97%|█████████▋| 5746/5922 [2:50:20<04:45,  1.62s/it] 97%|█████████▋| 5747/5922 [2:50:22<04:33,  1.56s/it] 97%|█████████▋| 5748/5922 [2:50:24<04:50,  1.67s/it] 97%|█████████▋| 5749/5922 [2:50:25<05:01,  1.74s/it] 97%|█████████▋| 5750/5922 [2:50:27<05:02,  1.76s/it]                                                     {'loss': 0.1281, 'grad_norm': 0.3802008569850615, 'learning_rate': 1.04080212747585e-06, 'epoch': 2.91}
 97%|█████████▋| 5750/5922 [2:50:27<05:02,  1.76s/it] 97%|█████████▋| 5751/5922 [2:50:29<04:49,  1.69s/it] 97%|█████████▋| 5752/5922 [2:50:31<05:00,  1.77s/it] 97%|█████████▋| 5753/5922 [2:50:33<05:04,  1.80s/it] 97%|█████████▋| 5754/5922 [2:50:35<05:18,  1.89s/it] 97%|█████████▋| 5755/5922 [2:50:37<05:20,  1.92s/it] 97%|█████████▋| 5756/5922 [2:50:38<04:55,  1.78s/it] 97%|█████████▋| 5757/5922 [2:50:40<04:42,  1.71s/it] 97%|█████████▋| 5758/5922 [2:50:42<04:52,  1.78s/it] 97%|█████████▋| 5759/5922 [2:50:43<04:32,  1.67s/it] 97%|█████████▋| 5760/5922 [2:50:45<04:43,  1.75s/it] 97%|█████████▋| 5761/5922 [2:50:46<04:24,  1.65s/it] 97%|█████████▋| 5762/5922 [2:50:49<04:54,  1.84s/it] 97%|█████████▋| 5763/5922 [2:50:51<04:54,  1.85s/it] 97%|█████████▋| 5764/5922 [2:50:52<04:31,  1.72s/it] 97%|█████████▋| 5765/5922 [2:50:54<04:28,  1.71s/it] 97%|█████████▋| 5766/5922 [2:50:55<04:16,  1.65s/it] 97%|█████████▋| 5767/5922 [2:50:57<04:32,  1.76s/it] 97%|█████████▋| 5768/5922 [2:50:59<04:21,  1.70s/it] 97%|█████████▋| 5769/5922 [2:51:01<04:30,  1.77s/it] 97%|█████████▋| 5770/5922 [2:51:02<04:20,  1.71s/it] 97%|█████████▋| 5771/5922 [2:51:04<04:06,  1.63s/it] 97%|█████████▋| 5772/5922 [2:51:06<04:38,  1.85s/it] 97%|█████████▋| 5773/5922 [2:51:08<04:25,  1.78s/it] 98%|█████████▊| 5774/5922 [2:51:09<04:06,  1.67s/it] 98%|█████████▊| 5775/5922 [2:51:10<03:53,  1.59s/it]                                                     {'loss': 0.1261, 'grad_norm': 0.3307339505622019, 'learning_rate': 1.0298674029067877e-06, 'epoch': 2.93}
 98%|█████████▊| 5775/5922 [2:51:10<03:53,  1.59s/it] 98%|█████████▊| 5776/5922 [2:51:12<04:08,  1.70s/it] 98%|█████████▊| 5777/5922 [2:51:14<04:16,  1.77s/it] 98%|█████████▊| 5778/5922 [2:51:16<04:00,  1.67s/it] 98%|█████████▊| 5779/5922 [2:51:18<04:09,  1.75s/it] 98%|█████████▊| 5780/5922 [2:51:19<04:04,  1.72s/it] 98%|█████████▊| 5781/5922 [2:51:21<03:48,  1.62s/it] 98%|█████████▊| 5782/5922 [2:51:22<03:38,  1.56s/it] 98%|█████████▊| 5783/5922 [2:51:24<03:33,  1.53s/it] 98%|█████████▊| 5784/5922 [2:51:26<03:49,  1.66s/it] 98%|█████████▊| 5785/5922 [2:51:27<03:38,  1.59s/it] 98%|█████████▊| 5786/5922 [2:51:29<03:43,  1.64s/it] 98%|█████████▊| 5787/5922 [2:51:31<03:48,  1.69s/it] 98%|█████████▊| 5788/5922 [2:51:33<04:11,  1.88s/it] 98%|█████████▊| 5789/5922 [2:51:34<03:54,  1.76s/it] 98%|█████████▊| 5790/5922 [2:51:36<03:39,  1.66s/it] 98%|█████████▊| 5791/5922 [2:51:38<03:58,  1.82s/it] 98%|█████████▊| 5792/5922 [2:51:40<04:02,  1.86s/it] 98%|█████████▊| 5793/5922 [2:51:41<03:45,  1.74s/it] 98%|█████████▊| 5794/5922 [2:51:43<03:34,  1.68s/it] 98%|█████████▊| 5795/5922 [2:51:45<03:31,  1.66s/it] 98%|█████████▊| 5796/5922 [2:51:47<03:44,  1.78s/it] 98%|█████████▊| 5797/5922 [2:51:49<03:48,  1.83s/it] 98%|█████████▊| 5798/5922 [2:51:51<03:52,  1.87s/it] 98%|█████████▊| 5799/5922 [2:51:52<03:38,  1.77s/it] 98%|█████████▊| 5800/5922 [2:51:54<03:36,  1.77s/it]                                                     {'loss': 0.1352, 'grad_norm': 0.4709344300993738, 'learning_rate': 1.0206326344044237e-06, 'epoch': 2.94}
 98%|█████████▊| 5800/5922 [2:51:54<03:36,  1.77s/it] 98%|█████████▊| 5801/5922 [2:51:55<03:20,  1.66s/it] 98%|█████████▊| 5802/5922 [2:51:57<03:29,  1.75s/it] 98%|█████████▊| 5803/5922 [2:51:59<03:34,  1.80s/it] 98%|█████████▊| 5804/5922 [2:52:01<03:37,  1.84s/it] 98%|█████████▊| 5805/5922 [2:52:03<03:39,  1.87s/it] 98%|█████████▊| 5806/5922 [2:52:05<03:44,  1.94s/it] 98%|█████████▊| 5807/5922 [2:52:07<03:27,  1.80s/it] 98%|█████████▊| 5808/5922 [2:52:08<03:12,  1.69s/it] 98%|█████████▊| 5809/5922 [2:52:09<03:01,  1.61s/it] 98%|█████████▊| 5810/5922 [2:52:11<03:00,  1.61s/it] 98%|█████████▊| 5811/5922 [2:52:13<02:52,  1.56s/it] 98%|█████████▊| 5812/5922 [2:52:14<03:04,  1.67s/it] 98%|█████████▊| 5813/5922 [2:52:16<02:54,  1.60s/it] 98%|█████████▊| 5814/5922 [2:52:18<02:56,  1.64s/it] 98%|█████████▊| 5815/5922 [2:52:20<03:04,  1.73s/it] 98%|█████████▊| 5816/5922 [2:52:21<03:05,  1.75s/it] 98%|█████████▊| 5817/5922 [2:52:23<02:57,  1.69s/it] 98%|█████████▊| 5818/5922 [2:52:24<02:46,  1.60s/it] 98%|█████████▊| 5819/5922 [2:52:26<02:39,  1.55s/it] 98%|█████████▊| 5820/5922 [2:52:28<02:49,  1.66s/it] 98%|█████████▊| 5821/5922 [2:52:30<03:09,  1.87s/it] 98%|█████████▊| 5822/5922 [2:52:31<02:52,  1.73s/it] 98%|█████████▊| 5823/5922 [2:52:33<02:57,  1.79s/it] 98%|█████████▊| 5824/5922 [2:52:35<02:43,  1.67s/it] 98%|█████████▊| 5825/5922 [2:52:36<02:34,  1.60s/it]                                                     {'loss': 0.1414, 'grad_norm': 0.38083734836873445, 'learning_rate': 1.0130994796752977e-06, 'epoch': 2.95}
 98%|█████████▊| 5825/5922 [2:52:36<02:34,  1.60s/it] 98%|█████████▊| 5826/5922 [2:52:38<02:38,  1.65s/it] 98%|█████████▊| 5827/5922 [2:52:40<02:59,  1.89s/it] 98%|█████████▊| 5828/5922 [2:52:42<02:44,  1.75s/it] 98%|█████████▊| 5829/5922 [2:52:43<02:33,  1.65s/it] 98%|█████████▊| 5830/5922 [2:52:45<02:30,  1.63s/it] 98%|█████████▊| 5831/5922 [2:52:46<02:26,  1.61s/it] 98%|█████████▊| 5832/5922 [2:52:48<02:19,  1.56s/it] 98%|█████████▊| 5833/5922 [2:52:49<02:14,  1.51s/it] 99%|█████████▊| 5834/5922 [2:52:51<02:12,  1.50s/it] 99%|█████████▊| 5835/5922 [2:52:53<02:23,  1.65s/it] 99%|█████████▊| 5836/5922 [2:52:55<02:29,  1.74s/it] 99%|█████████▊| 5837/5922 [2:52:56<02:19,  1.65s/it] 99%|█████████▊| 5838/5922 [2:52:58<02:24,  1.72s/it] 99%|█████████▊| 5839/5922 [2:53:00<02:25,  1.75s/it] 99%|█████████▊| 5840/5922 [2:53:02<02:22,  1.74s/it] 99%|█████████▊| 5841/5922 [2:53:03<02:23,  1.77s/it] 99%|█████████▊| 5842/5922 [2:53:05<02:29,  1.87s/it] 99%|█████████▊| 5843/5922 [2:53:07<02:28,  1.88s/it] 99%|█████████▊| 5844/5922 [2:53:09<02:28,  1.90s/it] 99%|█████████▊| 5845/5922 [2:53:12<02:39,  2.08s/it] 99%|█████████▊| 5846/5922 [2:53:13<02:22,  1.87s/it] 99%|█████████▊| 5847/5922 [2:53:15<02:14,  1.79s/it] 99%|█████████▉| 5848/5922 [2:53:17<02:16,  1.84s/it] 99%|█████████▉| 5849/5922 [2:53:19<02:20,  1.93s/it] 99%|█████████▉| 5850/5922 [2:53:20<02:10,  1.81s/it]                                                     {'loss': 0.1215, 'grad_norm': 0.3657060674804511, 'learning_rate': 1.0072692909741902e-06, 'epoch': 2.96}
 99%|█████████▉| 5850/5922 [2:53:20<02:10,  1.81s/it] 99%|█████████▉| 5851/5922 [2:53:22<02:02,  1.73s/it] 99%|█████████▉| 5852/5922 [2:53:23<01:54,  1.63s/it] 99%|█████████▉| 5853/5922 [2:53:25<01:52,  1.63s/it] 99%|█████████▉| 5854/5922 [2:53:26<01:46,  1.56s/it] 99%|█████████▉| 5855/5922 [2:53:28<01:48,  1.62s/it] 99%|█████████▉| 5856/5922 [2:53:30<01:52,  1.71s/it] 99%|█████████▉| 5857/5922 [2:53:32<01:55,  1.78s/it] 99%|█████████▉| 5858/5922 [2:53:34<01:56,  1.82s/it] 99%|█████████▉| 5859/5922 [2:53:36<01:57,  1.86s/it] 99%|█████████▉| 5860/5922 [2:53:38<01:56,  1.88s/it] 99%|█████████▉| 5861/5922 [2:53:40<01:55,  1.89s/it] 99%|█████████▉| 5862/5922 [2:53:41<01:44,  1.75s/it] 99%|█████████▉| 5863/5922 [2:53:43<01:46,  1.81s/it] 99%|█████████▉| 5864/5922 [2:53:45<01:46,  1.84s/it] 99%|█████████▉| 5865/5922 [2:53:47<01:42,  1.80s/it] 99%|█████████▉| 5866/5922 [2:53:48<01:36,  1.72s/it] 99%|█████████▉| 5867/5922 [2:53:50<01:29,  1.63s/it] 99%|█████████▉| 5868/5922 [2:53:51<01:26,  1.60s/it] 99%|█████████▉| 5869/5922 [2:53:53<01:32,  1.74s/it] 99%|█████████▉| 5870/5922 [2:53:55<01:25,  1.64s/it] 99%|█████████▉| 5871/5922 [2:53:56<01:21,  1.60s/it] 99%|█████████▉| 5872/5922 [2:53:58<01:18,  1.56s/it] 99%|█████████▉| 5873/5922 [2:54:00<01:21,  1.67s/it] 99%|█████████▉| 5874/5922 [2:54:01<01:16,  1.59s/it] 99%|█████████▉| 5875/5922 [2:54:02<01:13,  1.56s/it]                                                     {'loss': 0.1282, 'grad_norm': 0.42524835200359656, 'learning_rate': 1.003143114861384e-06, 'epoch': 2.98}
 99%|█████████▉| 5875/5922 [2:54:03<01:13,  1.56s/it] 99%|█████████▉| 5876/5922 [2:54:04<01:17,  1.67s/it] 99%|█████████▉| 5877/5922 [2:54:06<01:17,  1.73s/it] 99%|█████████▉| 5878/5922 [2:54:09<01:25,  1.95s/it] 99%|█████████▉| 5879/5922 [2:54:11<01:29,  2.07s/it] 99%|█████████▉| 5880/5922 [2:54:14<01:31,  2.19s/it] 99%|█████████▉| 5881/5922 [2:54:15<01:24,  2.07s/it] 99%|█████████▉| 5882/5922 [2:54:17<01:21,  2.03s/it] 99%|█████████▉| 5883/5922 [2:54:19<01:14,  1.90s/it] 99%|█████████▉| 5884/5922 [2:54:20<01:06,  1.74s/it] 99%|█████████▉| 5885/5922 [2:54:22<01:00,  1.64s/it] 99%|█████████▉| 5886/5922 [2:54:23<01:00,  1.68s/it] 99%|█████████▉| 5887/5922 [2:54:25<00:56,  1.60s/it] 99%|█████████▉| 5888/5922 [2:54:27<00:57,  1.68s/it] 99%|█████████▉| 5889/5922 [2:54:28<00:54,  1.64s/it] 99%|█████████▉| 5890/5922 [2:54:30<00:52,  1.63s/it] 99%|█████████▉| 5891/5922 [2:54:32<00:58,  1.87s/it] 99%|█████████▉| 5892/5922 [2:54:34<00:56,  1.88s/it]100%|█████████▉| 5893/5922 [2:54:36<00:54,  1.87s/it]100%|█████████▉| 5894/5922 [2:54:37<00:48,  1.73s/it]100%|█████████▉| 5895/5922 [2:54:39<00:44,  1.64s/it]100%|█████████▉| 5896/5922 [2:54:41<00:45,  1.74s/it]100%|█████████▉| 5897/5922 [2:54:42<00:41,  1.64s/it]100%|█████████▉| 5898/5922 [2:54:44<00:37,  1.58s/it]100%|█████████▉| 5899/5922 [2:54:45<00:34,  1.52s/it]100%|█████████▉| 5900/5922 [2:54:47<00:36,  1.65s/it]                                                     {'loss': 0.12, 'grad_norm': 0.5548475466062891, 'learning_rate': 1.0007216920148006e-06, 'epoch': 2.99}
100%|█████████▉| 5900/5922 [2:54:47<00:36,  1.65s/it]100%|█████████▉| 5901/5922 [2:54:48<00:33,  1.58s/it]100%|█████████▉| 5902/5922 [2:54:50<00:30,  1.53s/it]100%|█████████▉| 5903/5922 [2:54:51<00:29,  1.55s/it]100%|█████████▉| 5904/5922 [2:54:53<00:29,  1.66s/it]100%|█████████▉| 5905/5922 [2:54:55<00:27,  1.65s/it]100%|█████████▉| 5906/5922 [2:54:56<00:25,  1.57s/it]100%|█████████▉| 5907/5922 [2:54:58<00:22,  1.52s/it]100%|█████████▉| 5908/5922 [2:54:59<00:21,  1.55s/it]100%|█████████▉| 5909/5922 [2:55:01<00:19,  1.53s/it]100%|█████████▉| 5910/5922 [2:55:02<00:18,  1.51s/it]100%|█████████▉| 5911/5922 [2:55:04<00:18,  1.64s/it]100%|█████████▉| 5912/5922 [2:55:06<00:17,  1.74s/it]100%|█████████▉| 5913/5922 [2:55:08<00:16,  1.78s/it]100%|█████████▉| 5914/5922 [2:55:10<00:13,  1.71s/it]100%|█████████▉| 5915/5922 [2:55:11<00:11,  1.68s/it]100%|█████████▉| 5916/5922 [2:55:13<00:10,  1.77s/it]100%|█████████▉| 5917/5922 [2:55:15<00:08,  1.67s/it]100%|█████████▉| 5918/5922 [2:55:16<00:06,  1.63s/it]100%|█████████▉| 5919/5922 [2:55:19<00:05,  1.88s/it]100%|█████████▉| 5920/5922 [2:55:20<00:03,  1.82s/it]100%|█████████▉| 5921/5922 [2:55:22<00:01,  1.87s/it]100%|██████████| 5922/5922 [2:55:24<00:00,  1.67s/it][INFO|trainer.py:3993] 2025-08-30 16:44:15,388 >> Saving model checkpoint to saves/qwen3-1.7B/lora/sft/checkpoint-5922
[INFO|configuration_utils.py:696] 2025-08-30 16:44:15,400 >> loading configuration file /home/qianwenhao/LLM/Qwen3-1.7B/config.json
[INFO|configuration_utils.py:770] 2025-08-30 16:44:15,401 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "max_position_embeddings": 40960,
  "max_window_layers": 28,
  "model_type": "qwen3",
  "num_attention_heads": 16,
  "num_hidden_layers": 28,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|tokenization_utils_base.py:2356] 2025-08-30 16:44:15,417 >> chat template saved in saves/qwen3-1.7B/lora/sft/checkpoint-5922/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-08-30 16:44:15,417 >> tokenizer config file saved in saves/qwen3-1.7B/lora/sft/checkpoint-5922/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-08-30 16:44:15,417 >> Special tokens file saved in saves/qwen3-1.7B/lora/sft/checkpoint-5922/special_tokens_map.json
[2025-08-30 16:44:15,583] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step5920 is about to be saved!
[2025-08-30 16:44:15,592] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: saves/qwen3-1.7B/lora/sft/checkpoint-5922/global_step5920/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-08-30 16:44:15,592] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-5922/global_step5920/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-08-30 16:44:15,597] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-5922/global_step5920/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-08-30 16:44:15,599] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving saves/qwen3-1.7B/lora/sft/checkpoint-5922/global_step5920/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-08-30 16:44:15,610] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved saves/qwen3-1.7B/lora/sft/checkpoint-5922/global_step5920/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-08-30 16:44:15,611] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved saves/qwen3-1.7B/lora/sft/checkpoint-5922/global_step5920/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-08-30 16:44:15,618] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step5920 is ready now!
[INFO|trainer.py:2676] 2025-08-30 16:44:15,624 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                     {'train_runtime': 10526.0695, 'train_samples_per_second': 35.992, 'train_steps_per_second': 0.563, 'train_loss': 0.16881176041252344, 'epoch': 3.0}
100%|██████████| 5922/5922 [2:55:26<00:00,  1.67s/it]100%|██████████| 5922/5922 [2:55:26<00:00,  1.78s/it]
[INFO|trainer.py:3993] 2025-08-30 16:44:17,961 >> Saving model checkpoint to saves/qwen3-1.7B/lora/sft
[INFO|configuration_utils.py:696] 2025-08-30 16:44:17,973 >> loading configuration file /home/qianwenhao/LLM/Qwen3-1.7B/config.json
[INFO|configuration_utils.py:770] 2025-08-30 16:44:17,974 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "max_position_embeddings": 40960,
  "max_window_layers": 28,
  "model_type": "qwen3",
  "num_attention_heads": 16,
  "num_hidden_layers": 28,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|tokenization_utils_base.py:2356] 2025-08-30 16:44:17,990 >> chat template saved in saves/qwen3-1.7B/lora/sft/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-08-30 16:44:17,991 >> tokenizer config file saved in saves/qwen3-1.7B/lora/sft/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-08-30 16:44:17,991 >> Special tokens file saved in saves/qwen3-1.7B/lora/sft/special_tokens_map.json
***** train metrics *****
  epoch                    =        3.0
  total_flos               =    94768GF
  train_loss               =     0.1688
  train_runtime            = 2:55:26.06
  train_samples_per_second =     35.992
  train_steps_per_second   =      0.563
Figure saved at: saves/qwen3-1.7B/lora/sft/training_loss.png
[WARNING|2025-08-30 16:44:18] llamafactory.extras.ploting:148 >> No metric eval_loss to plot.
[WARNING|2025-08-30 16:44:18] llamafactory.extras.ploting:148 >> No metric eval_accuracy to plot.
[INFO|modelcard.py:450] 2025-08-30 16:44:18,361 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
